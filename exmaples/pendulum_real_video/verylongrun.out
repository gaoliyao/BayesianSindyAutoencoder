nohup: ignoring input
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From train_pendulum_sampling.py:92: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:30: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:269: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From ../../src/autoencoder_pendulum_masked_curriculum.py:198: The name tf.log is deprecated. Please use tf.math.log instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:14: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:24: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:27: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:64: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From /home/marsgao/.conda/envs/mars/lib/python3.7/site-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
WARNING:tensorflow:From ../../src/training_pendulum_curriculum.py:65: Laplace.__init__ (from tensorflow.python.ops.distributions.laplace) is deprecated and will be removed after 2019-01-01.
Instructions for updating:
The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.
2022-09-16 17:57:48.484610: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
2022-09-16 17:57:48.507496: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz
2022-09-16 17:57:48.509719: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562abad17020 executing computations on platform Host. Devices:
2022-09-16 17:57:48.509771: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2022-09-16 17:57:48.513987: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2022-09-16 17:57:48.683519: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562abad2c930 executing computations on platform CUDA. Devices:
2022-09-16 17:57:48.683578: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5
2022-09-16 17:57:48.684557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: NVIDIA GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:1a:00.0
2022-09-16 17:57:48.685041: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2022-09-16 17:57:48.689172: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2022-09-16 17:57:48.692546: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2022-09-16 17:57:48.693109: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2022-09-16 17:57:48.696721: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2022-09-16 17:57:48.698724: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2022-09-16 17:57:48.705069: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2022-09-16 17:57:48.706051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2022-09-16 17:57:48.706105: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2022-09-16 17:57:48.706690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-09-16 17:57:48.706705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2022-09-16 17:57:48.706715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2022-09-16 17:57:48.707668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9917 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5)
2022-09-16 17:57:49.744158: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
data_test['x'].shape (8, 648)
data_test['dx'].shape (8, 648)
data_test['ddx'].shape (8, 648)
(382, 648)
EXPERIMENT 0
Hyper-parameters and experimental setup
{'input_dim': 648, 'latent_dim': 1, 'model_order': 2, 'poly_order': 3, 'include_sine': True, 'library_dim': 11, 'sequential_thresholding': True, 'coefficient_threshold': 0.1, 'threshold_frequency': 500, 'threshold_start': 0, 'coefficient_mask': array([[1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]), 'coefficient_initialization': 'normal', 'loss_weight_decoder': 1000.0, 'loss_weight_sindy_x': 0.0005, 'loss_weight_sindy_z': 5e-05, 'activation': 'sigmoid', 'widths': [64, 32, 16], 'epoch_size': 382, 'batch_size': 10, 'data_path': '/home/marsgao/SindyAutoencoders/examples/curriculum_pen_video/', 'print_progress': True, 'print_frequency': 25, 'max_epochs': 7501, 'refinement_epochs': 1501, 'prior': 'spike-and-slab', 'loss_weight_sindy_regularization': 0.1, 'learning_rate': 0.001, 'l2_weight': 0.1, 'pi': 0.091, 'c_std': 5.0, 'epsilon': 1.0, 'decay': 0.01, 'sigma': 0.5, 'csgld': 500}
TRAINING
=========================
[[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]
[[ 0.22698362]
 [ 0.5136674 ]
 [-1.1893321 ]
 [-0.927548  ]
 [-0.21265426]
 [-0.6615623 ]
 [ 0.8540417 ]
 [-0.14653428]
 [-0.14213614]
 [-2.2636807 ]
 [ 0.21450688]]
--- 0.8159325122833252 seconds for one epoch ---
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 110093.1171875, (103900.22, 0.02122371, 6174.408, 2.5317795)
   validation loss 101299.2890625, (100080.03, 0.023091106, 1200.7621, 2.5317795)
decoder loss ratio: 3877274.157200, decoder SINDy loss  ratio: 2.592014
--- 0.25646424293518066 seconds for one epoch ---
--- 0.32575106620788574 seconds for one epoch ---
--- 0.3352811336517334 seconds for one epoch ---
--- 0.3196146488189697 seconds for one epoch ---
--- 0.32671213150024414 seconds for one epoch ---
--- 0.31116557121276855 seconds for one epoch ---
--- 0.3290736675262451 seconds for one epoch ---
--- 0.3129746913909912 seconds for one epoch ---
--- 0.32955026626586914 seconds for one epoch ---
--- 0.3221769332885742 seconds for one epoch ---
--- 0.33376431465148926 seconds for one epoch ---
--- 0.32790660858154297 seconds for one epoch ---
--- 0.34926867485046387 seconds for one epoch ---
--- 0.3223254680633545 seconds for one epoch ---
--- 0.3326246738433838 seconds for one epoch ---
--- 0.32810473442077637 seconds for one epoch ---
--- 0.33928751945495605 seconds for one epoch ---
--- 0.32000136375427246 seconds for one epoch ---
--- 0.32506752014160156 seconds for one epoch ---
--- 0.3206641674041748 seconds for one epoch ---
--- 0.32979345321655273 seconds for one epoch ---
--- 0.31887173652648926 seconds for one epoch ---
--- 0.3382556438446045 seconds for one epoch ---
--- 0.3179776668548584 seconds for one epoch ---
=========================
[[0.7773236 ]
 [0.7773947 ]
 [0.7792643 ]
 [0.78087974]
 [0.77496946]
 [0.77764213]
 [0.77820444]
 [0.7749493 ]
 [0.77486986]
 [0.7896596 ]
 [0.7764449 ]]
[[ 0.5405202 ]
 [ 0.5527352 ]
 [-0.83468527]
 [-1.0331439 ]
 [ 0.03361244]
 [-0.5942722 ]
 [ 0.6834558 ]
 [ 0.02808368]
 [ 0.00601503]
 [-1.7629243 ]
 [ 0.37726673]]
--- 0.2548861503601074 seconds for one epoch ---
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 76128.875, (66868.984, 62.888912, 9156.421, 2.5317502)
   validation loss 46542.73046875, (45137.016, 35.105145, 1330.0328, 2.5317502)
decoder loss ratio: 1748686.346618, decoder SINDy loss  ratio: 2.871063
--- 0.31702685356140137 seconds for one epoch ---
--- 0.3382441997528076 seconds for one epoch ---
--- 0.3193073272705078 seconds for one epoch ---
--- 0.33004212379455566 seconds for one epoch ---
--- 0.3288884162902832 seconds for one epoch ---
--- 0.32880163192749023 seconds for one epoch ---
--- 0.309673547744751 seconds for one epoch ---
--- 0.3228747844696045 seconds for one epoch ---
--- 0.302905797958374 seconds for one epoch ---
--- 0.33772969245910645 seconds for one epoch ---
--- 0.31636738777160645 seconds for one epoch ---
--- 0.3567490577697754 seconds for one epoch ---
--- 0.3154423236846924 seconds for one epoch ---
--- 0.34856486320495605 seconds for one epoch ---
--- 0.3107891082763672 seconds for one epoch ---
--- 0.3380398750305176 seconds for one epoch ---
--- 0.31394386291503906 seconds for one epoch ---
--- 0.32910776138305664 seconds for one epoch ---
--- 0.315171480178833 seconds for one epoch ---
--- 0.34185314178466797 seconds for one epoch ---
--- 0.3179330825805664 seconds for one epoch ---
--- 0.3264150619506836 seconds for one epoch ---
--- 0.3163728713989258 seconds for one epoch ---
--- 0.33641982078552246 seconds for one epoch ---
=========================
[[0.6233101 ]
 [0.6169176 ]
 [0.6204505 ]
 [0.62738454]
 [0.61534   ]
 [0.6243285 ]
 [0.619136  ]
 [0.61598754]
 [0.61482036]
 [0.6237025 ]
 [0.6174036 ]]
[[ 0.90675664]
 [ 0.30243084]
 [-0.67478335]
 [-1.1740098 ]
 [-0.08486351]
 [-0.9793553 ]
 [ 0.5502039 ]
 [ 0.1794449 ]
 [ 0.00251536]
 [-0.93525577]
 [ 0.36161587]]
--- 0.30388712882995605 seconds for one epoch ---
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 52169.69140625, (43896.676, 16.842968, 8197.649, 2.5317354)
   validation loss 39796.20703125, (38563.477, 7.4872937, 1166.7185, 2.5317354)
decoder loss ratio: 1494016.031171, decoder SINDy loss  ratio: 2.518526
--- 0.273162841796875 seconds for one epoch ---
--- 0.31451845169067383 seconds for one epoch ---
--- 0.3386256694793701 seconds for one epoch ---
--- 0.3132505416870117 seconds for one epoch ---
--- 0.33817410469055176 seconds for one epoch ---
--- 0.30912065505981445 seconds for one epoch ---
--- 0.3401956558227539 seconds for one epoch ---
--- 0.3201465606689453 seconds for one epoch ---
--- 0.3522157669067383 seconds for one epoch ---
--- 0.29107213020324707 seconds for one epoch ---
--- 0.33670639991760254 seconds for one epoch ---
--- 0.3116953372955322 seconds for one epoch ---
--- 0.34175848960876465 seconds for one epoch ---
--- 0.303088903427124 seconds for one epoch ---
--- 0.3516674041748047 seconds for one epoch ---
--- 0.3316617012023926 seconds for one epoch ---
--- 0.3483738899230957 seconds for one epoch ---
--- 0.30746936798095703 seconds for one epoch ---
--- 0.33875179290771484 seconds for one epoch ---
--- 0.31696200370788574 seconds for one epoch ---
--- 0.3539290428161621 seconds for one epoch ---
--- 0.3056957721710205 seconds for one epoch ---
--- 0.33771705627441406 seconds for one epoch ---
--- 0.3192331790924072 seconds for one epoch ---
=========================
[[0.4907091 ]
 [0.48186797]
 [0.48739982]
 [0.49264333]
 [0.48195297]
 [0.50299823]
 [0.48705798]
 [0.48280075]
 [0.48077127]
 [0.48953015]
 [0.48346174]]
[[ 0.821463  ]
 [ 0.1286759 ]
 [-0.60886914]
 [-0.9297837 ]
 [-0.13789995]
 [-1.3855841 ]
 [ 0.5844722 ]
 [ 0.22566487]
 [-0.00232982]
 [-0.7501365 ]
 [ 0.28956488]]
--- 0.24548745155334473 seconds for one epoch ---
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 49685.07421875, (44596.85, 2.3238585, 5008.7837, 2.5317318)
   validation loss 18289.134765625, (17158.586, 0.31133562, 1053.1232, 2.5317318)
decoder loss ratio: 664753.407834, decoder SINDy loss  ratio: 2.273314
--- 0.32224440574645996 seconds for one epoch ---
--- 0.34264397621154785 seconds for one epoch ---
--- 0.31365418434143066 seconds for one epoch ---
--- 0.3402109146118164 seconds for one epoch ---
--- 0.30793142318725586 seconds for one epoch ---
--- 0.35033392906188965 seconds for one epoch ---
--- 0.30948710441589355 seconds for one epoch ---
--- 0.3554799556732178 seconds for one epoch ---
--- 0.29965996742248535 seconds for one epoch ---
--- 0.3511960506439209 seconds for one epoch ---
--- 0.2999229431152344 seconds for one epoch ---
--- 0.36798954010009766 seconds for one epoch ---
--- 0.2993581295013428 seconds for one epoch ---
--- 0.3371458053588867 seconds for one epoch ---
--- 0.325314998626709 seconds for one epoch ---
--- 0.3500826358795166 seconds for one epoch ---
--- 0.31233739852905273 seconds for one epoch ---
--- 0.34441447257995605 seconds for one epoch ---
--- 0.3008272647857666 seconds for one epoch ---
--- 0.34683871269226074 seconds for one epoch ---
--- 0.31600499153137207 seconds for one epoch ---
--- 0.34076952934265137 seconds for one epoch ---
--- 0.30143046379089355 seconds for one epoch ---
--- 0.35727429389953613 seconds for one epoch ---
=========================
[[0.39401293]
 [0.38491458]
 [0.38934124]
 [0.3958235 ]
 [0.38662246]
 [0.42009038]
 [0.39203474]
 [0.38722   ]
 [0.3849313 ]
 [0.3958776 ]
 [0.3873298 ]]
[[ 0.6818451 ]
 [ 0.00426133]
 [-0.3850224 ]
 [-0.7788306 ]
 [-0.16720672]
 [-1.6349381 ]
 [ 0.5655209 ]
 [ 0.21892555]
 [-0.00597584]
 [-0.78160685]
 [ 0.22818202]]
--- 0.29976701736450195 seconds for one epoch ---
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 27945.154296875, (19948.303, 5.366659, 7900.4443, 2.5317285)
   validation loss 10197.5205078125, (9232.457, 0.29351437, 873.7283, 2.5317285)
decoder loss ratio: 357681.413641, decoder SINDy loss  ratio: 1.886065
--- 0.26507067680358887 seconds for one epoch ---
--- 0.31603026390075684 seconds for one epoch ---
--- 0.3519010543823242 seconds for one epoch ---
--- 0.30295538902282715 seconds for one epoch ---
--- 0.35282063484191895 seconds for one epoch ---
--- 0.31061482429504395 seconds for one epoch ---
--- 0.35217881202697754 seconds for one epoch ---
--- 0.3127574920654297 seconds for one epoch ---
--- 0.37401723861694336 seconds for one epoch ---
--- 0.3034641742706299 seconds for one epoch ---
--- 0.34275150299072266 seconds for one epoch ---
--- 0.3152029514312744 seconds for one epoch ---
--- 0.359943151473999 seconds for one epoch ---
--- 0.39803051948547363 seconds for one epoch ---
--- 0.3474302291870117 seconds for one epoch ---
--- 0.3196382522583008 seconds for one epoch ---
--- 0.35906481742858887 seconds for one epoch ---
--- 0.3070549964904785 seconds for one epoch ---
--- 0.36708736419677734 seconds for one epoch ---
--- 0.32184481620788574 seconds for one epoch ---
--- 0.3526430130004883 seconds for one epoch ---
--- 0.3073453903198242 seconds for one epoch ---
--- 0.35250306129455566 seconds for one epoch ---
--- 0.3097798824310303 seconds for one epoch ---
=========================
[[0.31057936]
 [0.30574012]
 [0.30526942]
 [0.31433526]
 [0.30558196]
 [0.35085815]
 [0.3112187 ]
 [0.30708843]
 [0.30410504]
 [0.32203582]
 [0.30724362]]
[[ 0.47443542]
 [-0.14226195]
 [-0.10390211]
 [-0.67781675]
 [-0.1295253 ]
 [-1.7833875 ]
 [ 0.5117549 ]
 [ 0.24529783]
 [-0.00262217]
 [-1.0079001 ]
 [ 0.25655836]]
--- 0.24199461936950684 seconds for one epoch ---
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 18833.888671875, (12988.119, 147.94, 5593.457, 2.5317314)
   validation loss 6271.650390625, (5484.6797, 0.19252136, 682.40546, 2.5317314)
decoder loss ratio: 212486.012916, decoder SINDy loss  ratio: 1.473068
--- 0.30690479278564453 seconds for one epoch ---
--- 0.37781643867492676 seconds for one epoch ---
--- 0.29132533073425293 seconds for one epoch ---
--- 0.3495821952819824 seconds for one epoch ---
--- 0.3150770664215088 seconds for one epoch ---
--- 0.34131503105163574 seconds for one epoch ---
--- 0.3110079765319824 seconds for one epoch ---
--- 0.3776075839996338 seconds for one epoch ---
--- 0.31593966484069824 seconds for one epoch ---
--- 0.3661065101623535 seconds for one epoch ---
--- 0.30982255935668945 seconds for one epoch ---
--- 0.32024335861206055 seconds for one epoch ---
--- 0.31526613235473633 seconds for one epoch ---
--- 0.35336732864379883 seconds for one epoch ---
--- 0.315793514251709 seconds for one epoch ---
--- 0.36418700218200684 seconds for one epoch ---
--- 0.31339478492736816 seconds for one epoch ---
--- 0.36949753761291504 seconds for one epoch ---
--- 0.30939817428588867 seconds for one epoch ---
--- 0.36594438552856445 seconds for one epoch ---
--- 0.3142518997192383 seconds for one epoch ---
--- 0.3577420711517334 seconds for one epoch ---
--- 0.31145191192626953 seconds for one epoch ---
--- 0.3607966899871826 seconds for one epoch ---
=========================
[[0.24923402]
 [0.24900897]
 [0.24756975]
 [0.25509492]
 [0.24687687]
 [0.30598277]
 [0.25315768]
 [0.248658  ]
 [0.24602206]
 [0.27397338]
 [0.24927446]]
[[ 0.24745731]
 [-0.23222767]
 [ 0.12952735]
 [-0.5844336 ]
 [-0.07639559]
 [-1.9480441 ]
 [ 0.48388544]
 [ 0.20806314]
 [-0.00704241]
 [-1.2724267 ]
 [ 0.25017798]]
--- 0.310272216796875 seconds for one epoch ---
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 12253.23828125, (9116.829, 16.859455, 3002.2444, 2.531741)
   validation loss 12154.875, (11357.037, 0.13275878, 680.3994, 2.531741)
decoder loss ratio: 439991.334301, decoder SINDy loss  ratio: 1.468738
--- 0.25823068618774414 seconds for one epoch ---
--- 0.31435608863830566 seconds for one epoch ---
--- 0.3883357048034668 seconds for one epoch ---
--- 0.3274064064025879 seconds for one epoch ---
--- 0.3688066005706787 seconds for one epoch ---
--- 0.3239898681640625 seconds for one epoch ---
--- 0.3954737186431885 seconds for one epoch ---
--- 0.3155946731567383 seconds for one epoch ---
--- 0.3710455894470215 seconds for one epoch ---
--- 0.30897045135498047 seconds for one epoch ---
--- 0.36335086822509766 seconds for one epoch ---
--- 0.3208131790161133 seconds for one epoch ---
--- 0.3857574462890625 seconds for one epoch ---
--- 0.29626941680908203 seconds for one epoch ---
--- 0.37787532806396484 seconds for one epoch ---
--- 0.3231816291809082 seconds for one epoch ---
--- 0.3800365924835205 seconds for one epoch ---
--- 0.32879209518432617 seconds for one epoch ---
--- 0.39678001403808594 seconds for one epoch ---
--- 0.3181161880493164 seconds for one epoch ---
--- 0.3856840133666992 seconds for one epoch ---
--- 0.3203873634338379 seconds for one epoch ---
--- 0.36905932426452637 seconds for one epoch ---
--- 0.31595349311828613 seconds for one epoch ---
=========================
[[0.19737299]
 [0.2011969 ]
 [0.20134498]
 [0.20549282]
 [0.19756821]
 [0.26782393]
 [0.20328212]
 [0.19988514]
 [0.19671176]
 [0.23607942]
 [0.20158333]]
[[ 0.05538916]
 [-0.31058443]
 [ 0.31937155]
 [-0.5408374 ]
 [-0.06996813]
 [-2.0560884 ]
 [ 0.42828372]
 [ 0.22957918]
 [-0.00448536]
 [-1.4994087 ]
 [ 0.33336943]]
--- 0.25860095024108887 seconds for one epoch ---
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 12215.55859375, (6983.178, 4.6840415, 5099.202, 2.5317543)
   validation loss 7504.91845703125, (6868.096, 0.11290438, 508.21585, 2.5317543)
decoder loss ratio: 266081.969994, decoder SINDy loss  ratio: 1.097055
--- 0.3089487552642822 seconds for one epoch ---
--- 0.36640071868896484 seconds for one epoch ---
--- 0.31197237968444824 seconds for one epoch ---
--- 0.3809211254119873 seconds for one epoch ---
--- 0.3177449703216553 seconds for one epoch ---
--- 0.39160847663879395 seconds for one epoch ---
--- 0.32491326332092285 seconds for one epoch ---
--- 0.3746461868286133 seconds for one epoch ---
--- 0.3143155574798584 seconds for one epoch ---
--- 0.4043610095977783 seconds for one epoch ---
--- 0.30725812911987305 seconds for one epoch ---
--- 0.3721129894256592 seconds for one epoch ---
--- 0.31430768966674805 seconds for one epoch ---
--- 0.38249921798706055 seconds for one epoch ---
--- 0.3097963333129883 seconds for one epoch ---
--- 0.38013768196105957 seconds for one epoch ---
--- 0.3106718063354492 seconds for one epoch ---
--- 0.3907456398010254 seconds for one epoch ---
--- 0.3168144226074219 seconds for one epoch ---
--- 0.386167049407959 seconds for one epoch ---
--- 0.31229448318481445 seconds for one epoch ---
--- 0.3792276382446289 seconds for one epoch ---
--- 0.3141796588897705 seconds for one epoch ---
--- 0.3844454288482666 seconds for one epoch ---
=========================
[[0.1630022 ]
 [0.16760196]
 [0.16941047]
 [0.16845362]
 [0.16140167]
 [0.24406974]
 [0.16744228]
 [0.1642017 ]
 [0.16104956]
 [0.21414112]
 [0.16698   ]]
[[-0.1430794 ]
 [-0.41260603]
 [ 0.5029155 ]
 [-0.45604625]
 [-0.03120536]
 [-2.172602  ]
 [ 0.4042731 ]
 [ 0.21997455]
 [-0.0049627 ]
 [-1.7277523 ]
 [ 0.37977976]]
--- 0.30307936668395996 seconds for one epoch ---
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7814.916015625, (3756.3438, 0.49713472, 3920.6614, 2.531773)
   validation loss 7437.33935546875, (6715.4844, 0.122001, 584.31903, 2.531773)
decoder loss ratio: 260169.523281, decoder SINDy loss  ratio: 1.261335
--- 0.2644212245941162 seconds for one epoch ---
--- 0.32688355445861816 seconds for one epoch ---
--- 0.38765597343444824 seconds for one epoch ---
--- 0.32561635971069336 seconds for one epoch ---
--- 0.3920426368713379 seconds for one epoch ---
--- 0.3245217800140381 seconds for one epoch ---
--- 0.3940455913543701 seconds for one epoch ---
--- 0.32111454010009766 seconds for one epoch ---
--- 0.38650941848754883 seconds for one epoch ---
--- 0.31940531730651855 seconds for one epoch ---
--- 0.40531134605407715 seconds for one epoch ---
--- 0.31902527809143066 seconds for one epoch ---
--- 0.3878440856933594 seconds for one epoch ---
--- 0.3095269203186035 seconds for one epoch ---
--- 0.395796537399292 seconds for one epoch ---
--- 0.3098123073577881 seconds for one epoch ---
--- 0.4148597717285156 seconds for one epoch ---
--- 0.32285356521606445 seconds for one epoch ---
--- 0.41939520835876465 seconds for one epoch ---
--- 0.32802677154541016 seconds for one epoch ---
--- 0.40130066871643066 seconds for one epoch ---
--- 0.3203139305114746 seconds for one epoch ---
--- 0.40631961822509766 seconds for one epoch ---
--- 0.3119668960571289 seconds for one epoch ---
=========================
[[0.13568275]
 [0.13924176]
 [0.14403547]
 [0.13671166]
 [0.13078512]
 [0.22253768]
 [0.13690044]
 [0.13384171]
 [0.13061248]
 [0.20028602]
 [0.13760148]]
[[-0.32132086]
 [-0.5000698 ]
 [ 0.7032229 ]
 [-0.37601238]
 [ 0.01553999]
 [-2.2434146 ]
 [ 0.38575602]
 [ 0.21614881]
 [ 0.00300176]
 [-1.9549943 ]
 [ 0.42122826]]
--- 0.2621195316314697 seconds for one epoch ---
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 11115.9306640625, (6556.1245, 6.1881876, 4408.804, 2.531793)
   validation loss 3880.659912109375, (3316.566, 0.105910935, 419.1747, 2.531793)
decoder loss ratio: 128489.521474, decoder SINDy loss  ratio: 0.904848
--- 0.3056640625 seconds for one epoch ---
--- 0.3829171657562256 seconds for one epoch ---
--- 0.3146688938140869 seconds for one epoch ---
--- 0.387432336807251 seconds for one epoch ---
--- 0.3097226619720459 seconds for one epoch ---
--- 0.3867168426513672 seconds for one epoch ---
--- 0.3111445903778076 seconds for one epoch ---
--- 0.3876924514770508 seconds for one epoch ---
--- 0.31661033630371094 seconds for one epoch ---
--- 0.4193384647369385 seconds for one epoch ---
--- 0.3094022274017334 seconds for one epoch ---
--- 0.38638949394226074 seconds for one epoch ---
--- 0.3121778964996338 seconds for one epoch ---
--- 0.39412760734558105 seconds for one epoch ---
--- 0.3054072856903076 seconds for one epoch ---
--- 0.4066951274871826 seconds for one epoch ---
--- 0.3208496570587158 seconds for one epoch ---
--- 0.39936089515686035 seconds for one epoch ---
--- 0.30708813667297363 seconds for one epoch ---
--- 0.3935587406158447 seconds for one epoch ---
--- 0.3206145763397217 seconds for one epoch ---
--- 0.41522669792175293 seconds for one epoch ---
--- 0.30969953536987305 seconds for one epoch ---
--- 0.4060213565826416 seconds for one epoch ---
=========================
[[0.11654905]
 [0.11804229]
 [0.12708978]
 [0.11278496]
 [0.10848947]
 [0.20662564]
 [0.11487103]
 [0.1114825 ]
 [0.10849001]
 [0.19382907]
 [0.11651739]]
[[-0.46446556]
 [-0.53215224]
 [ 0.8736401 ]
 [-0.27305052]
 [ 0.00408797]
 [-2.2874577 ]
 [ 0.38317734]
 [ 0.19826685]
 [-0.00412033]
 [-2.137347  ]
 [ 0.46298683]]
--- 0.28878188133239746 seconds for one epoch ---
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8364.71875, (4899.0586, 0.36366543, 3314.7322, 2.531809)
   validation loss 2664.01611328125, (2143.959, 0.09672201, 369.39676, 2.531809)
decoder loss ratio: 83060.693131, decoder SINDy loss  ratio: 0.797395
--- 0.25995516777038574 seconds for one epoch ---
--- 0.3157687187194824 seconds for one epoch ---
--- 0.4064359664916992 seconds for one epoch ---
--- 0.30809688568115234 seconds for one epoch ---
--- 0.3979165554046631 seconds for one epoch ---
--- 0.3089864253997803 seconds for one epoch ---
--- 0.40451836585998535 seconds for one epoch ---
--- 0.30820131301879883 seconds for one epoch ---
--- 0.3955557346343994 seconds for one epoch ---
--- 0.32203173637390137 seconds for one epoch ---
--- 0.4064939022064209 seconds for one epoch ---
--- 0.31377243995666504 seconds for one epoch ---
--- 0.40439796447753906 seconds for one epoch ---
--- 0.41465115547180176 seconds for one epoch ---
--- 0.37018632888793945 seconds for one epoch ---
--- 0.31042027473449707 seconds for one epoch ---
--- 0.43794822692871094 seconds for one epoch ---
--- 0.3172750473022461 seconds for one epoch ---
--- 0.4135575294494629 seconds for one epoch ---
--- 0.3157389163970947 seconds for one epoch ---
--- 0.40532398223876953 seconds for one epoch ---
--- 0.30179500579833984 seconds for one epoch ---
--- 0.4281454086303711 seconds for one epoch ---
--- 0.31107640266418457 seconds for one epoch ---
=========================
[[0.10105661]
 [0.10029519]
 [0.11437796]
 [0.09276281]
 [0.08960821]
 [0.191866  ]
 [0.09532455]
 [0.09254055]
 [0.08948721]
 [0.193575  ]
 [0.09896063]]
[[-0.6068114 ]
 [-0.5756839 ]
 [ 1.0480375 ]
 [-0.20969328]
 [ 0.01098636]
 [-2.3106172 ]
 [ 0.34810904]
 [ 0.19682118]
 [-0.00258334]
 [-2.3289394 ]
 [ 0.5189692 ]]
--- 0.22881460189819336 seconds for one epoch ---
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6461.90966796875, (2621.915, 0.560563, 3683.2256, 2.5318277)
   validation loss 2238.718505859375, (1729.9698, 0.09143447, 352.4488, 2.5318277)
decoder loss ratio: 67022.035296, decoder SINDy loss  ratio: 0.760810
--- 0.3144845962524414 seconds for one epoch ---
--- 0.41243815422058105 seconds for one epoch ---
--- 0.3056960105895996 seconds for one epoch ---
--- 0.4124584197998047 seconds for one epoch ---
--- 0.3046717643737793 seconds for one epoch ---
--- 0.4036386013031006 seconds for one epoch ---
--- 0.3139803409576416 seconds for one epoch ---
--- 0.41203951835632324 seconds for one epoch ---
--- 0.30540037155151367 seconds for one epoch ---
--- 0.4364321231842041 seconds for one epoch ---
--- 0.3237147331237793 seconds for one epoch ---
--- 0.4031970500946045 seconds for one epoch ---
--- 0.31588029861450195 seconds for one epoch ---
--- 0.4048311710357666 seconds for one epoch ---
--- 0.3123483657836914 seconds for one epoch ---
--- 0.41899633407592773 seconds for one epoch ---
--- 0.3196086883544922 seconds for one epoch ---
--- 0.4240303039550781 seconds for one epoch ---
--- 0.2934257984161377 seconds for one epoch ---
--- 0.42201781272888184 seconds for one epoch ---
--- 0.3153657913208008 seconds for one epoch ---
--- 0.4198417663574219 seconds for one epoch ---
--- 0.31212472915649414 seconds for one epoch ---
--- 0.4317004680633545 seconds for one epoch ---
=========================
[[0.09152527]
 [0.08804379]
 [0.10718623]
 [0.07786226]
 [0.07564928]
 [0.18089388]
 [0.08092985]
 [0.07888966]
 [0.07564002]
 [0.20329554]
 [0.08721882]]
[[-0.7620914 ]
 [-0.6344973 ]
 [ 1.2088581 ]
 [-0.14812228]
 [ 0.00648617]
 [-2.3250008 ]
 [ 0.3182568 ]
 [ 0.2080897 ]
 [-0.00585266]
 [-2.5451975 ]
 [ 0.6020592 ]]
--- 0.30396080017089844 seconds for one epoch ---
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6035.38525390625, (2590.186, 0.8108339, 3281.3196, 2.5318496)
   validation loss 3185.954345703125, (2585.5474, 0.11060102, 437.22745, 2.5318496)
decoder loss ratio: 100168.593561, decoder SINDy loss  ratio: 0.943817
--- 0.26837706565856934 seconds for one epoch ---
--- 0.3204805850982666 seconds for one epoch ---
--- 0.42279529571533203 seconds for one epoch ---
--- 0.30516552925109863 seconds for one epoch ---
--- 0.43509507179260254 seconds for one epoch ---
--- 0.3064591884613037 seconds for one epoch ---
--- 0.4163966178894043 seconds for one epoch ---
--- 0.3077683448791504 seconds for one epoch ---
--- 0.41445469856262207 seconds for one epoch ---
--- 0.3168482780456543 seconds for one epoch ---
--- 0.42519712448120117 seconds for one epoch ---
--- 0.30744171142578125 seconds for one epoch ---
--- 0.4249105453491211 seconds for one epoch ---
--- 0.3121969699859619 seconds for one epoch ---
--- 0.43396615982055664 seconds for one epoch ---
--- 0.32096004486083984 seconds for one epoch ---
--- 0.42240357398986816 seconds for one epoch ---
--- 0.3030824661254883 seconds for one epoch ---
--- 0.427182674407959 seconds for one epoch ---
--- 0.31877565383911133 seconds for one epoch ---
--- 0.4319612979888916 seconds for one epoch ---
--- 0.3363535404205322 seconds for one epoch ---
--- 0.43535852432250977 seconds for one epoch ---
--- 0.3237583637237549 seconds for one epoch ---
=========================
[[0.08430535]
 [0.07743607]
 [0.10212874]
 [0.06565198]
 [0.0638172 ]
 [0.17151085]
 [0.06849842]
 [0.0668722 ]
 [0.06361237]
 [0.2163498 ]
 [0.07599956]]
[[-9.0839887e-01]
 [-6.7988610e-01]
 [ 1.3532399e+00]
 [-1.3256791e-01]
 [ 1.6309777e-02]
 [-2.3377438e+00]
 [ 2.9147163e-01]
 [ 2.0352811e-01]
 [-2.5237801e-03]
 [-2.7459354e+00]
 [ 6.2579012e-01]]
--- 0.24530792236328125 seconds for one epoch ---
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4968.39404296875, (2207.9248, 2.1020424, 2590.6501, 2.5318708)
   validation loss 1386.3690185546875, (853.1119, 0.10787295, 365.43176, 2.5318708)
decoder loss ratio: 33051.035199, decoder SINDy loss  ratio: 0.788836
--- 0.3083689212799072 seconds for one epoch ---
--- 0.42232608795166016 seconds for one epoch ---
--- 0.317690372467041 seconds for one epoch ---
--- 0.41253089904785156 seconds for one epoch ---
--- 0.30645060539245605 seconds for one epoch ---
--- 0.4343864917755127 seconds for one epoch ---
--- 0.3085041046142578 seconds for one epoch ---
--- 0.42706918716430664 seconds for one epoch ---
--- 0.31816697120666504 seconds for one epoch ---
--- 0.4548351764678955 seconds for one epoch ---
--- 0.3160848617553711 seconds for one epoch ---
--- 0.4363596439361572 seconds for one epoch ---
--- 0.32897090911865234 seconds for one epoch ---
--- 0.4335203170776367 seconds for one epoch ---
--- 0.316190242767334 seconds for one epoch ---
--- 0.42502570152282715 seconds for one epoch ---
--- 0.31366872787475586 seconds for one epoch ---
--- 0.4252965450286865 seconds for one epoch ---
--- 0.31830263137817383 seconds for one epoch ---
--- 0.444164514541626 seconds for one epoch ---
--- 0.32173824310302734 seconds for one epoch ---
--- 0.43996214866638184 seconds for one epoch ---
--- 0.31830525398254395 seconds for one epoch ---
--- 0.4369313716888428 seconds for one epoch ---
=========================
[[0.08058066]
 [0.06984821]
 [0.09955779]
 [0.05639383]
 [0.05498445]
 [0.16465293]
 [0.05925729]
 [0.05821673]
 [0.0547745 ]
 [0.23331936]
 [0.06784718]]
[[-1.0465753e+00]
 [-7.1924734e-01]
 [ 1.4697098e+00]
 [-1.0480211e-01]
 [ 1.5126292e-02]
 [-2.3473456e+00]
 [ 2.6698858e-01]
 [ 2.1079285e-01]
 [-1.1105891e-03]
 [-2.9327822e+00]
 [ 6.4653462e-01]]
--- 0.31158447265625 seconds for one epoch ---
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5091.6484375, (2293.8584, 0.25373328, 2625.2212, 2.5318916)
   validation loss 3660.859130859375, (3070.0464, 0.14122328, 418.35568, 2.5318916)
decoder loss ratio: 118938.926856, decoder SINDy loss  ratio: 0.903080
--- 0.25853896141052246 seconds for one epoch ---
--- 0.30103445053100586 seconds for one epoch ---
--- 0.4479656219482422 seconds for one epoch ---
--- 0.3044290542602539 seconds for one epoch ---
--- 0.44488000869750977 seconds for one epoch ---
--- 0.30192017555236816 seconds for one epoch ---
--- 0.45005106925964355 seconds for one epoch ---
--- 0.3153064250946045 seconds for one epoch ---
--- 0.4426436424255371 seconds for one epoch ---
--- 0.2924768924713135 seconds for one epoch ---
--- 0.4445781707763672 seconds for one epoch ---
--- 0.31484413146972656 seconds for one epoch ---
--- 0.43889307975769043 seconds for one epoch ---
--- 0.3091166019439697 seconds for one epoch ---
--- 0.46695494651794434 seconds for one epoch ---
--- 0.30989551544189453 seconds for one epoch ---
--- 0.43503260612487793 seconds for one epoch ---
--- 0.3014993667602539 seconds for one epoch ---
--- 0.4619472026824951 seconds for one epoch ---
--- 0.3061370849609375 seconds for one epoch ---
--- 0.4374260902404785 seconds for one epoch ---
--- 0.2968876361846924 seconds for one epoch ---
--- 0.4730799198150635 seconds for one epoch ---
--- 0.30510878562927246 seconds for one epoch ---
=========================
[[0.07802381]
 [0.06269627]
 [0.09934399]
 [0.04830911]
 [0.04771617]
 [0.15803054]
 [0.05150525]
 [0.05025721]
 [0.04717713]
 [0.2511677 ]
 [0.06090224]]
[[-1.1690005 ]
 [-0.73203486]
 [ 1.5959284 ]
 [-0.0768388 ]
 [ 0.03933976]
 [-2.348667  ]
 [ 0.25932124]
 [ 0.1916453 ]
 [-0.00408266]
 [-3.1008272 ]
 [ 0.66833574]]
--- 0.27237534523010254 seconds for one epoch ---
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4417.044921875, (2414.1482, 0.43312812, 1825.7573, 2.5319104)
   validation loss 2967.1357421875, (2428.3, 0.12173518, 362.0077, 2.5319104)
decoder loss ratio: 94076.559606, decoder SINDy loss  ratio: 0.781445
--- 0.3043348789215088 seconds for one epoch ---
--- 0.43380212783813477 seconds for one epoch ---
--- 0.3120598793029785 seconds for one epoch ---
--- 0.4610118865966797 seconds for one epoch ---
--- 0.3199927806854248 seconds for one epoch ---
--- 0.4594731330871582 seconds for one epoch ---
--- 0.3136332035064697 seconds for one epoch ---
--- 0.45241880416870117 seconds for one epoch ---
--- 0.3097803592681885 seconds for one epoch ---
--- 0.4695136547088623 seconds for one epoch ---
--- 0.3030383586883545 seconds for one epoch ---
--- 0.4592137336730957 seconds for one epoch ---
--- 0.319028377532959 seconds for one epoch ---
--- 0.458446741104126 seconds for one epoch ---
--- 0.3157639503479004 seconds for one epoch ---
--- 0.4492955207824707 seconds for one epoch ---
--- 0.3110167980194092 seconds for one epoch ---
--- 0.45458555221557617 seconds for one epoch ---
--- 0.31510138511657715 seconds for one epoch ---
--- 0.4482390880584717 seconds for one epoch ---
--- 0.3166046142578125 seconds for one epoch ---
--- 0.44939565658569336 seconds for one epoch ---
--- 0.31966471672058105 seconds for one epoch ---
--- 0.45236635208129883 seconds for one epoch ---
=========================
[[0.07815693]
 [0.05703901]
 [0.10024899]
 [0.04233861]
 [0.04205126]
 [0.1533426 ]
 [0.04542776]
 [0.04468252]
 [0.04146469]
 [0.27260458]
 [0.05626904]]
[[-1.2953081e+00]
 [-7.2877318e-01]
 [ 1.6976649e+00]
 [-5.6707539e-02]
 [ 3.8463488e-02]
 [-2.3517509e+00]
 [ 2.3560803e-01]
 [ 1.9505747e-01]
 [ 2.3883834e-04]
 [-3.2680304e+00]
 [ 7.0194703e-01]]
--- 0.2717158794403076 seconds for one epoch ---
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3553.619384765625, (1791.4277, 0.5798695, 1581.1821, 2.5319302)
   validation loss 1901.1636962890625, (1372.2365, 0.08869277, 348.40897, 2.5319302)
decoder loss ratio: 53162.822388, decoder SINDy loss  ratio: 0.752090
--- 0.25722217559814453 seconds for one epoch ---
--- 0.3116116523742676 seconds for one epoch ---
--- 0.46616125106811523 seconds for one epoch ---
--- 0.3036012649536133 seconds for one epoch ---
--- 0.45736122131347656 seconds for one epoch ---
--- 0.3161449432373047 seconds for one epoch ---
--- 0.44536781311035156 seconds for one epoch ---
--- 0.3110544681549072 seconds for one epoch ---
--- 0.4547128677368164 seconds for one epoch ---
--- 0.30429768562316895 seconds for one epoch ---
--- 0.44439172744750977 seconds for one epoch ---
--- 0.3231797218322754 seconds for one epoch ---
--- 0.4585916996002197 seconds for one epoch ---
--- 0.3063013553619385 seconds for one epoch ---
--- 0.4792492389678955 seconds for one epoch ---
--- 0.30773258209228516 seconds for one epoch ---
--- 0.466963529586792 seconds for one epoch ---
--- 0.31293773651123047 seconds for one epoch ---
--- 0.4674816131591797 seconds for one epoch ---
--- 0.31830644607543945 seconds for one epoch ---
--- 0.47206735610961914 seconds for one epoch ---
--- 0.3181009292602539 seconds for one epoch ---
--- 0.47191786766052246 seconds for one epoch ---
--- 0.30684542655944824 seconds for one epoch ---
=========================
[[0.08002228]
 [0.053649  ]
 [0.10133212]
 [0.03782789]
 [0.03697327]
 [0.14981109]
 [0.03977506]
 [0.03974443]
 [0.03654039]
 [0.29720736]
 [0.05167024]]
[[-1.4286830e+00]
 [-7.7763051e-01]
 [ 1.7838345e+00]
 [-8.2181439e-02]
 [ 2.8594645e-02]
 [-2.3598750e+00]
 [ 1.9521166e-01]
 [ 1.9351970e-01]
 [-4.0185533e-04]
 [-3.4387946e+00]
 [ 7.1074581e-01]]
--- 0.2295382022857666 seconds for one epoch ---
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5405.755859375, (2539.144, 0.2874249, 2682.8022, 2.5319514)
   validation loss 1313.5386962890625, (846.47833, 0.09930541, 283.43832, 2.5319514)
decoder loss ratio: 32794.040153, decoder SINDy loss  ratio: 0.611841
--- 0.3073694705963135 seconds for one epoch ---
--- 0.47631049156188965 seconds for one epoch ---
--- 0.32474350929260254 seconds for one epoch ---
--- 0.46935105323791504 seconds for one epoch ---
--- 0.3222074508666992 seconds for one epoch ---
--- 0.4780008792877197 seconds for one epoch ---
--- 0.31140637397766113 seconds for one epoch ---
--- 0.4781947135925293 seconds for one epoch ---
--- 0.32175588607788086 seconds for one epoch ---
--- 0.4789566993713379 seconds for one epoch ---
--- 0.3171117305755615 seconds for one epoch ---
--- 0.4808814525604248 seconds for one epoch ---
--- 0.3231821060180664 seconds for one epoch ---
--- 0.4788808822631836 seconds for one epoch ---
--- 0.32238006591796875 seconds for one epoch ---
--- 0.4741840362548828 seconds for one epoch ---
--- 0.3269693851470947 seconds for one epoch ---
--- 0.4857785701751709 seconds for one epoch ---
--- 0.3164193630218506 seconds for one epoch ---
--- 0.4730184078216553 seconds for one epoch ---
--- 0.3220803737640381 seconds for one epoch ---
--- 0.4686250686645508 seconds for one epoch ---
--- 0.42655181884765625 seconds for one epoch ---
--- 0.45493626594543457 seconds for one epoch ---
=========================
[[0.0838438 ]
 [0.05118598]
 [0.10551956]
 [0.03354294]
 [0.03339964]
 [0.14590684]
 [0.03571893]
 [0.0364459 ]
 [0.03295099]
 [0.32646406]
 [0.04854827]]
[[-1.5613455 ]
 [-0.8142272 ]
 [ 1.8904175 ]
 [-0.043381  ]
 [ 0.03429092]
 [-2.3532608 ]
 [ 0.17279133]
 [ 0.21281312]
 [ 0.00532967]
 [-3.6197047 ]
 [ 0.72743756]]
--- 0.277498722076416 seconds for one epoch ---
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4528.2744140625, (1919.6742, 5.3126864, 2415.8877, 2.5319753)
   validation loss 1375.5274658203125, (865.2705, 0.06085011, 322.7959, 2.5319753)
decoder loss ratio: 33522.081648, decoder SINDy loss  ratio: 0.696800
--- 0.26476311683654785 seconds for one epoch ---
--- 0.3151562213897705 seconds for one epoch ---
--- 0.4660942554473877 seconds for one epoch ---
--- 0.3263559341430664 seconds for one epoch ---
--- 0.5001411437988281 seconds for one epoch ---
--- 0.318636417388916 seconds for one epoch ---
--- 0.47632455825805664 seconds for one epoch ---
--- 0.30401039123535156 seconds for one epoch ---
--- 0.48810291290283203 seconds for one epoch ---
--- 0.310957670211792 seconds for one epoch ---
--- 0.47799062728881836 seconds for one epoch ---
--- 0.3156700134277344 seconds for one epoch ---
--- 0.4889249801635742 seconds for one epoch ---
--- 0.2953166961669922 seconds for one epoch ---
--- 0.47751355171203613 seconds for one epoch ---
--- 0.3031187057495117 seconds for one epoch ---
--- 0.47602343559265137 seconds for one epoch ---
--- 0.30525636672973633 seconds for one epoch ---
--- 0.4982450008392334 seconds for one epoch ---
--- 0.31981635093688965 seconds for one epoch ---
--- 0.46486902236938477 seconds for one epoch ---
--- 0.2981410026550293 seconds for one epoch ---
--- 0.4868040084838867 seconds for one epoch ---
--- 0.33101415634155273 seconds for one epoch ---
=========================
[[0.08977762]
 [0.04841863]
 [0.10938256]
 [0.03025851]
 [0.03045546]
 [0.14297792]
 [0.03202945]
 [0.03312169]
 [0.02972278]
 [0.36092427]
 [0.04551368]]
[[-1.7070013 ]
 [-0.8261985 ]
 [ 1.9793819 ]
 [-0.03848208]
 [ 0.0508642 ]
 [-2.3523245 ]
 [ 0.14506081]
 [ 0.20594372]
 [ 0.0040557 ]
 [-3.8166804 ]
 [ 0.7315977 ]]
--- 0.24829792976379395 seconds for one epoch ---
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3567.767333984375, (1402.3564, 0.6673061, 1974.5128, 2.5319998)
   validation loss 1216.13720703125, (708.89215, 0.0805564, 316.93375, 2.5319998)
decoder loss ratio: 27463.712616, decoder SINDy loss  ratio: 0.684146
--- 0.3100547790527344 seconds for one epoch ---
--- 0.4712791442871094 seconds for one epoch ---
--- 0.31739044189453125 seconds for one epoch ---
--- 0.5035877227783203 seconds for one epoch ---
--- 0.31966137886047363 seconds for one epoch ---
--- 0.4900522232055664 seconds for one epoch ---
--- 0.30856990814208984 seconds for one epoch ---
--- 0.47879886627197266 seconds for one epoch ---
--- 0.319854736328125 seconds for one epoch ---
--- 0.4918019771575928 seconds for one epoch ---
--- 0.32453060150146484 seconds for one epoch ---
--- 0.4947080612182617 seconds for one epoch ---
--- 0.30018043518066406 seconds for one epoch ---
--- 0.49103355407714844 seconds for one epoch ---
--- 0.30586719512939453 seconds for one epoch ---
--- 0.4933133125305176 seconds for one epoch ---
--- 0.30881834030151367 seconds for one epoch ---
--- 0.49349141120910645 seconds for one epoch ---
--- 0.3074331283569336 seconds for one epoch ---
--- 0.5186529159545898 seconds for one epoch ---
--- 0.3054208755493164 seconds for one epoch ---
--- 0.511693000793457 seconds for one epoch ---
--- 0.32195305824279785 seconds for one epoch ---
--- 0.49692726135253906 seconds for one epoch ---
=========================
[[0.09561998]
 [0.04637507]
 [0.11290967]
 [0.02738907]
 [0.02789096]
 [0.1407776 ]
 [0.02991671]
 [0.03047217]
 [0.02734675]
 [0.39066812]
 [0.04319458]]
[[-1.8257316 ]
 [-0.8357977 ]
 [ 2.0497756 ]
 [ 0.0082832 ]
 [ 0.04036416]
 [-2.3515234 ]
 [ 0.16097254]
 [ 0.19183387]
 [-0.00553412]
 [-3.9782798 ]
 [ 0.73297036]]
--- 0.28563523292541504 seconds for one epoch ---
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3005.293212890625, (1304.9156, 0.4572553, 1505.8457, 2.5320206)
   validation loss 1530.3367919921875, (1057.7245, 0.096808955, 278.44122, 2.5320206)
decoder loss ratio: 40978.082929, decoder SINDy loss  ratio: 0.601055
THRESHOLDING: 3 active coefficients
--- 0.4814600944519043 seconds for one epoch ---
--- 0.3184385299682617 seconds for one epoch ---
--- 0.49529504776000977 seconds for one epoch ---
--- 0.301952600479126 seconds for one epoch ---
--- 0.5151059627532959 seconds for one epoch ---
--- 0.3148477077484131 seconds for one epoch ---
--- 0.49553894996643066 seconds for one epoch ---
--- 0.31420087814331055 seconds for one epoch ---
--- 0.5113146305084229 seconds for one epoch ---
--- 0.3100554943084717 seconds for one epoch ---
--- 0.5056922435760498 seconds for one epoch ---
--- 0.30272889137268066 seconds for one epoch ---
--- 0.5267238616943359 seconds for one epoch ---
--- 0.32348179817199707 seconds for one epoch ---
--- 0.5063388347625732 seconds for one epoch ---
--- 0.31812095642089844 seconds for one epoch ---
--- 0.5143539905548096 seconds for one epoch ---
--- 0.3146681785583496 seconds for one epoch ---
--- 0.4918520450592041 seconds for one epoch ---
--- 0.3170037269592285 seconds for one epoch ---
--- 0.5091876983642578 seconds for one epoch ---
--- 0.31266260147094727 seconds for one epoch ---
--- 0.5013189315795898 seconds for one epoch ---
--- 0.3126559257507324 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.17325865]
 [0.        ]
 [0.        ]
 [0.08795835]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.39379963]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.6584964]
 [ 0.       ]
 [ 0.       ]
 [-1.7434003]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.0008636]
 [ 0.       ]]
--- 0.2608914375305176 seconds for one epoch ---
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4297.001953125, (1556.0243, 0.38292587, 2740.2651, 0.32972825)
   validation loss 926.490478515625, (644.76605, 0.08159127, 281.31308, 0.32972825)
decoder loss ratio: 24979.356227, decoder SINDy loss  ratio: 0.607254
--- 0.30025506019592285 seconds for one epoch ---
--- 0.50541090965271 seconds for one epoch ---
--- 0.31638455390930176 seconds for one epoch ---
--- 0.5115675926208496 seconds for one epoch ---
--- 0.3023958206176758 seconds for one epoch ---
--- 0.49343323707580566 seconds for one epoch ---
--- 0.3225271701812744 seconds for one epoch ---
--- 0.5069866180419922 seconds for one epoch ---
--- 0.31920433044433594 seconds for one epoch ---
--- 0.5343408584594727 seconds for one epoch ---
--- 0.3181946277618408 seconds for one epoch ---
--- 0.5179429054260254 seconds for one epoch ---
--- 0.32050371170043945 seconds for one epoch ---
--- 0.5144808292388916 seconds for one epoch ---
--- 0.3147454261779785 seconds for one epoch ---
--- 0.5109777450561523 seconds for one epoch ---
--- 0.31276679039001465 seconds for one epoch ---
--- 0.5215520858764648 seconds for one epoch ---
--- 0.3070640563964844 seconds for one epoch ---
--- 0.5314242839813232 seconds for one epoch ---
--- 0.28942394256591797 seconds for one epoch ---
--- 0.5159733295440674 seconds for one epoch ---
--- 0.29986023902893066 seconds for one epoch ---
--- 0.5024561882019043 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.19922931]
 [0.        ]
 [0.        ]
 [0.07798932]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.40894023]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.8694687]
 [ 0.       ]
 [ 0.       ]
 [-1.6108865]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.0819397]
 [ 0.       ]]
--- 0.29411888122558594 seconds for one epoch ---
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5112.18017578125, (2879.67, 1.4605719, 2230.7117, 0.3376687)
   validation loss 1145.3963623046875, (812.416, 0.07333972, 332.5693, 0.3376687)
decoder loss ratio: 31474.406862, decoder SINDy loss  ratio: 0.717898
--- 0.26522040367126465 seconds for one epoch ---
--- 0.31766462326049805 seconds for one epoch ---
--- 0.5031030178070068 seconds for one epoch ---
--- 0.31928110122680664 seconds for one epoch ---
--- 0.5069417953491211 seconds for one epoch ---
--- 0.3138129711151123 seconds for one epoch ---
--- 0.5088789463043213 seconds for one epoch ---
--- 0.31373095512390137 seconds for one epoch ---
--- 0.5153083801269531 seconds for one epoch ---
--- 0.31535959243774414 seconds for one epoch ---
--- 0.5159597396850586 seconds for one epoch ---
--- 0.30634474754333496 seconds for one epoch ---
--- 0.508298397064209 seconds for one epoch ---
--- 0.3187851905822754 seconds for one epoch ---
--- 0.5166895389556885 seconds for one epoch ---
--- 0.3051106929779053 seconds for one epoch ---
--- 0.5192294120788574 seconds for one epoch ---
--- 0.3168303966522217 seconds for one epoch ---
--- 0.5256397724151611 seconds for one epoch ---
--- 0.3210577964782715 seconds for one epoch ---
--- 0.541456937789917 seconds for one epoch ---
--- 0.31170105934143066 seconds for one epoch ---
--- 0.5375988483428955 seconds for one epoch ---
--- 0.32828187942504883 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.21164751]
 [0.        ]
 [0.        ]
 [0.07641981]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.4248621 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.9662747]
 [ 0.       ]
 [ 0.       ]
 [-1.6068594]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.165358 ]
 [ 0.       ]]
--- 0.24704885482788086 seconds for one epoch ---
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 8011.53564453125, (1715.4851, 1.6605219, 6294.045, 0.34519258)
   validation loss 1277.853759765625, (960.8574, 0.082402855, 316.5687, 0.34519258)
decoder loss ratio: 37225.284645, decoder SINDy loss  ratio: 0.683358
--- 0.31593990325927734 seconds for one epoch ---
--- 0.519200325012207 seconds for one epoch ---
--- 0.29915547370910645 seconds for one epoch ---
--- 0.5256903171539307 seconds for one epoch ---
--- 0.3139832019805908 seconds for one epoch ---
--- 0.5278346538543701 seconds for one epoch ---
--- 0.3089621067047119 seconds for one epoch ---
--- 0.5161659717559814 seconds for one epoch ---
--- 0.2979013919830322 seconds for one epoch ---
--- 0.5322434902191162 seconds for one epoch ---
--- 0.3163278102874756 seconds for one epoch ---
--- 0.521470308303833 seconds for one epoch ---
--- 0.29889440536499023 seconds for one epoch ---
--- 0.5454287528991699 seconds for one epoch ---
--- 0.31241369247436523 seconds for one epoch ---
--- 0.541593074798584 seconds for one epoch ---
--- 0.326007604598999 seconds for one epoch ---
--- 0.5328552722930908 seconds for one epoch ---
--- 0.31977415084838867 seconds for one epoch ---
--- 0.5420782566070557 seconds for one epoch ---
--- 0.3193497657775879 seconds for one epoch ---
--- 0.5384390354156494 seconds for one epoch ---
--- 0.30341076850891113 seconds for one epoch ---
--- 0.5143074989318848 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.22183722]
 [0.        ]
 [0.        ]
 [0.07385219]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.43655396]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.0418327]
 [ 0.       ]
 [ 0.       ]
 [-1.5808411]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.226166 ]
 [ 0.       ]]
--- 0.30472803115844727 seconds for one epoch ---
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3234.432373046875, (1526.2416, 0.9798782, 1706.8606, 0.35035354)
   validation loss 1398.81005859375, (1124.0928, 0.08346306, 274.28342, 0.35035354)
decoder loss ratio: 43549.305554, decoder SINDy loss  ratio: 0.592079
--- 0.2609593868255615 seconds for one epoch ---
--- 0.3053605556488037 seconds for one epoch ---
--- 0.5408978462219238 seconds for one epoch ---
--- 0.30866479873657227 seconds for one epoch ---
--- 0.5377485752105713 seconds for one epoch ---
--- 0.3237943649291992 seconds for one epoch ---
--- 0.5484812259674072 seconds for one epoch ---
--- 0.3093228340148926 seconds for one epoch ---
--- 0.5381059646606445 seconds for one epoch ---
--- 0.32411766052246094 seconds for one epoch ---
--- 0.5557985305786133 seconds for one epoch ---
--- 0.3238964080810547 seconds for one epoch ---
--- 0.5333685874938965 seconds for one epoch ---
--- 0.326617956161499 seconds for one epoch ---
--- 0.5513558387756348 seconds for one epoch ---
--- 0.32794713973999023 seconds for one epoch ---
--- 0.5486495494842529 seconds for one epoch ---
--- 0.3133885860443115 seconds for one epoch ---
--- 0.5595715045928955 seconds for one epoch ---
--- 0.3196451663970947 seconds for one epoch ---
--- 0.5415027141571045 seconds for one epoch ---
--- 0.31562256813049316 seconds for one epoch ---
--- 0.5531494617462158 seconds for one epoch ---
--- 0.3088216781616211 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.23080261]
 [0.        ]
 [0.        ]
 [0.07235211]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.44769508]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.1061623]
 [ 0.       ]
 [ 0.       ]
 [-1.5705836]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.283584 ]
 [ 0.       ]]
--- 0.266157865524292 seconds for one epoch ---
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4582.966796875, (1628.3351, 2.0421119, 2952.234, 0.35570398)
   validation loss 2572.8720703125, (2203.1526, 0.045698904, 369.31818, 0.35570398)
decoder loss ratio: 85353.956096, decoder SINDy loss  ratio: 0.797225
--- 0.3175375461578369 seconds for one epoch ---
--- 0.5407061576843262 seconds for one epoch ---
--- 0.32529592514038086 seconds for one epoch ---
--- 0.544562816619873 seconds for one epoch ---
--- 0.31139707565307617 seconds for one epoch ---
--- 0.5531928539276123 seconds for one epoch ---
--- 0.30910658836364746 seconds for one epoch ---
--- 0.545041561126709 seconds for one epoch ---
--- 0.3120708465576172 seconds for one epoch ---
--- 0.5549557209014893 seconds for one epoch ---
--- 0.31447792053222656 seconds for one epoch ---
--- 0.5490858554840088 seconds for one epoch ---
--- 0.3150599002838135 seconds for one epoch ---
--- 0.5553085803985596 seconds for one epoch ---
--- 0.30239391326904297 seconds for one epoch ---
--- 0.5699646472930908 seconds for one epoch ---
--- 0.30902695655822754 seconds for one epoch ---
--- 0.5672709941864014 seconds for one epoch ---
--- 0.33052825927734375 seconds for one epoch ---
--- 0.5515313148498535 seconds for one epoch ---
--- 0.2992987632751465 seconds for one epoch ---
--- 0.5721907615661621 seconds for one epoch ---
--- 0.31528711318969727 seconds for one epoch ---
--- 0.5701675415039062 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.23498943]
 [0.        ]
 [0.        ]
 [0.07211354]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.45874342]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.1369343]
 [ 0.       ]
 [ 0.       ]
 [-1.5779313]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.3396854]
 [ 0.       ]]
--- 0.2888484001159668 seconds for one epoch ---
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3652.01025390625, (1684.7018, 0.47623694, 1966.4723, 0.35975373)
   validation loss 1641.00341796875, (1366.9952, 0.121478856, 273.52695, 0.35975373)
decoder loss ratio: 52959.768777, decoder SINDy loss  ratio: 0.590446
--- 0.2721233367919922 seconds for one epoch ---
--- 0.3136916160583496 seconds for one epoch ---
--- 0.5536067485809326 seconds for one epoch ---
--- 0.31301212310791016 seconds for one epoch ---
--- 0.5578787326812744 seconds for one epoch ---
--- 0.31743788719177246 seconds for one epoch ---
--- 0.5713176727294922 seconds for one epoch ---
--- 0.30105137825012207 seconds for one epoch ---
--- 0.5582077503204346 seconds for one epoch ---
--- 0.31726932525634766 seconds for one epoch ---
--- 0.5509164333343506 seconds for one epoch ---
--- 0.3027932643890381 seconds for one epoch ---
--- 0.5676991939544678 seconds for one epoch ---
--- 0.30909085273742676 seconds for one epoch ---
--- 0.5608510971069336 seconds for one epoch ---
--- 0.30637431144714355 seconds for one epoch ---
--- 0.5738050937652588 seconds for one epoch ---
--- 0.32135748863220215 seconds for one epoch ---
--- 0.569657564163208 seconds for one epoch ---
--- 0.3199656009674072 seconds for one epoch ---
--- 0.5646224021911621 seconds for one epoch ---
--- 0.3080878257751465 seconds for one epoch ---
--- 0.5625927448272705 seconds for one epoch ---
--- 0.3127012252807617 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.24361135]
 [0.        ]
 [0.        ]
 [0.07039014]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.4702198 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.1949184]
 [ 0.       ]
 [ 0.       ]
 [-1.5590085]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.3975215]
 [ 0.       ]]
--- 0.2523360252380371 seconds for one epoch ---
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4748.13720703125, (2435.7964, 0.6946886, 2311.2827, 0.3638441)
   validation loss 1309.850341796875, (993.0297, 0.11261528, 316.34412, 0.3638441)
decoder loss ratio: 38471.695488, decoder SINDy loss  ratio: 0.682873
--- 0.44136619567871094 seconds for one epoch ---
--- 0.5686452388763428 seconds for one epoch ---
--- 0.30133676528930664 seconds for one epoch ---
--- 0.572739839553833 seconds for one epoch ---
--- 0.3154258728027344 seconds for one epoch ---
--- 0.5754601955413818 seconds for one epoch ---
--- 0.30786824226379395 seconds for one epoch ---
--- 0.5590002536773682 seconds for one epoch ---
--- 0.31075000762939453 seconds for one epoch ---
--- 0.5710010528564453 seconds for one epoch ---
--- 0.29706382751464844 seconds for one epoch ---
--- 0.5663783550262451 seconds for one epoch ---
--- 0.3205292224884033 seconds for one epoch ---
--- 0.5694108009338379 seconds for one epoch ---
--- 0.2942991256713867 seconds for one epoch ---
--- 0.5589404106140137 seconds for one epoch ---
--- 0.303530216217041 seconds for one epoch ---
--- 0.5718698501586914 seconds for one epoch ---
--- 0.312908411026001 seconds for one epoch ---
--- 0.5779397487640381 seconds for one epoch ---
--- 0.309955358505249 seconds for one epoch ---
--- 0.5533735752105713 seconds for one epoch ---
--- 0.31120753288269043 seconds for one epoch ---
--- 0.5668528079986572 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2434137 ]
 [0.        ]
 [0.        ]
 [0.07142992]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.4809008 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.1960263]
 [ 0.       ]
 [ 0.       ]
 [-1.5842478]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.4509926]
 [ 0.       ]]
--- 0.29172825813293457 seconds for one epoch ---
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3017.44189453125, (1300.2026, 0.32793143, 1716.5444, 0.36696157)
   validation loss 1090.8477783203125, (792.3491, 0.065544896, 298.0662, 0.36696157)
decoder loss ratio: 30696.980530, decoder SINDy loss  ratio: 0.643418
--- 0.27413392066955566 seconds for one epoch ---
--- 0.32029128074645996 seconds for one epoch ---
--- 0.5668127536773682 seconds for one epoch ---
--- 0.3083195686340332 seconds for one epoch ---
--- 0.5801107883453369 seconds for one epoch ---
--- 0.3194572925567627 seconds for one epoch ---
--- 0.5864822864532471 seconds for one epoch ---
--- 0.30621957778930664 seconds for one epoch ---
--- 0.5453851222991943 seconds for one epoch ---
--- 0.2869880199432373 seconds for one epoch ---
--- 0.5919003486633301 seconds for one epoch ---
--- 0.31023454666137695 seconds for one epoch ---
--- 0.5646038055419922 seconds for one epoch ---
--- 0.3042328357696533 seconds for one epoch ---
--- 0.5781002044677734 seconds for one epoch ---
--- 0.3002934455871582 seconds for one epoch ---
--- 0.5622754096984863 seconds for one epoch ---
--- 0.30953168869018555 seconds for one epoch ---
--- 0.5793061256408691 seconds for one epoch ---
--- 0.3214089870452881 seconds for one epoch ---
--- 0.5844738483428955 seconds for one epoch ---
--- 0.3064854145050049 seconds for one epoch ---
--- 0.576941728591919 seconds for one epoch ---
--- 0.30150842666625977 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.24433392]
 [0.        ]
 [0.        ]
 [0.07224703]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.4867279 ]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 3.203892]
 [ 0.      ]
 [ 0.      ]
 [-1.604563]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-4.480592]
 [ 0.      ]]
--- 0.25309085845947266 seconds for one epoch ---
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4050.0634765625, (1744.7855, 1.2144963, 2303.694, 0.36939248)
   validation loss 901.5187377929688, (561.28467, 0.0991268, 339.76556, 0.36939248)
decoder loss ratio: 21745.142470, decoder SINDy loss  ratio: 0.733432
--- 0.31674742698669434 seconds for one epoch ---
--- 0.589982271194458 seconds for one epoch ---
--- 0.31142759323120117 seconds for one epoch ---
--- 0.5802586078643799 seconds for one epoch ---
--- 0.3021962642669678 seconds for one epoch ---
--- 0.5908150672912598 seconds for one epoch ---
--- 0.3003654479980469 seconds for one epoch ---
--- 0.6074559688568115 seconds for one epoch ---
--- 0.31029224395751953 seconds for one epoch ---
--- 0.5990710258483887 seconds for one epoch ---
--- 0.3107123374938965 seconds for one epoch ---
--- 0.5936923027038574 seconds for one epoch ---
--- 0.31711673736572266 seconds for one epoch ---
--- 0.5943236351013184 seconds for one epoch ---
--- 0.3180224895477295 seconds for one epoch ---
--- 0.5912439823150635 seconds for one epoch ---
--- 0.31271910667419434 seconds for one epoch ---
--- 0.6042051315307617 seconds for one epoch ---
--- 0.307722806930542 seconds for one epoch ---
--- 0.6141724586486816 seconds for one epoch ---
--- 0.3083045482635498 seconds for one epoch ---
--- 0.5822422504425049 seconds for one epoch ---
--- 0.3148820400238037 seconds for one epoch ---
--- 0.5850460529327393 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2537583 ]
 [0.        ]
 [0.        ]
 [0.07004116]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.49313325]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.2637064]
 [ 0.       ]
 [ 0.       ]
 [-1.5731665]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.512758 ]
 [ 0.       ]]
--- 0.3030228614807129 seconds for one epoch ---
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2685.435791015625, (1210.2587, 2.1455476, 1472.6592, 0.37241513)
   validation loss 899.696044921875, (616.9631, 0.11934135, 282.2412, 0.37241513)
decoder loss ratio: 23902.220571, decoder SINDy loss  ratio: 0.609257
--- 0.2745485305786133 seconds for one epoch ---
--- 0.30799078941345215 seconds for one epoch ---
--- 0.5886659622192383 seconds for one epoch ---
--- 0.3169517517089844 seconds for one epoch ---
--- 0.589087724685669 seconds for one epoch ---
--- 0.3175976276397705 seconds for one epoch ---
--- 0.5826747417449951 seconds for one epoch ---
--- 0.3030829429626465 seconds for one epoch ---
--- 0.6008331775665283 seconds for one epoch ---
--- 0.3099243640899658 seconds for one epoch ---
--- 0.5999386310577393 seconds for one epoch ---
--- 0.308330774307251 seconds for one epoch ---
--- 0.6106152534484863 seconds for one epoch ---
--- 0.31322312355041504 seconds for one epoch ---
--- 0.5964434146881104 seconds for one epoch ---
--- 0.30471301078796387 seconds for one epoch ---
--- 0.5885865688323975 seconds for one epoch ---
--- 0.3063318729400635 seconds for one epoch ---
--- 0.598717451095581 seconds for one epoch ---
--- 0.31586527824401855 seconds for one epoch ---
--- 0.6234126091003418 seconds for one epoch ---
--- 0.3090698719024658 seconds for one epoch ---
--- 0.6439244747161865 seconds for one epoch ---
--- 0.3067035675048828 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2526064 ]
 [0.        ]
 [0.        ]
 [0.07049594]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.50337464]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.2580578]
 [ 0.       ]
 [ 0.       ]
 [-1.5855112]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.5636463]
 [ 0.       ]]
--- 0.25743627548217773 seconds for one epoch ---
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4530.287109375, (2239.8545, 1.8508531, 2288.2063, 0.37536022)
   validation loss 1832.762939453125, (1449.9792, 0.12754528, 382.28073, 0.37536022)
decoder loss ratio: 56174.713344, decoder SINDy loss  ratio: 0.825207
--- 0.3147406578063965 seconds for one epoch ---
--- 0.5856502056121826 seconds for one epoch ---
--- 0.31923723220825195 seconds for one epoch ---
--- 0.5876121520996094 seconds for one epoch ---
--- 0.29135751724243164 seconds for one epoch ---
--- 0.5967388153076172 seconds for one epoch ---
--- 0.32366180419921875 seconds for one epoch ---
--- 0.6292297840118408 seconds for one epoch ---
--- 0.3148844242095947 seconds for one epoch ---
--- 0.620107889175415 seconds for one epoch ---
--- 0.309767484664917 seconds for one epoch ---
--- 0.6046569347381592 seconds for one epoch ---
--- 0.31798529624938965 seconds for one epoch ---
--- 0.6150290966033936 seconds for one epoch ---
--- 0.31482553482055664 seconds for one epoch ---
--- 0.6324207782745361 seconds for one epoch ---
--- 0.30666565895080566 seconds for one epoch ---
--- 0.623682975769043 seconds for one epoch ---
--- 0.31433844566345215 seconds for one epoch ---
--- 0.6215336322784424 seconds for one epoch ---
--- 0.31925249099731445 seconds for one epoch ---
--- 0.6424825191497803 seconds for one epoch ---
--- 0.32070064544677734 seconds for one epoch ---
--- 0.6266493797302246 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.25816154]
 [0.        ]
 [0.        ]
 [0.0687876 ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.511564  ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.2928798]
 [ 0.       ]
 [ 0.       ]
 [-1.5604823]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.6043916]
 [ 0.       ]]
--- 0.3000907897949219 seconds for one epoch ---
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5893.3896484375, (2953.4211, 1.344988, 2938.2456, 0.37800917)
   validation loss 1264.1397705078125, (891.8486, 0.048582483, 371.86453, 0.37800917)
decoder loss ratio: 34551.761988, decoder SINDy loss  ratio: 0.802722
--- 0.2452716827392578 seconds for one epoch ---
--- 0.3126349449157715 seconds for one epoch ---
--- 0.6359541416168213 seconds for one epoch ---
--- 0.3024172782897949 seconds for one epoch ---
--- 0.640012264251709 seconds for one epoch ---
--- 0.30255866050720215 seconds for one epoch ---
--- 0.6401901245117188 seconds for one epoch ---
--- 0.32155370712280273 seconds for one epoch ---
--- 0.6302809715270996 seconds for one epoch ---
--- 0.30352354049682617 seconds for one epoch ---
--- 0.635749340057373 seconds for one epoch ---
--- 0.3140387535095215 seconds for one epoch ---
--- 0.647702693939209 seconds for one epoch ---
--- 0.29674458503723145 seconds for one epoch ---
--- 0.6177606582641602 seconds for one epoch ---
--- 0.30912065505981445 seconds for one epoch ---
--- 0.6289572715759277 seconds for one epoch ---
--- 0.31027889251708984 seconds for one epoch ---
--- 0.6416506767272949 seconds for one epoch ---
--- 0.30225205421447754 seconds for one epoch ---
--- 0.6324634552001953 seconds for one epoch ---
--- 0.3149986267089844 seconds for one epoch ---
--- 0.6302716732025146 seconds for one epoch ---
--- 0.32145190238952637 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2592642 ]
 [0.        ]
 [0.        ]
 [0.06922852]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.523281  ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.3004715]
 [ 0.       ]
 [ 0.       ]
 [-1.5712576]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.6625643]
 [ 0.       ]]
--- 0.25487351417541504 seconds for one epoch ---
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3127.174072265625, (1466.6512, 3.932938, 1656.2091, 0.38069323)
   validation loss 1176.8997802734375, (862.5418, 0.084403574, 313.89285, 0.38069323)
decoder loss ratio: 33416.367122, decoder SINDy loss  ratio: 0.677582
--- 0.30997252464294434 seconds for one epoch ---
--- 0.6461682319641113 seconds for one epoch ---
--- 0.30067896842956543 seconds for one epoch ---
--- 0.6562337875366211 seconds for one epoch ---
--- 0.3074784278869629 seconds for one epoch ---
--- 0.6232151985168457 seconds for one epoch ---
--- 0.3119373321533203 seconds for one epoch ---
--- 0.6349785327911377 seconds for one epoch ---
--- 0.30140018463134766 seconds for one epoch ---
--- 0.611868143081665 seconds for one epoch ---
--- 0.3039398193359375 seconds for one epoch ---
--- 0.621274471282959 seconds for one epoch ---
--- 0.3126108646392822 seconds for one epoch ---
--- 0.6369764804840088 seconds for one epoch ---
--- 0.30437397956848145 seconds for one epoch ---
--- 0.6223437786102295 seconds for one epoch ---
--- 0.30628538131713867 seconds for one epoch ---
--- 0.6338169574737549 seconds for one epoch ---
--- 0.30527544021606445 seconds for one epoch ---
--- 0.6374950408935547 seconds for one epoch ---
--- 0.3128926753997803 seconds for one epoch ---
--- 0.6352167129516602 seconds for one epoch ---
--- 0.3247969150543213 seconds for one epoch ---
--- 0.6248655319213867 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2558217 ]
 [0.        ]
 [0.        ]
 [0.06962307]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5325496 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.2804108]
 [ 0.       ]
 [ 0.       ]
 [-1.5804167]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.7087593]
 [ 0.       ]]
--- 0.2867894172668457 seconds for one epoch ---
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3739.500244140625, (1414.2401, 3.2879655, 2321.59, 0.38217902)
   validation loss 1021.4652099609375, (717.8473, 0.105825074, 303.1299, 0.38217902)
decoder loss ratio: 27810.650254, decoder SINDy loss  ratio: 0.654349
--- 0.26301074028015137 seconds for one epoch ---
--- 0.3201589584350586 seconds for one epoch ---
--- 0.6368129253387451 seconds for one epoch ---
--- 0.3012988567352295 seconds for one epoch ---
--- 0.6289491653442383 seconds for one epoch ---
--- 0.3033938407897949 seconds for one epoch ---
--- 0.6483955383300781 seconds for one epoch ---
--- 0.31418442726135254 seconds for one epoch ---
--- 0.6463136672973633 seconds for one epoch ---
--- 0.2926516532897949 seconds for one epoch ---
--- 0.6614992618560791 seconds for one epoch ---
--- 0.3254268169403076 seconds for one epoch ---
--- 0.6480183601379395 seconds for one epoch ---
--- 0.31235432624816895 seconds for one epoch ---
--- 0.6518998146057129 seconds for one epoch ---
--- 0.3038804531097412 seconds for one epoch ---
--- 0.6378848552703857 seconds for one epoch ---
--- 0.31284308433532715 seconds for one epoch ---
--- 0.6292622089385986 seconds for one epoch ---
--- 0.3062441349029541 seconds for one epoch ---
--- 0.6464529037475586 seconds for one epoch ---
--- 0.31269359588623047 seconds for one epoch ---
--- 0.6407651901245117 seconds for one epoch ---
--- 0.31899189949035645 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.25436822]
 [0.        ]
 [0.        ]
 [0.06802094]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.53663105]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.2722592]
 [ 0.       ]
 [ 0.       ]
 [-1.555753 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.7293386]
 [ 0.       ]]
--- 0.24660992622375488 seconds for one epoch ---
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4302.8876953125, (1775.4746, 1.6498601, 2525.3816, 0.38183513)
   validation loss 855.990478515625, (563.47363, 0.060620274, 292.07443, 0.38183513)
decoder loss ratio: 21829.946768, decoder SINDy loss  ratio: 0.630484
--- 0.2893519401550293 seconds for one epoch ---
--- 0.6364543437957764 seconds for one epoch ---
--- 0.30179762840270996 seconds for one epoch ---
--- 0.6488652229309082 seconds for one epoch ---
--- 0.31153225898742676 seconds for one epoch ---
--- 0.6594219207763672 seconds for one epoch ---
--- 0.3206799030303955 seconds for one epoch ---
--- 0.6716341972351074 seconds for one epoch ---
--- 0.3183727264404297 seconds for one epoch ---
--- 0.6742732524871826 seconds for one epoch ---
--- 0.31400632858276367 seconds for one epoch ---
--- 0.6663012504577637 seconds for one epoch ---
--- 0.30824828147888184 seconds for one epoch ---
--- 0.6501483917236328 seconds for one epoch ---
--- 0.30831241607666016 seconds for one epoch ---
--- 0.6701188087463379 seconds for one epoch ---
--- 0.3172476291656494 seconds for one epoch ---
--- 0.6636087894439697 seconds for one epoch ---
--- 0.32409214973449707 seconds for one epoch ---
--- 0.6523568630218506 seconds for one epoch ---
--- 0.32857799530029297 seconds for one epoch ---
--- 0.6564877033233643 seconds for one epoch ---
--- 0.31580424308776855 seconds for one epoch ---
--- 0.6839039325714111 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2516534 ]
 [0.        ]
 [0.        ]
 [0.06756973]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.54251873]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.2562237]
 [ 0.       ]
 [ 0.       ]
 [-1.549888 ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.7588716]
 [ 0.       ]]
--- 0.2993292808532715 seconds for one epoch ---
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3430.376953125, (1061.7045, 1.4847541, 2366.8054, 0.38238415)
   validation loss 1029.944091796875, (757.58057, 0.16575435, 271.8154, 0.38238415)
decoder loss ratio: 29349.986360, decoder SINDy loss  ratio: 0.586752
--- 0.24817633628845215 seconds for one epoch ---
--- 0.3039231300354004 seconds for one epoch ---
--- 0.6715645790100098 seconds for one epoch ---
--- 0.3109736442565918 seconds for one epoch ---
--- 0.6701292991638184 seconds for one epoch ---
--- 0.3409569263458252 seconds for one epoch ---
--- 0.6710550785064697 seconds for one epoch ---
--- 0.30675649642944336 seconds for one epoch ---
--- 0.6503875255584717 seconds for one epoch ---
--- 0.30375123023986816 seconds for one epoch ---
--- 0.6783838272094727 seconds for one epoch ---
--- 0.31155848503112793 seconds for one epoch ---
--- 0.6565442085266113 seconds for one epoch ---
--- 0.3127152919769287 seconds for one epoch ---
--- 0.6602706909179688 seconds for one epoch ---
--- 0.3104686737060547 seconds for one epoch ---
--- 0.6884331703186035 seconds for one epoch ---
--- 0.32021093368530273 seconds for one epoch ---
--- 0.6769239902496338 seconds for one epoch ---
--- 0.3166372776031494 seconds for one epoch ---
--- 0.6700258255004883 seconds for one epoch ---
--- 0.31590867042541504 seconds for one epoch ---
--- 0.6729252338409424 seconds for one epoch ---
--- 0.3091166019439697 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.2488529 ]
 [0.        ]
 [0.        ]
 [0.066876  ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.55678827]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.239519 ]
 [ 0.       ]
 [ 0.       ]
 [-1.5396711]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.8304734]
 [ 0.       ]]
--- 0.26322412490844727 seconds for one epoch ---
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4399.306640625, (1587.0446, 0.81986636, 2811.0583, 0.38383967)
   validation loss 1238.68603515625, (963.22455, 0.1098822, 274.96777, 0.38383967)
decoder loss ratio: 37316.991234, decoder SINDy loss  ratio: 0.593557
--- 0.3123641014099121 seconds for one epoch ---
--- 0.678494930267334 seconds for one epoch ---
--- 0.32021594047546387 seconds for one epoch ---
--- 0.6696679592132568 seconds for one epoch ---
--- 0.3112969398498535 seconds for one epoch ---
--- 0.6808788776397705 seconds for one epoch ---
--- 0.3231058120727539 seconds for one epoch ---
--- 0.6648721694946289 seconds for one epoch ---
--- 0.3170430660247803 seconds for one epoch ---
--- 0.6647205352783203 seconds for one epoch ---
--- 0.3178846836090088 seconds for one epoch ---
--- 0.6715328693389893 seconds for one epoch ---
--- 0.30594706535339355 seconds for one epoch ---
--- 0.6662838459014893 seconds for one epoch ---
--- 0.3164052963256836 seconds for one epoch ---
--- 0.6800310611724854 seconds for one epoch ---
--- 0.3110079765319824 seconds for one epoch ---
--- 0.6819684505462646 seconds for one epoch ---
--- 0.3158876895904541 seconds for one epoch ---
--- 0.68896484375 seconds for one epoch ---
--- 0.31345057487487793 seconds for one epoch ---
--- 0.6720726490020752 seconds for one epoch ---
--- 0.31241369247436523 seconds for one epoch ---
--- 0.6765265464782715 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.24572174]
 [0.        ]
 [0.        ]
 [0.06654305]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.56477034]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.220549 ]
 [ 0.       ]
 [ 0.       ]
 [-1.5352422]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.870881 ]
 [ 0.       ]]
--- 0.291393518447876 seconds for one epoch ---
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5958.310546875, (1974.842, 2.1260629, 3980.9587, 0.38392606)
   validation loss 1247.8446044921875, (918.3414, 0.14068335, 328.97864, 0.38392606)
decoder loss ratio: 35578.138970, decoder SINDy loss  ratio: 0.710147
--- 0.2696058750152588 seconds for one epoch ---
--- 0.315687894821167 seconds for one epoch ---
--- 0.6800110340118408 seconds for one epoch ---
--- 0.31269001960754395 seconds for one epoch ---
--- 0.6863040924072266 seconds for one epoch ---
--- 0.3099343776702881 seconds for one epoch ---
--- 0.6869089603424072 seconds for one epoch ---
--- 0.31100893020629883 seconds for one epoch ---
--- 0.7015211582183838 seconds for one epoch ---
--- 0.30875515937805176 seconds for one epoch ---
--- 0.6935470104217529 seconds for one epoch ---
--- 0.47703123092651367 seconds for one epoch ---
--- 0.6633358001708984 seconds for one epoch ---
--- 0.3104417324066162 seconds for one epoch ---
--- 0.6796140670776367 seconds for one epoch ---
--- 0.3027019500732422 seconds for one epoch ---
--- 0.6843438148498535 seconds for one epoch ---
--- 0.3137967586517334 seconds for one epoch ---
--- 0.6832015514373779 seconds for one epoch ---
--- 0.3146858215332031 seconds for one epoch ---
--- 0.6834354400634766 seconds for one epoch ---
--- 0.3129899501800537 seconds for one epoch ---
--- 0.6853640079498291 seconds for one epoch ---
--- 0.3137814998626709 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.24473915]
 [0.        ]
 [0.        ]
 [0.06567378]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5706896 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.2147982]
 [ 0.       ]
 [ 0.       ]
 [-1.5213584]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.901035 ]
 [ 0.       ]]
--- 0.26651549339294434 seconds for one epoch ---
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2994.5029296875, (1399.3018, 0.93590045, 1593.8817, 0.38354936)
   validation loss 1066.0289306640625, (773.93585, 0.12809297, 291.58145, 0.38354936)
decoder loss ratio: 29983.618520, decoder SINDy loss  ratio: 0.629420
--- 0.316417932510376 seconds for one epoch ---
--- 0.6799414157867432 seconds for one epoch ---
--- 0.31466031074523926 seconds for one epoch ---
--- 0.6955349445343018 seconds for one epoch ---
--- 0.3171567916870117 seconds for one epoch ---
--- 0.7014927864074707 seconds for one epoch ---
--- 0.30876779556274414 seconds for one epoch ---
--- 0.6876969337463379 seconds for one epoch ---
--- 0.32402849197387695 seconds for one epoch ---
--- 0.7082493305206299 seconds for one epoch ---
--- 0.31299734115600586 seconds for one epoch ---
--- 0.6890769004821777 seconds for one epoch ---
--- 0.3154573440551758 seconds for one epoch ---
--- 0.7116081714630127 seconds for one epoch ---
--- 0.32679176330566406 seconds for one epoch ---
--- 0.7134158611297607 seconds for one epoch ---
--- 0.31260037422180176 seconds for one epoch ---
--- 0.7087035179138184 seconds for one epoch ---
--- 0.3162996768951416 seconds for one epoch ---
--- 0.6991138458251953 seconds for one epoch ---
--- 0.3018474578857422 seconds for one epoch ---
--- 0.713979959487915 seconds for one epoch ---
--- 0.3118288516998291 seconds for one epoch ---
--- 0.696540117263794 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.24514759]
 [0.        ]
 [0.        ]
 [0.06490406]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.5819573 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 3.2176092]
 [-0.       ]
 [ 0.       ]
 [-1.5088129]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-4.958663 ]
 [ 0.       ]]
--- 0.3003535270690918 seconds for one epoch ---
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4193.33154296875, (2072.385, 1.772733, 2118.7896, 0.38436422)
   validation loss 985.3839721679688, (636.6717, 0.2010465, 348.12692, 0.38436422)
decoder loss ratio: 24665.766655, decoder SINDy loss  ratio: 0.751481
THRESHOLDING: 2 active coefficients
--- 0.6911375522613525 seconds for one epoch ---
--- 0.3105013370513916 seconds for one epoch ---
--- 0.700979471206665 seconds for one epoch ---
--- 0.3201611042022705 seconds for one epoch ---
--- 0.7063744068145752 seconds for one epoch ---
--- 0.3151834011077881 seconds for one epoch ---
--- 0.6969327926635742 seconds for one epoch ---
--- 0.32079553604125977 seconds for one epoch ---
--- 0.721372127532959 seconds for one epoch ---
--- 0.31305503845214844 seconds for one epoch ---
--- 0.7033407688140869 seconds for one epoch ---
--- 0.322690486907959 seconds for one epoch ---
--- 0.7198469638824463 seconds for one epoch ---
--- 0.31174659729003906 seconds for one epoch ---
--- 0.7103667259216309 seconds for one epoch ---
--- 0.3201422691345215 seconds for one epoch ---
--- 0.7094013690948486 seconds for one epoch ---
--- 0.31907033920288086 seconds for one epoch ---
--- 0.7371718883514404 seconds for one epoch ---
--- 0.31532883644104004 seconds for one epoch ---
--- 0.7254126071929932 seconds for one epoch ---
--- 0.3201446533203125 seconds for one epoch ---
--- 0.7354929447174072 seconds for one epoch ---
--- 0.28433823585510254 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.12283569]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.6418593 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 2.2714956]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.276497 ]
 [ 0.       ]]
--- 0.2569425106048584 seconds for one epoch ---
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2386.5791015625, (833.36566, 1.4643954, 1551.4756, 0.2735295)
   validation loss 1035.5836181640625, (752.6031, 0.25767097, 282.44925, 0.2735295)
decoder loss ratio: 29157.150220, decoder SINDy loss  ratio: 0.609706
--- 0.3054671287536621 seconds for one epoch ---
--- 0.6957924365997314 seconds for one epoch ---
--- 0.3155937194824219 seconds for one epoch ---
--- 0.7115182876586914 seconds for one epoch ---
--- 0.3299860954284668 seconds for one epoch ---
--- 0.6912541389465332 seconds for one epoch ---
--- 0.30048274993896484 seconds for one epoch ---
--- 0.7386646270751953 seconds for one epoch ---
--- 0.3191509246826172 seconds for one epoch ---
--- 0.6961750984191895 seconds for one epoch ---
--- 0.3170278072357178 seconds for one epoch ---
--- 0.6975629329681396 seconds for one epoch ---
--- 0.3172636032104492 seconds for one epoch ---
--- 0.7125487327575684 seconds for one epoch ---
--- 0.317457914352417 seconds for one epoch ---
--- 0.7368595600128174 seconds for one epoch ---
--- 0.3259875774383545 seconds for one epoch ---
--- 0.7220046520233154 seconds for one epoch ---
--- 0.31803369522094727 seconds for one epoch ---
--- 0.7167842388153076 seconds for one epoch ---
--- 0.31615710258483887 seconds for one epoch ---
--- 0.7274456024169922 seconds for one epoch ---
--- 0.3160066604614258 seconds for one epoch ---
--- 0.7102138996124268 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.07343475]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.70103055]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 1.6525217]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-5.6202917]
 [ 0.       ]]
--- 0.2994875907897949 seconds for one epoch ---
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2393.010498046875, (1038.9326, 2.5220056, 1351.2888, 0.26697296)
   validation loss 737.176025390625, (466.65723, 0.21377315, 270.0381, 0.26697296)
decoder loss ratio: 18079.111110, decoder SINDy loss  ratio: 0.582915
--- 0.2639439105987549 seconds for one epoch ---
--- 0.31816554069519043 seconds for one epoch ---
--- 0.7262740135192871 seconds for one epoch ---
--- 0.3191702365875244 seconds for one epoch ---
--- 0.7063875198364258 seconds for one epoch ---
--- 0.32778382301330566 seconds for one epoch ---
--- 0.6975510120391846 seconds for one epoch ---
--- 0.3190493583679199 seconds for one epoch ---
--- 0.7331349849700928 seconds for one epoch ---
--- 0.30504512786865234 seconds for one epoch ---
--- 0.7320346832275391 seconds for one epoch ---
--- 0.3183434009552002 seconds for one epoch ---
--- 0.7590723037719727 seconds for one epoch ---
--- 0.3216526508331299 seconds for one epoch ---
--- 0.721489429473877 seconds for one epoch ---
--- 0.31353139877319336 seconds for one epoch ---
--- 0.7336738109588623 seconds for one epoch ---
--- 0.30627989768981934 seconds for one epoch ---
--- 0.7488999366760254 seconds for one epoch ---
--- 0.32117557525634766 seconds for one epoch ---
--- 0.7573974132537842 seconds for one epoch ---
--- 0.31481289863586426 seconds for one epoch ---
--- 0.7171468734741211 seconds for one epoch ---
--- 0.3129138946533203 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.04934825]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.75722724]
 [0.        ]]
[[-0.      ]
 [-0.      ]
 [ 1.202643]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [ 0.      ]
 [ 0.      ]
 [-0.      ]
 [-5.992038]
 [ 0.      ]]
--- 0.2708165645599365 seconds for one epoch ---
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2462.156005859375, (1143.773, 0.7531497, 1317.3633, 0.26666185)
   validation loss 1137.839111328125, (837.63403, 0.22229631, 299.71613, 0.26666185)
decoder loss ratio: 32451.396643, decoder SINDy loss  ratio: 0.646979
--- 0.3140900135040283 seconds for one epoch ---
--- 0.7484610080718994 seconds for one epoch ---
--- 0.31619834899902344 seconds for one epoch ---
--- 0.7347278594970703 seconds for one epoch ---
--- 0.31575870513916016 seconds for one epoch ---
--- 0.7382807731628418 seconds for one epoch ---
--- 0.3254661560058594 seconds for one epoch ---
--- 0.7654805183410645 seconds for one epoch ---
--- 0.3191251754760742 seconds for one epoch ---
--- 0.7528121471405029 seconds for one epoch ---
--- 0.3281514644622803 seconds for one epoch ---
--- 0.7572777271270752 seconds for one epoch ---
--- 0.31418442726135254 seconds for one epoch ---
--- 0.7217302322387695 seconds for one epoch ---
--- 0.3200254440307617 seconds for one epoch ---
--- 0.7516705989837646 seconds for one epoch ---
--- 0.3224811553955078 seconds for one epoch ---
--- 0.7133734226226807 seconds for one epoch ---
--- 0.30559396743774414 seconds for one epoch ---
--- 0.7411959171295166 seconds for one epoch ---
--- 0.31786155700683594 seconds for one epoch ---
--- 0.7570364475250244 seconds for one epoch ---
--- 0.3297758102416992 seconds for one epoch ---
--- 0.7592806816101074 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.03463669]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.80013967]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [ 0.81656766]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-6.323315  ]
 [ 0.        ]]
--- 0.30321478843688965 seconds for one epoch ---
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2911.3896484375, (1362.709, 0.4535115, 1547.9602, 0.26703596)
   validation loss 1035.558349609375, (661.3258, 0.1976901, 373.76782, 0.26703596)
decoder loss ratio: 25620.909824, decoder SINDy loss  ratio: 0.806830
--- 0.2688331604003906 seconds for one epoch ---
--- 0.3140740394592285 seconds for one epoch ---
--- 0.7620570659637451 seconds for one epoch ---
--- 0.2996253967285156 seconds for one epoch ---
--- 0.73748779296875 seconds for one epoch ---
--- 0.3100426197052002 seconds for one epoch ---
--- 0.7549302577972412 seconds for one epoch ---
--- 0.32045578956604004 seconds for one epoch ---
--- 0.7426187992095947 seconds for one epoch ---
--- 0.31045031547546387 seconds for one epoch ---
--- 0.7455928325653076 seconds for one epoch ---
--- 0.31917428970336914 seconds for one epoch ---
--- 0.7525317668914795 seconds for one epoch ---
--- 0.31739211082458496 seconds for one epoch ---
--- 0.7641172409057617 seconds for one epoch ---
--- 0.30930304527282715 seconds for one epoch ---
--- 0.7689352035522461 seconds for one epoch ---
--- 0.3120889663696289 seconds for one epoch ---
--- 0.7704977989196777 seconds for one epoch ---
--- 0.3223905563354492 seconds for one epoch ---
--- 0.7519357204437256 seconds for one epoch ---
--- 0.3123602867126465 seconds for one epoch ---
--- 0.7513647079467773 seconds for one epoch ---
--- 0.3130669593811035 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02545574]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8382865 ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [ 0.48957294]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-6.672484  ]
 [-0.        ]]
--- 0.25666165351867676 seconds for one epoch ---
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2671.25439453125, (1237.5568, 0.25401962, 1433.1749, 0.26861152)
   validation loss 1079.6553955078125, (772.56, 0.13124241, 306.6956, 0.26861152)
decoder loss ratio: 29930.315529, decoder SINDy loss  ratio: 0.662046
--- 0.30965304374694824 seconds for one epoch ---
--- 0.7458372116088867 seconds for one epoch ---
--- 0.33039331436157227 seconds for one epoch ---
--- 0.751910924911499 seconds for one epoch ---
--- 0.3049137592315674 seconds for one epoch ---
--- 0.7754013538360596 seconds for one epoch ---
--- 0.31908345222473145 seconds for one epoch ---
--- 0.7699835300445557 seconds for one epoch ---
--- 0.31079936027526855 seconds for one epoch ---
--- 0.7755532264709473 seconds for one epoch ---
--- 0.31703662872314453 seconds for one epoch ---
--- 0.7503523826599121 seconds for one epoch ---
--- 0.3234720230102539 seconds for one epoch ---
--- 0.7772729396820068 seconds for one epoch ---
--- 0.30456995964050293 seconds for one epoch ---
--- 0.7595429420471191 seconds for one epoch ---
--- 0.3196220397949219 seconds for one epoch ---
--- 0.768071174621582 seconds for one epoch ---
--- 0.3206064701080322 seconds for one epoch ---
--- 0.7631034851074219 seconds for one epoch ---
--- 0.31705594062805176 seconds for one epoch ---
--- 0.7751040458679199 seconds for one epoch ---
--- 0.31787538528442383 seconds for one epoch ---
--- 0.7658236026763916 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02025478]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8698363 ]
 [0.        ]]
[[-0.       ]
 [-0.       ]
 [ 0.2515012]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-7.0223045]
 [-0.       ]]
--- 0.30930399894714355 seconds for one epoch ---
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4481.09521484375, (2122.7837, 1.23315, 2356.8064, 0.2717839)
   validation loss 984.5146484375, (693.0294, 0.18359011, 291.02985, 0.2717839)
decoder loss ratio: 26849.162842, decoder SINDy loss  ratio: 0.628229
--- 0.26699399948120117 seconds for one epoch ---
--- 0.3186821937561035 seconds for one epoch ---
--- 0.7539434432983398 seconds for one epoch ---
--- 0.31952452659606934 seconds for one epoch ---
--- 0.7565641403198242 seconds for one epoch ---
--- 0.31878042221069336 seconds for one epoch ---
--- 0.7932894229888916 seconds for one epoch ---
--- 0.3140285015106201 seconds for one epoch ---
--- 0.7666237354278564 seconds for one epoch ---
--- 0.31525659561157227 seconds for one epoch ---
--- 0.7954442501068115 seconds for one epoch ---
--- 0.3213016986846924 seconds for one epoch ---
--- 0.7585418224334717 seconds for one epoch ---
--- 0.3133218288421631 seconds for one epoch ---
--- 0.7846956253051758 seconds for one epoch ---
--- 0.3168025016784668 seconds for one epoch ---
--- 0.7854773998260498 seconds for one epoch ---
--- 0.31236815452575684 seconds for one epoch ---
--- 0.77939772605896 seconds for one epoch ---
--- 0.31560397148132324 seconds for one epoch ---
--- 0.7765228748321533 seconds for one epoch ---
--- 0.3137187957763672 seconds for one epoch ---
--- 0.7825863361358643 seconds for one epoch ---
--- 0.30110645294189453 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01722413]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.8947647 ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [ 0.08508947]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-7.3604655 ]
 [ 0.        ]]
--- 0.26179933547973633 seconds for one epoch ---
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4127.400390625, (1290.0885, 0.89941406, 2836.1372, 0.27559534)
   validation loss 1024.06396484375, (740.3928, 0.19788165, 283.1977, 0.27559534)
decoder loss ratio: 28684.103313, decoder SINDy loss  ratio: 0.611322
--- 0.3333899974822998 seconds for one epoch ---
--- 0.7923219203948975 seconds for one epoch ---
--- 0.3163299560546875 seconds for one epoch ---
--- 0.7828977108001709 seconds for one epoch ---
--- 0.3093869686126709 seconds for one epoch ---
--- 0.7791924476623535 seconds for one epoch ---
--- 0.32069873809814453 seconds for one epoch ---
--- 0.788611650466919 seconds for one epoch ---
--- 0.32431864738464355 seconds for one epoch ---
--- 0.7866430282592773 seconds for one epoch ---
--- 0.299424409866333 seconds for one epoch ---
--- 0.784151554107666 seconds for one epoch ---
--- 0.31223630905151367 seconds for one epoch ---
--- 0.7800438404083252 seconds for one epoch ---
--- 0.3010261058807373 seconds for one epoch ---
--- 0.8006162643432617 seconds for one epoch ---
--- 0.31065797805786133 seconds for one epoch ---
--- 0.7799527645111084 seconds for one epoch ---
--- 0.3269798755645752 seconds for one epoch ---
--- 0.7771615982055664 seconds for one epoch ---
--- 0.3190302848815918 seconds for one epoch ---
--- 0.7879037857055664 seconds for one epoch ---
--- 0.31685376167297363 seconds for one epoch ---
--- 0.780975341796875 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01684476]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9147521 ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.06317539]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-7.693463  ]
 [-0.        ]]
--- 0.30731654167175293 seconds for one epoch ---
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3123.12939453125, (1818.0272, 2.9549108, 1301.8654, 0.2817543)
   validation loss 1289.5020751953125, (1013.78046, 0.23306267, 275.20682, 0.2817543)
decoder loss ratio: 39275.614887, decoder SINDy loss  ratio: 0.594073
--- 0.26105809211730957 seconds for one epoch ---
--- 0.31319665908813477 seconds for one epoch ---
--- 0.7719278335571289 seconds for one epoch ---
--- 0.3288230895996094 seconds for one epoch ---
--- 0.7800326347351074 seconds for one epoch ---
--- 0.30580830574035645 seconds for one epoch ---
--- 0.7921252250671387 seconds for one epoch ---
--- 0.30776333808898926 seconds for one epoch ---
--- 0.7917764186859131 seconds for one epoch ---
--- 0.2964363098144531 seconds for one epoch ---
--- 0.7949612140655518 seconds for one epoch ---
--- 0.33121562004089355 seconds for one epoch ---
--- 0.7796056270599365 seconds for one epoch ---
--- 0.3291919231414795 seconds for one epoch ---
--- 0.7881088256835938 seconds for one epoch ---
--- 0.3074185848236084 seconds for one epoch ---
--- 0.8003528118133545 seconds for one epoch ---
--- 0.29239988327026367 seconds for one epoch ---
--- 0.7823424339294434 seconds for one epoch ---
--- 0.31311631202697754 seconds for one epoch ---
--- 0.7817108631134033 seconds for one epoch ---
--- 0.3226747512817383 seconds for one epoch ---
--- 0.7928669452667236 seconds for one epoch ---
--- 0.31906867027282715 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.01901435]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9307629 ]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.18877336]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-0.        ]
 [-8.022187  ]
 [-0.        ]]
--- 0.26009202003479004 seconds for one epoch ---
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4037.48828125, (2149.9414, 2.393173, 1884.8633, 0.29054993)
   validation loss 899.4292602539062, (595.3618, 0.17819363, 303.5987, 0.29054993)
decoder loss ratio: 23065.350361, decoder SINDy loss  ratio: 0.655360
--- 0.3032097816467285 seconds for one epoch ---
--- 0.8021590709686279 seconds for one epoch ---
--- 0.32025766372680664 seconds for one epoch ---
--- 0.8197915554046631 seconds for one epoch ---
--- 0.3151814937591553 seconds for one epoch ---
--- 0.8200154304504395 seconds for one epoch ---
--- 0.3208775520324707 seconds for one epoch ---
--- 0.7892684936523438 seconds for one epoch ---
--- 0.3044400215148926 seconds for one epoch ---
--- 0.7901990413665771 seconds for one epoch ---
--- 0.3094463348388672 seconds for one epoch ---
--- 0.8063826560974121 seconds for one epoch ---
--- 0.295856237411499 seconds for one epoch ---
--- 0.79970383644104 seconds for one epoch ---
--- 0.31028223037719727 seconds for one epoch ---
--- 0.8136093616485596 seconds for one epoch ---
--- 0.3289978504180908 seconds for one epoch ---
--- 0.8050384521484375 seconds for one epoch ---
--- 0.3072991371154785 seconds for one epoch ---
--- 0.8097748756408691 seconds for one epoch ---
--- 0.32057619094848633 seconds for one epoch ---
--- 0.8338625431060791 seconds for one epoch ---
--- 0.3070034980773926 seconds for one epoch ---
--- 0.8094534873962402 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02078687]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9438233 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.2816247]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-8.353771 ]
 [ 0.       ]]
--- 0.3050673007965088 seconds for one epoch ---
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5202.89501953125, (2155.7722, 1.6818558, 3045.1426, 0.29827353)
   validation loss 1121.4805908203125, (817.49896, 0.18394722, 303.49945, 0.29827353)
decoder loss ratio: 31671.329044, decoder SINDy loss  ratio: 0.655146
--- 0.2655489444732666 seconds for one epoch ---
--- 0.3232243061065674 seconds for one epoch ---
--- 0.7925896644592285 seconds for one epoch ---
--- 0.3209078311920166 seconds for one epoch ---
--- 0.8227934837341309 seconds for one epoch ---
--- 0.32210850715637207 seconds for one epoch ---
--- 0.8302412033081055 seconds for one epoch ---
--- 0.32192254066467285 seconds for one epoch ---
--- 0.8230733871459961 seconds for one epoch ---
--- 0.3109874725341797 seconds for one epoch ---
--- 0.8011629581451416 seconds for one epoch ---
--- 0.32715654373168945 seconds for one epoch ---
--- 0.8061790466308594 seconds for one epoch ---
--- 0.30555105209350586 seconds for one epoch ---
--- 0.8155269622802734 seconds for one epoch ---
--- 0.3204622268676758 seconds for one epoch ---
--- 0.8155004978179932 seconds for one epoch ---
--- 0.31935715675354004 seconds for one epoch ---
--- 0.828984260559082 seconds for one epoch ---
--- 0.31261634826660156 seconds for one epoch ---
--- 0.8155851364135742 seconds for one epoch ---
--- 0.31964778900146484 seconds for one epoch ---
--- 0.8170502185821533 seconds for one epoch ---
--- 0.3214995861053467 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02236895]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9542005 ]
 [0.        ]]
[[-0.        ]
 [-0.        ]
 [-0.35839072]
 [ 0.        ]
 [ 0.        ]
 [-0.        ]
 [ 0.        ]
 [ 0.        ]
 [ 0.        ]
 [-8.680149  ]
 [ 0.        ]]
--- 0.2531607151031494 seconds for one epoch ---
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4059.155517578125, (1761.6519, 1.7743347, 2295.424, 0.30536255)
   validation loss 1255.808349609375, (915.26416, 0.19502516, 340.04373, 0.30536255)
decoder loss ratio: 35458.922533, decoder SINDy loss  ratio: 0.734032
--- 0.298384428024292 seconds for one epoch ---
--- 0.7941980361938477 seconds for one epoch ---
--- 0.3048243522644043 seconds for one epoch ---
--- 0.8148176670074463 seconds for one epoch ---
--- 0.302717924118042 seconds for one epoch ---
--- 0.8204503059387207 seconds for one epoch ---
--- 0.3033912181854248 seconds for one epoch ---
--- 0.8256292343139648 seconds for one epoch ---
--- 0.3177821636199951 seconds for one epoch ---
--- 0.8378915786743164 seconds for one epoch ---
--- 0.32291722297668457 seconds for one epoch ---
--- 0.8321218490600586 seconds for one epoch ---
--- 0.3166368007659912 seconds for one epoch ---
--- 0.8191015720367432 seconds for one epoch ---
--- 0.31791019439697266 seconds for one epoch ---
--- 0.8218114376068115 seconds for one epoch ---
--- 0.3211374282836914 seconds for one epoch ---
--- 0.8494105339050293 seconds for one epoch ---
--- 0.31218886375427246 seconds for one epoch ---
--- 0.8488178253173828 seconds for one epoch ---
--- 0.3091917037963867 seconds for one epoch ---
--- 0.8312397003173828 seconds for one epoch ---
--- 0.31459736824035645 seconds for one epoch ---
--- 0.8290705680847168 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02389202]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9617914 ]
 [0.        ]]
[[ 0.       ]
 [ 0.       ]
 [-0.4275082]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-8.972493 ]
 [-0.       ]]
--- 0.28570985794067383 seconds for one epoch ---
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2371.943603515625, (1327.0789, 0.55974907, 1043.9934, 0.31170645)
   validation loss 962.2058715820312, (691.8299, 0.22481449, 269.8395, 0.31170645)
decoder loss ratio: 26802.691203, decoder SINDy loss  ratio: 0.582487
--- 0.26361989974975586 seconds for one epoch ---
--- 0.3056967258453369 seconds for one epoch ---
--- 0.8053834438323975 seconds for one epoch ---
--- 0.31507253646850586 seconds for one epoch ---
--- 0.8245902061462402 seconds for one epoch ---
--- 0.3146400451660156 seconds for one epoch ---
--- 0.851726770401001 seconds for one epoch ---
--- 0.3137364387512207 seconds for one epoch ---
--- 0.8016929626464844 seconds for one epoch ---
--- 0.32424116134643555 seconds for one epoch ---
--- 0.833106517791748 seconds for one epoch ---
--- 0.31068944931030273 seconds for one epoch ---
--- 0.818443775177002 seconds for one epoch ---
--- 0.3172876834869385 seconds for one epoch ---
--- 0.8498780727386475 seconds for one epoch ---
--- 0.4834887981414795 seconds for one epoch ---
--- 0.8213081359863281 seconds for one epoch ---
--- 0.31459879875183105 seconds for one epoch ---
--- 0.8223850727081299 seconds for one epoch ---
--- 0.3181431293487549 seconds for one epoch ---
--- 0.8297953605651855 seconds for one epoch ---
--- 0.30604982376098633 seconds for one epoch ---
--- 0.8204262256622314 seconds for one epoch ---
--- 0.3234841823577881 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02561575]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9676805 ]
 [0.        ]]
[[ 0.       ]
 [-0.       ]
 [-0.5008257]
 [ 0.       ]
 [-0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-9.245472 ]
 [-0.       ]]
--- 0.2638826370239258 seconds for one epoch ---
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3742.58642578125, (1583.6937, 1.7193292, 2156.8557, 0.317738)
   validation loss 796.7789916992188, (512.08527, 0.20994033, 284.16602, 0.317738)
decoder loss ratio: 19839.072228, decoder SINDy loss  ratio: 0.613412
--- 0.313274621963501 seconds for one epoch ---
--- 0.8356857299804688 seconds for one epoch ---
--- 0.32572031021118164 seconds for one epoch ---
--- 0.8680953979492188 seconds for one epoch ---
--- 0.31490111351013184 seconds for one epoch ---
--- 0.858957052230835 seconds for one epoch ---
--- 0.3466815948486328 seconds for one epoch ---
--- 0.8380606174468994 seconds for one epoch ---
--- 0.31532788276672363 seconds for one epoch ---
--- 0.8598864078521729 seconds for one epoch ---
--- 0.30917811393737793 seconds for one epoch ---
--- 0.8584644794464111 seconds for one epoch ---
--- 0.30825376510620117 seconds for one epoch ---
--- 0.8271400928497314 seconds for one epoch ---
--- 0.3139922618865967 seconds for one epoch ---
--- 0.8568031787872314 seconds for one epoch ---
--- 0.3155210018157959 seconds for one epoch ---
--- 0.8363525867462158 seconds for one epoch ---
--- 0.31528139114379883 seconds for one epoch ---
--- 0.8402776718139648 seconds for one epoch ---
--- 0.3133111000061035 seconds for one epoch ---
--- 0.8548216819763184 seconds for one epoch ---
--- 0.3064000606536865 seconds for one epoch ---
--- 0.8323409557342529 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02589689]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9728492 ]
 [0.        ]]
[[-0.       ]
 [ 0.       ]
 [-0.5125575]
 [-0.       ]
 [ 0.       ]
 [-0.       ]
 [ 0.       ]
 [ 0.       ]
 [-0.       ]
 [-9.533076 ]
 [ 0.       ]]
--- 0.2912585735321045 seconds for one epoch ---
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2158.671142578125, (1344.9087, 0.5519742, 812.88824, 0.32230783)
   validation loss 1190.7015380859375, (865.59656, 0.2879014, 324.49478, 0.32230783)
decoder loss ratio: 33534.713384, decoder SINDy loss  ratio: 0.700468
--- 0.2765815258026123 seconds for one epoch ---
--- 0.30199337005615234 seconds for one epoch ---
--- 0.855750560760498 seconds for one epoch ---
--- 0.3236100673675537 seconds for one epoch ---
--- 0.8506910800933838 seconds for one epoch ---
--- 0.3304421901702881 seconds for one epoch ---
--- 0.8615832328796387 seconds for one epoch ---
--- 0.2962329387664795 seconds for one epoch ---
--- 0.831589937210083 seconds for one epoch ---
--- 0.3173234462738037 seconds for one epoch ---
--- 0.865478515625 seconds for one epoch ---
--- 0.3077878952026367 seconds for one epoch ---
--- 0.8436522483825684 seconds for one epoch ---
--- 0.3094363212585449 seconds for one epoch ---
--- 0.8462743759155273 seconds for one epoch ---
--- 0.31664252281188965 seconds for one epoch ---
--- 0.8709924221038818 seconds for one epoch ---
--- 0.3229382038116455 seconds for one epoch ---
--- 0.8600254058837891 seconds for one epoch ---
--- 0.3005385398864746 seconds for one epoch ---
--- 0.8666307926177979 seconds for one epoch ---
--- 0.31534337997436523 seconds for one epoch ---
--- 0.8611278533935547 seconds for one epoch ---
--- 0.3156106472015381 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02647376]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9768105 ]
 [0.        ]]
[[ 0.        ]
 [-0.        ]
 [-0.53595954]
 [ 0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [-0.        ]
 [ 0.        ]
 [-9.796738  ]
 [-0.        ]]
--- 0.26392579078674316 seconds for one epoch ---
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2900.838623046875, (1743.763, 1.1707448, 1155.5778, 0.32724866)
   validation loss 1017.8040771484375, (721.8006, 0.27580357, 295.4004, 0.32724866)
decoder loss ratio: 27963.808273, decoder SINDy loss  ratio: 0.637663
--- 0.3072926998138428 seconds for one epoch ---
--- 0.8815498352050781 seconds for one epoch ---
--- 0.3213081359863281 seconds for one epoch ---
--- 0.8694624900817871 seconds for one epoch ---
--- 0.317976713180542 seconds for one epoch ---
--- 0.8525199890136719 seconds for one epoch ---
--- 0.3082005977630615 seconds for one epoch ---
--- 0.8748931884765625 seconds for one epoch ---
--- 0.32826948165893555 seconds for one epoch ---
--- 0.8808703422546387 seconds for one epoch ---
--- 0.3185751438140869 seconds for one epoch ---
--- 0.8584871292114258 seconds for one epoch ---
--- 0.3155984878540039 seconds for one epoch ---
--- 0.8830277919769287 seconds for one epoch ---
--- 0.32407188415527344 seconds for one epoch ---
--- 0.8829948902130127 seconds for one epoch ---
--- 0.29836130142211914 seconds for one epoch ---
--- 0.8447470664978027 seconds for one epoch ---
--- 0.3248581886291504 seconds for one epoch ---
--- 0.886235237121582 seconds for one epoch ---
--- 0.3103370666503906 seconds for one epoch ---
--- 0.886608362197876 seconds for one epoch ---
--- 0.32464075088500977 seconds for one epoch ---
--- 0.9024832248687744 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02718062]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.97970563]
 [0.        ]]
[[ -0.        ]
 [ -0.        ]
 [ -0.56388676]
 [ -0.        ]
 [ -0.        ]
 [ -0.        ]
 [  0.        ]
 [ -0.        ]
 [ -0.        ]
 [-10.022663  ]
 [  0.        ]]
--- 0.2760763168334961 seconds for one epoch ---
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3264.052490234375, (1394.6829, 2.5627055, 1866.4756, 0.3313993)
   validation loss 1053.803466796875, (779.63965, 0.35964444, 273.47275, 0.3313993)
decoder loss ratio: 30204.593494, decoder SINDy loss  ratio: 0.590329
--- 0.2716407775878906 seconds for one epoch ---
--- 0.31020498275756836 seconds for one epoch ---
--- 0.8650026321411133 seconds for one epoch ---
--- 0.31357550621032715 seconds for one epoch ---
--- 0.871396541595459 seconds for one epoch ---
--- 0.31696343421936035 seconds for one epoch ---
--- 0.8867981433868408 seconds for one epoch ---
--- 0.30249738693237305 seconds for one epoch ---
--- 0.8865935802459717 seconds for one epoch ---
--- 0.31134867668151855 seconds for one epoch ---
--- 0.8711426258087158 seconds for one epoch ---
--- 0.2978169918060303 seconds for one epoch ---
--- 0.8896439075469971 seconds for one epoch ---
--- 0.2966952323913574 seconds for one epoch ---
--- 0.8518345355987549 seconds for one epoch ---
--- 0.3122291564941406 seconds for one epoch ---
--- 0.8720355033874512 seconds for one epoch ---
--- 0.3369486331939697 seconds for one epoch ---
--- 0.8728156089782715 seconds for one epoch ---
--- 0.3119208812713623 seconds for one epoch ---
--- 0.8848986625671387 seconds for one epoch ---
--- 0.3197290897369385 seconds for one epoch ---
--- 0.8808958530426025 seconds for one epoch ---
--- 0.31908679008483887 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02744977]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98223495]
 [0.        ]]
[[ -0.       ]
 [ -0.       ]
 [ -0.5744509]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-10.250846 ]
 [ -0.       ]]
--- 0.265941858291626 seconds for one epoch ---
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3155.31787109375, (1491.8237, 1.3849174, 1661.7738, 0.33534312)
   validation loss 1248.3668212890625, (956.11743, 0.2632306, 291.65076, 0.33534312)
decoder loss ratio: 37041.649195, decoder SINDy loss  ratio: 0.629569
--- 0.3058910369873047 seconds for one epoch ---
--- 0.8710017204284668 seconds for one epoch ---
--- 0.30737757682800293 seconds for one epoch ---
--- 0.8785130977630615 seconds for one epoch ---
--- 0.3152446746826172 seconds for one epoch ---
--- 0.878455638885498 seconds for one epoch ---
--- 0.3236258029937744 seconds for one epoch ---
--- 0.8865466117858887 seconds for one epoch ---
--- 0.3132021427154541 seconds for one epoch ---
--- 0.8757054805755615 seconds for one epoch ---
--- 0.3111453056335449 seconds for one epoch ---
--- 0.8983535766601562 seconds for one epoch ---
--- 0.29856324195861816 seconds for one epoch ---
--- 0.8905298709869385 seconds for one epoch ---
--- 0.30855846405029297 seconds for one epoch ---
--- 0.8716433048248291 seconds for one epoch ---
--- 0.31641697883605957 seconds for one epoch ---
--- 0.8925695419311523 seconds for one epoch ---
--- 0.320324182510376 seconds for one epoch ---
--- 0.909905195236206 seconds for one epoch ---
--- 0.30481696128845215 seconds for one epoch ---
--- 0.8922779560089111 seconds for one epoch ---
--- 0.30912184715270996 seconds for one epoch ---
--- 0.8817160129547119 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02823058]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98442817]
 [0.        ]]
[[  0.        ]
 [  0.        ]
 [ -0.60417867]
 [ -0.        ]
 [ -0.        ]
 [ -0.        ]
 [ -0.        ]
 [ -0.        ]
 [ -0.        ]
 [-10.479788  ]
 [  0.        ]]
--- 0.27124857902526855 seconds for one epoch ---
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2891.520263671875, (1102.432, 0.43682113, 1788.3119, 0.3396639)
   validation loss 1153.580078125, (814.7034, 0.29459834, 338.24234, 0.3396639)
decoder loss ratio: 31563.025272, decoder SINDy loss  ratio: 0.730144
--- 0.2616586685180664 seconds for one epoch ---
--- 0.31514692306518555 seconds for one epoch ---
--- 0.890153169631958 seconds for one epoch ---
--- 0.3010745048522949 seconds for one epoch ---
--- 0.9015552997589111 seconds for one epoch ---
--- 0.31740593910217285 seconds for one epoch ---
--- 0.9083495140075684 seconds for one epoch ---
--- 0.3223123550415039 seconds for one epoch ---
--- 0.8833129405975342 seconds for one epoch ---
--- 0.32611870765686035 seconds for one epoch ---
--- 0.8648569583892822 seconds for one epoch ---
--- 0.3061239719390869 seconds for one epoch ---
--- 0.9053034782409668 seconds for one epoch ---
--- 0.31036853790283203 seconds for one epoch ---
--- 0.9069018363952637 seconds for one epoch ---
--- 0.3029642105102539 seconds for one epoch ---
--- 0.8893916606903076 seconds for one epoch ---
--- 0.2959330081939697 seconds for one epoch ---
--- 0.8762001991271973 seconds for one epoch ---
--- 0.3064603805541992 seconds for one epoch ---
--- 0.9057133197784424 seconds for one epoch ---
--- 0.3134336471557617 seconds for one epoch ---
--- 0.8743264675140381 seconds for one epoch ---
--- 0.31281065940856934 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02863369]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98628294]
 [0.        ]]
[[  0.        ]
 [ -0.        ]
 [ -0.61928827]
 [  0.        ]
 [ -0.        ]
 [ -0.        ]
 [ -0.        ]
 [ -0.        ]
 [ -0.        ]
 [-10.7030735 ]
 [  0.        ]]
--- 0.24532008171081543 seconds for one epoch ---
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3834.26953125, (1525.6135, 3.929187, 2304.383, 0.34373316)
   validation loss 818.4215087890625, (557.56274, 0.23998685, 260.27505, 0.34373316)
decoder loss ratio: 21600.948679, decoder SINDy loss  ratio: 0.561840
--- 0.3127322196960449 seconds for one epoch ---
--- 0.9113795757293701 seconds for one epoch ---
--- 0.3089935779571533 seconds for one epoch ---
--- 0.9210565090179443 seconds for one epoch ---
--- 0.31505274772644043 seconds for one epoch ---
--- 0.9107553958892822 seconds for one epoch ---
--- 0.3135411739349365 seconds for one epoch ---
--- 0.9165849685668945 seconds for one epoch ---
--- 0.31629371643066406 seconds for one epoch ---
--- 0.9087228775024414 seconds for one epoch ---
--- 0.31656575202941895 seconds for one epoch ---
--- 0.9183378219604492 seconds for one epoch ---
--- 0.31357598304748535 seconds for one epoch ---
--- 0.9426813125610352 seconds for one epoch ---
--- 0.31367015838623047 seconds for one epoch ---
--- 0.9304571151733398 seconds for one epoch ---
--- 0.31772685050964355 seconds for one epoch ---
--- 0.9276394844055176 seconds for one epoch ---
--- 0.30058956146240234 seconds for one epoch ---
--- 0.9120566844940186 seconds for one epoch ---
--- 0.3084566593170166 seconds for one epoch ---
--- 0.9201810359954834 seconds for one epoch ---
--- 0.3158268928527832 seconds for one epoch ---
--- 0.902625322341919 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.02887467]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.9877798 ]
 [0.        ]]
[[ -0.       ]
 [  0.       ]
 [ -0.6282537]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [-10.90937  ]
 [ -0.       ]]
--- 0.30478811264038086 seconds for one epoch ---
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2572.3173828125, (1267.1599, 1.7660677, 1303.0443, 0.34718105)
   validation loss 1194.192138671875, (881.9543, 0.29464906, 311.596, 0.34718105)
decoder loss ratio: 34168.440128, decoder SINDy loss  ratio: 0.672624
THRESHOLDING: 1 active coefficients
--- 0.26177382469177246 seconds for one epoch ---
--- 0.3287849426269531 seconds for one epoch ---
--- 0.9341602325439453 seconds for one epoch ---
--- 0.31355881690979004 seconds for one epoch ---
--- 0.9455535411834717 seconds for one epoch ---
--- 0.30776166915893555 seconds for one epoch ---
--- 0.9347870349884033 seconds for one epoch ---
--- 0.2984733581542969 seconds for one epoch ---
--- 0.925469160079956 seconds for one epoch ---
--- 0.3086202144622803 seconds for one epoch ---
--- 0.9414093494415283 seconds for one epoch ---
--- 0.3164820671081543 seconds for one epoch ---
--- 0.9114649295806885 seconds for one epoch ---
--- 0.30401134490966797 seconds for one epoch ---
--- 0.9210705757141113 seconds for one epoch ---
--- 0.3110697269439697 seconds for one epoch ---
--- 0.9167447090148926 seconds for one epoch ---
--- 0.33028697967529297 seconds for one epoch ---
--- 0.9227383136749268 seconds for one epoch ---
--- 0.30350732803344727 seconds for one epoch ---
--- 0.914926290512085 seconds for one epoch ---
--- 0.32458043098449707 seconds for one epoch ---
--- 0.9276740550994873 seconds for one epoch ---
--- 0.3177366256713867 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.98890346]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-11.083533]
 [  0.      ]]
--- 0.26610541343688965 seconds for one epoch ---
Epoch 1525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2282.445068359375, (1081.4386, 2.2143848, 1198.467, 0.32484987)
   validation loss 1094.5697021484375, (803.2439, 0.2937507, 290.70728, 0.32484987)
decoder loss ratio: 31119.063043, decoder SINDy loss  ratio: 0.627533
--- 0.2881338596343994 seconds for one epoch ---
--- 0.9198243618011475 seconds for one epoch ---
--- 0.317612886428833 seconds for one epoch ---
--- 0.9111583232879639 seconds for one epoch ---
--- 0.32171082496643066 seconds for one epoch ---
--- 0.929969310760498 seconds for one epoch ---
--- 0.32401227951049805 seconds for one epoch ---
--- 0.9153957366943359 seconds for one epoch ---
--- 0.3277871608734131 seconds for one epoch ---
--- 0.9457015991210938 seconds for one epoch ---
--- 0.31749987602233887 seconds for one epoch ---
--- 0.9165375232696533 seconds for one epoch ---
--- 0.3142552375793457 seconds for one epoch ---
--- 0.935011625289917 seconds for one epoch ---
--- 0.30959391593933105 seconds for one epoch ---
--- 0.9518554210662842 seconds for one epoch ---
--- 0.30601024627685547 seconds for one epoch ---
--- 0.9343948364257812 seconds for one epoch ---
--- 0.3129570484161377 seconds for one epoch ---
--- 0.9260132312774658 seconds for one epoch ---
--- 0.30297112464904785 seconds for one epoch ---
--- 0.9356870651245117 seconds for one epoch ---
--- 0.30610203742980957 seconds for one epoch ---
--- 0.9541761875152588 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9898696]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-11.24991]
 [ -0.     ]]
--- 0.2904472351074219 seconds for one epoch ---
Epoch 1550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3332.21044921875, (1568.197, 1.4114321, 1762.2745, 0.3276486)
   validation loss 1019.89453125, (702.10706, 0.2982841, 317.1616, 0.3276486)
decoder loss ratio: 27200.846248, decoder SINDy loss  ratio: 0.684638
--- 0.2616703510284424 seconds for one epoch ---
--- 0.31134867668151855 seconds for one epoch ---
--- 0.9291362762451172 seconds for one epoch ---
--- 0.31574273109436035 seconds for one epoch ---
--- 0.9326257705688477 seconds for one epoch ---
--- 0.3256549835205078 seconds for one epoch ---
--- 0.9378762245178223 seconds for one epoch ---
--- 0.32396483421325684 seconds for one epoch ---
--- 0.9501292705535889 seconds for one epoch ---
--- 0.31932830810546875 seconds for one epoch ---
--- 0.954765796661377 seconds for one epoch ---
--- 0.3186972141265869 seconds for one epoch ---
--- 0.9577662944793701 seconds for one epoch ---
--- 0.3127598762512207 seconds for one epoch ---
--- 0.9729955196380615 seconds for one epoch ---
--- 0.30910468101501465 seconds for one epoch ---
--- 0.9421024322509766 seconds for one epoch ---
--- 0.3228144645690918 seconds for one epoch ---
--- 0.9611513614654541 seconds for one epoch ---
--- 0.31182169914245605 seconds for one epoch ---
--- 0.9483494758605957 seconds for one epoch ---
--- 0.32502007484436035 seconds for one epoch ---
--- 0.9391536712646484 seconds for one epoch ---
--- 0.32421398162841797 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9907998]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.427794]
 [ -0.      ]]
--- 0.2572212219238281 seconds for one epoch ---
Epoch 1575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2194.768798828125, (841.0397, 0.40103638, 1352.9973, 0.330771)
   validation loss 960.4735717773438, (684.35693, 0.3978096, 275.3881, 0.330771)
decoder loss ratio: 26513.175703, decoder SINDy loss  ratio: 0.594464
--- 0.3158762454986572 seconds for one epoch ---
--- 0.940671443939209 seconds for one epoch ---
--- 0.31856513023376465 seconds for one epoch ---
--- 0.9391450881958008 seconds for one epoch ---
--- 0.3113713264465332 seconds for one epoch ---
--- 0.9484202861785889 seconds for one epoch ---
--- 0.3124263286590576 seconds for one epoch ---
--- 0.9426689147949219 seconds for one epoch ---
--- 0.3177657127380371 seconds for one epoch ---
--- 0.9616248607635498 seconds for one epoch ---
--- 0.3209187984466553 seconds for one epoch ---
--- 0.9805927276611328 seconds for one epoch ---
--- 0.3115839958190918 seconds for one epoch ---
--- 0.9754147529602051 seconds for one epoch ---
--- 0.3213217258453369 seconds for one epoch ---
--- 0.9658422470092773 seconds for one epoch ---
--- 0.32345032691955566 seconds for one epoch ---
--- 0.9671502113342285 seconds for one epoch ---
--- 0.326946496963501 seconds for one epoch ---
--- 0.9761700630187988 seconds for one epoch ---
--- 0.31568408012390137 seconds for one epoch ---
--- 0.9949917793273926 seconds for one epoch ---
--- 0.3211400508880615 seconds for one epoch ---
--- 0.9751725196838379 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9914776]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.570855]
 [  0.      ]]
--- 0.29692959785461426 seconds for one epoch ---
Epoch 1600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5419.005859375, (1825.8538, 2.604073, 3590.215, 0.33322224)
   validation loss 800.0473022460938, (536.09705, 0.30782932, 263.3092, 0.33322224)
decoder loss ratio: 20769.330264, decoder SINDy loss  ratio: 0.568390
--- 0.2699568271636963 seconds for one epoch ---
--- 0.30532383918762207 seconds for one epoch ---
--- 0.9524781703948975 seconds for one epoch ---
--- 0.3231079578399658 seconds for one epoch ---
--- 0.950446367263794 seconds for one epoch ---
--- 0.3217957019805908 seconds for one epoch ---
--- 0.9629843235015869 seconds for one epoch ---
--- 0.3144259452819824 seconds for one epoch ---
--- 0.9439668655395508 seconds for one epoch ---
--- 0.31179261207580566 seconds for one epoch ---
--- 0.958099365234375 seconds for one epoch ---
--- 0.3051266670227051 seconds for one epoch ---
--- 0.9533858299255371 seconds for one epoch ---
--- 0.3078889846801758 seconds for one epoch ---
--- 0.9640188217163086 seconds for one epoch ---
--- 0.3185880184173584 seconds for one epoch ---
--- 0.9572992324829102 seconds for one epoch ---
--- 0.31050705909729004 seconds for one epoch ---
--- 0.962367057800293 seconds for one epoch ---
--- 0.3198697566986084 seconds for one epoch ---
--- 0.9805941581726074 seconds for one epoch ---
--- 0.31578516960144043 seconds for one epoch ---
--- 0.9670326709747314 seconds for one epoch ---
--- 0.31440019607543945 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99209553]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-11.712839]
 [  0.      ]]
--- 0.263655424118042 seconds for one epoch ---
Epoch 1625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2963.017578125, (955.57043, 3.935003, 2003.1764, 0.3356807)
   validation loss 856.8366088867188, (577.97943, 0.42031923, 278.10114, 0.3356807)
decoder loss ratio: 22391.926579, decoder SINDy loss  ratio: 0.600320
--- 0.3061192035675049 seconds for one epoch ---
--- 0.9575259685516357 seconds for one epoch ---
--- 0.3147900104522705 seconds for one epoch ---
--- 0.9784097671508789 seconds for one epoch ---
--- 0.31144118309020996 seconds for one epoch ---
--- 0.9487519264221191 seconds for one epoch ---
--- 0.3229496479034424 seconds for one epoch ---
--- 0.9709174633026123 seconds for one epoch ---
--- 0.31375718116760254 seconds for one epoch ---
--- 0.9710509777069092 seconds for one epoch ---
--- 0.32201290130615234 seconds for one epoch ---
--- 0.9847297668457031 seconds for one epoch ---
--- 0.2900416851043701 seconds for one epoch ---
--- 0.9700696468353271 seconds for one epoch ---
--- 0.31395483016967773 seconds for one epoch ---
--- 0.9812748432159424 seconds for one epoch ---
--- 0.31728029251098633 seconds for one epoch ---
--- 0.9957759380340576 seconds for one epoch ---
--- 0.3142879009246826 seconds for one epoch ---
--- 0.9807684421539307 seconds for one epoch ---
--- 0.3180530071258545 seconds for one epoch ---
--- 0.9565615653991699 seconds for one epoch ---
--- 0.3130152225494385 seconds for one epoch ---
--- 0.9720296859741211 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9926169]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.842792]
 [ -0.      ]]
--- 0.2939155101776123 seconds for one epoch ---
Epoch 1650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2199.442138671875, (1202.2833, 0.6323368, 996.18854, 0.33796474)
   validation loss 948.2677612304688, (646.78345, 0.3610303, 300.7853, 0.33796474)
decoder loss ratio: 25057.513613, decoder SINDy loss  ratio: 0.649287
--- 0.2550640106201172 seconds for one epoch ---
--- 0.30338573455810547 seconds for one epoch ---
--- 0.956446647644043 seconds for one epoch ---
--- 0.3193061351776123 seconds for one epoch ---
--- 0.9694933891296387 seconds for one epoch ---
--- 0.3029935359954834 seconds for one epoch ---
--- 0.9880592823028564 seconds for one epoch ---
--- 0.3037095069885254 seconds for one epoch ---
--- 0.9924914836883545 seconds for one epoch ---
--- 0.3185563087463379 seconds for one epoch ---
--- 1.0107862949371338 seconds for one epoch ---
--- 0.2959113121032715 seconds for one epoch ---
--- 1.0051229000091553 seconds for one epoch ---
--- 0.3159830570220947 seconds for one epoch ---
--- 0.9838001728057861 seconds for one epoch ---
--- 0.3068819046020508 seconds for one epoch ---
--- 1.010051965713501 seconds for one epoch ---
--- 0.30621814727783203 seconds for one epoch ---
--- 1.012345314025879 seconds for one epoch ---
--- 0.3179166316986084 seconds for one epoch ---
--- 0.9760446548461914 seconds for one epoch ---
--- 0.3259878158569336 seconds for one epoch ---
--- 1.010505199432373 seconds for one epoch ---
--- 0.30922412872314453 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99312156]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-11.979109]
 [ -0.      ]]
--- 0.2680802345275879 seconds for one epoch ---
Epoch 1675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2398.0927734375, (1162.5327, 1.2910903, 1233.9286, 0.34036028)
   validation loss 1055.1903076171875, (770.54175, 0.38384673, 283.9244, 0.34036028)
decoder loss ratio: 29852.125039, decoder SINDy loss  ratio: 0.612891
--- 0.3231699466705322 seconds for one epoch ---
--- 1.0137717723846436 seconds for one epoch ---
--- 0.33984971046447754 seconds for one epoch ---
--- 0.9643476009368896 seconds for one epoch ---
--- 0.31386637687683105 seconds for one epoch ---
--- 0.9791178703308105 seconds for one epoch ---
--- 0.3279726505279541 seconds for one epoch ---
--- 0.9895651340484619 seconds for one epoch ---
--- 0.31583404541015625 seconds for one epoch ---
--- 1.0087413787841797 seconds for one epoch ---
--- 0.3141613006591797 seconds for one epoch ---
--- 0.9863409996032715 seconds for one epoch ---
--- 0.30276060104370117 seconds for one epoch ---
--- 1.0198478698730469 seconds for one epoch ---
--- 0.3227870464324951 seconds for one epoch ---
--- 1.006467580795288 seconds for one epoch ---
--- 0.32183384895324707 seconds for one epoch ---
--- 1.0073487758636475 seconds for one epoch ---
--- 0.3139462471008301 seconds for one epoch ---
--- 1.0104124546051025 seconds for one epoch ---
--- 0.310650110244751 seconds for one epoch ---
--- 1.019019603729248 seconds for one epoch ---
--- 0.3060905933380127 seconds for one epoch ---
--- 1.0417025089263916 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9935651]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-12.108359]
 [  0.      ]]
--- 0.29515862464904785 seconds for one epoch ---
Epoch 1700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1560.6707763671875, (798.9018, 0.61976075, 760.8065, 0.34269983)
   validation loss 829.1727905273438, (545.4982, 0.3179932, 283.01382, 0.34269983)
decoder loss ratio: 21133.548456, decoder SINDy loss  ratio: 0.610925
--- 0.2697179317474365 seconds for one epoch ---
--- 0.31889843940734863 seconds for one epoch ---
--- 1.022413969039917 seconds for one epoch ---
--- 0.3112156391143799 seconds for one epoch ---
--- 1.0177602767944336 seconds for one epoch ---
--- 0.31389451026916504 seconds for one epoch ---
--- 0.983147144317627 seconds for one epoch ---
--- 0.31740570068359375 seconds for one epoch ---
--- 1.0411183834075928 seconds for one epoch ---
--- 0.3174302577972412 seconds for one epoch ---
--- 1.0157420635223389 seconds for one epoch ---
--- 0.31798720359802246 seconds for one epoch ---
--- 1.0294990539550781 seconds for one epoch ---
--- 0.31331801414489746 seconds for one epoch ---
--- 1.0170843601226807 seconds for one epoch ---
--- 0.31268310546875 seconds for one epoch ---
--- 1.0122764110565186 seconds for one epoch ---
--- 0.2905914783477783 seconds for one epoch ---
--- 1.0312209129333496 seconds for one epoch ---
--- 0.31314921379089355 seconds for one epoch ---
--- 1.0063157081604004 seconds for one epoch ---
--- 0.3015737533569336 seconds for one epoch ---
--- 1.0362298488616943 seconds for one epoch ---
--- 0.2981400489807129 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99398386]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.240437]
 [ -0.      ]]
--- 0.24885821342468262 seconds for one epoch ---
Epoch 1725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4589.38330078125, (2345.5388, 0.7161247, 2242.783, 0.34513065)
   validation loss 990.7981567382812, (717.7764, 0.39619777, 272.2804, 0.34513065)
decoder loss ratio: 27807.904944, decoder SINDy loss  ratio: 0.587756
--- 0.3036940097808838 seconds for one epoch ---
--- 1.0355207920074463 seconds for one epoch ---
--- 0.304889440536499 seconds for one epoch ---
--- 1.0080816745758057 seconds for one epoch ---
--- 0.3103351593017578 seconds for one epoch ---
--- 0.995262861251831 seconds for one epoch ---
--- 0.3109414577484131 seconds for one epoch ---
--- 1.030888557434082 seconds for one epoch ---
--- 0.310086727142334 seconds for one epoch ---
--- 1.0368294715881348 seconds for one epoch ---
--- 0.31322503089904785 seconds for one epoch ---
--- 1.0231356620788574 seconds for one epoch ---
--- 0.31811022758483887 seconds for one epoch ---
--- 1.0617344379425049 seconds for one epoch ---
--- 0.3186495304107666 seconds for one epoch ---
--- 1.0530269145965576 seconds for one epoch ---
--- 0.30684423446655273 seconds for one epoch ---
--- 1.0290765762329102 seconds for one epoch ---
--- 0.32164812088012695 seconds for one epoch ---
--- 1.0378062725067139 seconds for one epoch ---
--- 0.31067371368408203 seconds for one epoch ---
--- 1.023346185684204 seconds for one epoch ---
--- 0.30977678298950195 seconds for one epoch ---
--- 1.0693886280059814 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9943439]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.362546]
 [  0.      ]]
--- 0.3115718364715576 seconds for one epoch ---
Epoch 1750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2214.389404296875, (1279.6863, 1.1191131, 933.2367, 0.34733137)
   validation loss 1022.2609252929688, (752.5547, 0.33541676, 269.02353, 0.34733137)
decoder loss ratio: 29155.275086, decoder SINDy loss  ratio: 0.580725
--- 0.2745687961578369 seconds for one epoch ---
--- 0.32675790786743164 seconds for one epoch ---
--- 1.0377593040466309 seconds for one epoch ---
--- 0.3281378746032715 seconds for one epoch ---
--- 1.0077881813049316 seconds for one epoch ---
--- 0.3029026985168457 seconds for one epoch ---
--- 1.0385594367980957 seconds for one epoch ---
--- 0.32573390007019043 seconds for one epoch ---
--- 1.0254321098327637 seconds for one epoch ---
--- 0.5088086128234863 seconds for one epoch ---
--- 1.0260777473449707 seconds for one epoch ---
--- 0.3079404830932617 seconds for one epoch ---
--- 1.0344288349151611 seconds for one epoch ---
--- 0.3219411373138428 seconds for one epoch ---
--- 1.0697605609893799 seconds for one epoch ---
--- 0.31454896926879883 seconds for one epoch ---
--- 1.075697422027588 seconds for one epoch ---
--- 0.3004188537597656 seconds for one epoch ---
--- 1.0137181282043457 seconds for one epoch ---
--- 0.31369543075561523 seconds for one epoch ---
--- 1.0722682476043701 seconds for one epoch ---
--- 0.335155725479126 seconds for one epoch ---
--- 1.0517065525054932 seconds for one epoch ---
--- 0.33712315559387207 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9946569]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.476543]
 [ -0.      ]]
--- 0.2574021816253662 seconds for one epoch ---
Epoch 1775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2810.308837890625, (1212.5042, 0.85198337, 1596.6035, 0.34947848)
   validation loss 1134.25634765625, (854.254, 0.37173682, 279.2811, 0.34947848)
decoder loss ratio: 33095.284107, decoder SINDy loss  ratio: 0.602868
--- 0.31304192543029785 seconds for one epoch ---
--- 1.0185258388519287 seconds for one epoch ---
--- 0.316845178604126 seconds for one epoch ---
--- 1.0549156665802002 seconds for one epoch ---
--- 0.30886387825012207 seconds for one epoch ---
--- 1.0486438274383545 seconds for one epoch ---
--- 0.31583738327026367 seconds for one epoch ---
--- 1.0449028015136719 seconds for one epoch ---
--- 0.31015753746032715 seconds for one epoch ---
--- 1.0424220561981201 seconds for one epoch ---
--- 0.31219935417175293 seconds for one epoch ---
--- 1.0522470474243164 seconds for one epoch ---
--- 0.3034343719482422 seconds for one epoch ---
--- 1.0743062496185303 seconds for one epoch ---
--- 0.2930922508239746 seconds for one epoch ---
--- 1.0563910007476807 seconds for one epoch ---
--- 0.30787062644958496 seconds for one epoch ---
--- 1.06489896774292 seconds for one epoch ---
--- 0.31102514266967773 seconds for one epoch ---
--- 1.0583081245422363 seconds for one epoch ---
--- 0.3189280033111572 seconds for one epoch ---
--- 1.0554280281066895 seconds for one epoch ---
--- 0.3175697326660156 seconds for one epoch ---
--- 1.0633363723754883 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99493766]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-12.585112]
 [  0.      ]]
--- 0.29823899269104004 seconds for one epoch ---
Epoch 1800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3236.872802734375, (1495.2583, 1.3269736, 1739.9359, 0.35147092)
   validation loss 1074.7532958984375, (775.4304, 0.4806921, 298.49075, 0.35147092)
decoder loss ratio: 30041.520674, decoder SINDy loss  ratio: 0.644334
--- 0.26978063583374023 seconds for one epoch ---
--- 0.31078028678894043 seconds for one epoch ---
--- 1.035207748413086 seconds for one epoch ---
--- 0.30738353729248047 seconds for one epoch ---
--- 1.0397369861602783 seconds for one epoch ---
--- 0.30712413787841797 seconds for one epoch ---
--- 1.036802053451538 seconds for one epoch ---
--- 0.2991185188293457 seconds for one epoch ---
--- 1.0421311855316162 seconds for one epoch ---
--- 0.3207571506500244 seconds for one epoch ---
--- 1.0520615577697754 seconds for one epoch ---
--- 0.30754923820495605 seconds for one epoch ---
--- 1.0375843048095703 seconds for one epoch ---
--- 0.3137998580932617 seconds for one epoch ---
--- 1.0658378601074219 seconds for one epoch ---
--- 0.3190796375274658 seconds for one epoch ---
--- 1.0525548458099365 seconds for one epoch ---
--- 0.3237602710723877 seconds for one epoch ---
--- 1.0345730781555176 seconds for one epoch ---
--- 0.29404234886169434 seconds for one epoch ---
--- 1.0527539253234863 seconds for one epoch ---
--- 0.3081810474395752 seconds for one epoch ---
--- 1.0408141613006592 seconds for one epoch ---
--- 0.3139793872833252 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9952084]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-12.696777]
 [  0.      ]]
--- 0.25638318061828613 seconds for one epoch ---
Epoch 1825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4537.1513671875, (2522.0876, 10.966479, 2003.7438, 0.3534883)
   validation loss 1335.035888671875, (1020.59863, 0.4557014, 313.62805, 0.3534883)
decoder loss ratio: 39539.762872, decoder SINDy loss  ratio: 0.677010
--- 0.313812255859375 seconds for one epoch ---
--- 1.0695178508758545 seconds for one epoch ---
--- 0.28679466247558594 seconds for one epoch ---
--- 1.0929856300354004 seconds for one epoch ---
--- 0.3291802406311035 seconds for one epoch ---
--- 1.0528676509857178 seconds for one epoch ---
--- 0.31498098373413086 seconds for one epoch ---
--- 1.0624501705169678 seconds for one epoch ---
--- 0.32224249839782715 seconds for one epoch ---
--- 1.060678243637085 seconds for one epoch ---
--- 0.3238060474395752 seconds for one epoch ---
--- 1.0844504833221436 seconds for one epoch ---
--- 0.3163907527923584 seconds for one epoch ---
--- 1.076491355895996 seconds for one epoch ---
--- 0.31354856491088867 seconds for one epoch ---
--- 1.0356581211090088 seconds for one epoch ---
--- 0.31425046920776367 seconds for one epoch ---
--- 1.0585205554962158 seconds for one epoch ---
--- 0.33112311363220215 seconds for one epoch ---
--- 1.0602617263793945 seconds for one epoch ---
--- 0.31768155097961426 seconds for one epoch ---
--- 1.0868511199951172 seconds for one epoch ---
--- 0.30867886543273926 seconds for one epoch ---
--- 1.0898194313049316 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9954303]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-12.794286]
 [ -0.      ]]
--- 0.30396270751953125 seconds for one epoch ---
Epoch 1850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3796.0791015625, (1659.3075, 1.9783244, 2134.438, 0.35541022)
   validation loss 1282.9876708984375, (963.87354, 0.6121793, 318.14645, 0.35541022)
decoder loss ratio: 37342.134110, decoder SINDy loss  ratio: 0.686764
--- 0.2714412212371826 seconds for one epoch ---
--- 0.32623767852783203 seconds for one epoch ---
--- 1.084751844406128 seconds for one epoch ---
--- 0.3176403045654297 seconds for one epoch ---
--- 1.0886964797973633 seconds for one epoch ---
--- 0.29515790939331055 seconds for one epoch ---
--- 1.063490867614746 seconds for one epoch ---
--- 0.32193517684936523 seconds for one epoch ---
--- 1.0637874603271484 seconds for one epoch ---
--- 0.31377434730529785 seconds for one epoch ---
--- 1.08134126663208 seconds for one epoch ---
--- 0.3106238842010498 seconds for one epoch ---
--- 1.097102403640747 seconds for one epoch ---
--- 0.3024735450744629 seconds for one epoch ---
--- 1.0916028022766113 seconds for one epoch ---
--- 0.30296778678894043 seconds for one epoch ---
--- 1.111067295074463 seconds for one epoch ---
--- 0.3037753105163574 seconds for one epoch ---
--- 1.0785257816314697 seconds for one epoch ---
--- 0.33034539222717285 seconds for one epoch ---
--- 1.0851285457611084 seconds for one epoch ---
--- 0.3189876079559326 seconds for one epoch ---
--- 1.0874137878417969 seconds for one epoch ---
--- 0.3147768974304199 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99565566]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-12.898692]
 [  0.      ]]
--- 0.24970769882202148 seconds for one epoch ---
Epoch 1875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4587.015625, (2141.7485, 1.7248703, 2443.185, 0.35726961)
   validation loss 927.3964233398438, (635.03564, 0.48324648, 291.5202, 0.35726961)
decoder loss ratio: 24602.383340, decoder SINDy loss  ratio: 0.629287
--- 0.32328343391418457 seconds for one epoch ---
--- 1.077336311340332 seconds for one epoch ---
--- 0.3145887851715088 seconds for one epoch ---
--- 1.087217092514038 seconds for one epoch ---
--- 0.32004833221435547 seconds for one epoch ---
--- 1.08282470703125 seconds for one epoch ---
--- 0.3093380928039551 seconds for one epoch ---
--- 1.0688605308532715 seconds for one epoch ---
--- 0.317516565322876 seconds for one epoch ---
--- 1.1154377460479736 seconds for one epoch ---
--- 0.33010077476501465 seconds for one epoch ---
--- 1.120518445968628 seconds for one epoch ---
--- 0.32067298889160156 seconds for one epoch ---
--- 1.0934178829193115 seconds for one epoch ---
--- 0.30551910400390625 seconds for one epoch ---
--- 1.1128685474395752 seconds for one epoch ---
--- 0.317352294921875 seconds for one epoch ---
--- 1.1098949909210205 seconds for one epoch ---
--- 0.3178243637084961 seconds for one epoch ---
--- 1.0915215015411377 seconds for one epoch ---
--- 0.3232994079589844 seconds for one epoch ---
--- 1.0982441902160645 seconds for one epoch ---
--- 0.28977489471435547 seconds for one epoch ---
--- 1.1174750328063965 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9958887]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.013677]
 [ -0.      ]]
--- 0.3034532070159912 seconds for one epoch ---
Epoch 1900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3244.210205078125, (1944.5571, 0.92756724, 1298.3658, 0.35950094)
   validation loss 1310.064453125, (1006.68445, 0.39673412, 302.62378, 0.35950094)
decoder loss ratio: 39000.703206, decoder SINDy loss  ratio: 0.653256
--- 0.2639315128326416 seconds for one epoch ---
--- 0.3263096809387207 seconds for one epoch ---
--- 1.089221715927124 seconds for one epoch ---
--- 0.3177924156188965 seconds for one epoch ---
--- 1.086409330368042 seconds for one epoch ---
--- 0.32059264183044434 seconds for one epoch ---
--- 1.0835216045379639 seconds for one epoch ---
--- 0.31438374519348145 seconds for one epoch ---
--- 1.1017463207244873 seconds for one epoch ---
--- 0.3175387382507324 seconds for one epoch ---
--- 1.1138067245483398 seconds for one epoch ---
--- 0.3172309398651123 seconds for one epoch ---
--- 1.0843250751495361 seconds for one epoch ---
--- 0.309856653213501 seconds for one epoch ---
--- 1.1208717823028564 seconds for one epoch ---
--- 0.3063786029815674 seconds for one epoch ---
--- 1.0847582817077637 seconds for one epoch ---
--- 0.31779932975769043 seconds for one epoch ---
--- 1.1157457828521729 seconds for one epoch ---
--- 0.2947080135345459 seconds for one epoch ---
--- 1.1315422058105469 seconds for one epoch ---
--- 0.3093435764312744 seconds for one epoch ---
--- 1.091541051864624 seconds for one epoch ---
--- 0.3182351589202881 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9960467]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.095852]
 [ -0.      ]]
--- 0.25812435150146484 seconds for one epoch ---
Epoch 1925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4232.84912109375, (1497.9215, 3.5229278, 2731.0437, 0.36098167)
   validation loss 1552.2646484375, (1265.0735, 0.36662897, 286.46365, 0.36098167)
decoder loss ratio: 49011.143125, decoder SINDy loss  ratio: 0.618372
--- 0.3144822120666504 seconds for one epoch ---
--- 1.1035587787628174 seconds for one epoch ---
--- 0.31323671340942383 seconds for one epoch ---
--- 1.1087589263916016 seconds for one epoch ---
--- 0.31537413597106934 seconds for one epoch ---
--- 1.1144583225250244 seconds for one epoch ---
--- 0.32407546043395996 seconds for one epoch ---
--- 1.1127233505249023 seconds for one epoch ---
--- 0.3142533302307129 seconds for one epoch ---
--- 1.1133911609649658 seconds for one epoch ---
--- 0.30905675888061523 seconds for one epoch ---
--- 1.1060683727264404 seconds for one epoch ---
--- 0.3125438690185547 seconds for one epoch ---
--- 1.1064176559448242 seconds for one epoch ---
--- 0.3223731517791748 seconds for one epoch ---
--- 1.1003811359405518 seconds for one epoch ---
--- 0.3237738609313965 seconds for one epoch ---
--- 1.1221649646759033 seconds for one epoch ---
--- 0.31606626510620117 seconds for one epoch ---
--- 1.147151231765747 seconds for one epoch ---
--- 0.31873464584350586 seconds for one epoch ---
--- 1.1408641338348389 seconds for one epoch ---
--- 0.3146476745605469 seconds for one epoch ---
--- 1.1133184432983398 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9961988]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.179178]
 [  0.      ]]
--- 0.28401923179626465 seconds for one epoch ---
Epoch 1950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3445.049072265625, (1405.9015, 1.4708354, 2037.3141, 0.36264238)
   validation loss 703.05322265625, (442.1444, 0.43058515, 260.11554, 0.36264238)
decoder loss ratio: 17129.442008, decoder SINDy loss  ratio: 0.561496
--- 0.25811123847961426 seconds for one epoch ---
--- 0.3177013397216797 seconds for one epoch ---
--- 1.1027448177337646 seconds for one epoch ---
--- 0.32937049865722656 seconds for one epoch ---
--- 1.1296167373657227 seconds for one epoch ---
--- 0.3127882480621338 seconds for one epoch ---
--- 1.126089096069336 seconds for one epoch ---
--- 0.32858920097351074 seconds for one epoch ---
--- 1.1137676239013672 seconds for one epoch ---
--- 0.3099987506866455 seconds for one epoch ---
--- 1.1324419975280762 seconds for one epoch ---
--- 0.3228142261505127 seconds for one epoch ---
--- 1.1287150382995605 seconds for one epoch ---
--- 0.31781959533691406 seconds for one epoch ---
--- 1.1223008632659912 seconds for one epoch ---
--- 0.31705236434936523 seconds for one epoch ---
--- 1.1074776649475098 seconds for one epoch ---
--- 0.3158233165740967 seconds for one epoch ---
--- 1.1442880630493164 seconds for one epoch ---
--- 0.3137836456298828 seconds for one epoch ---
--- 1.1002068519592285 seconds for one epoch ---
--- 0.32571911811828613 seconds for one epoch ---
--- 1.1216630935668945 seconds for one epoch ---
--- 0.3020913600921631 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9963733]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-13.27906]
 [  0.     ]]
--- 0.2613182067871094 seconds for one epoch ---
Epoch 1975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2049.6650390625, (977.9896, 0.94000477, 1070.3708, 0.36455715)
   validation loss 931.0250244140625, (612.8509, 0.5076536, 317.30194, 0.36455715)
decoder loss ratio: 23742.907478, decoder SINDy loss  ratio: 0.684941
--- 0.3107438087463379 seconds for one epoch ---
--- 1.1440141201019287 seconds for one epoch ---
--- 0.3209571838378906 seconds for one epoch ---
--- 1.112227201461792 seconds for one epoch ---
--- 0.3169825077056885 seconds for one epoch ---
--- 1.1024606227874756 seconds for one epoch ---
--- 0.31689929962158203 seconds for one epoch ---
--- 1.1290512084960938 seconds for one epoch ---
--- 0.313521146774292 seconds for one epoch ---
--- 1.1226601600646973 seconds for one epoch ---
--- 0.31878137588500977 seconds for one epoch ---
--- 1.1275725364685059 seconds for one epoch ---
--- 0.3189542293548584 seconds for one epoch ---
--- 1.1567115783691406 seconds for one epoch ---
--- 0.3182637691497803 seconds for one epoch ---
--- 1.1598830223083496 seconds for one epoch ---
--- 0.30571675300598145 seconds for one epoch ---
--- 1.1345224380493164 seconds for one epoch ---
--- 0.3121778964996338 seconds for one epoch ---
--- 1.138375997543335 seconds for one epoch ---
--- 0.3164961338043213 seconds for one epoch ---
--- 1.159994125366211 seconds for one epoch ---
--- 0.32117128372192383 seconds for one epoch ---
--- 1.1829495429992676 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9965317]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.375089]
 [ -0.      ]]
--- 0.2964200973510742 seconds for one epoch ---
Epoch 2000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5115.3427734375, (2564.9314, 3.9695175, 2546.0754, 0.3663075)
   validation loss 832.9005737304688, (546.7953, 0.5098995, 285.22906, 0.3663075)
decoder loss ratio: 21183.798739, decoder SINDy loss  ratio: 0.615707
THRESHOLDING: 1 active coefficients
--- 1.1478347778320312 seconds for one epoch ---
--- 0.32195281982421875 seconds for one epoch ---
--- 1.1163887977600098 seconds for one epoch ---
--- 0.31768035888671875 seconds for one epoch ---
--- 1.1540031433105469 seconds for one epoch ---
--- 0.32231688499450684 seconds for one epoch ---
--- 1.1569480895996094 seconds for one epoch ---
--- 0.3213222026824951 seconds for one epoch ---
--- 1.176177740097046 seconds for one epoch ---
--- 0.32242441177368164 seconds for one epoch ---
--- 1.1547229290008545 seconds for one epoch ---
--- 0.31351232528686523 seconds for one epoch ---
--- 1.1029584407806396 seconds for one epoch ---
--- 0.31844139099121094 seconds for one epoch ---
--- 1.1793663501739502 seconds for one epoch ---
--- 0.3199608325958252 seconds for one epoch ---
--- 1.1703894138336182 seconds for one epoch ---
--- 0.3212924003601074 seconds for one epoch ---
--- 1.1343743801116943 seconds for one epoch ---
--- 0.3190593719482422 seconds for one epoch ---
--- 1.1488800048828125 seconds for one epoch ---
--- 0.31070446968078613 seconds for one epoch ---
--- 1.1507759094238281 seconds for one epoch ---
--- 0.3276526927947998 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99666345]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-13.459277]
 [ -0.      ]]
--- 0.2667863368988037 seconds for one epoch ---
Epoch 2025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2725.405517578125, (1338.2203, 2.3938708, 1384.4298, 0.36151788)
   validation loss 922.4209594726562, (606.541, 0.45299783, 315.0654, 0.36151788)
decoder loss ratio: 23498.451947, decoder SINDy loss  ratio: 0.680113
--- 0.27669763565063477 seconds for one epoch ---
--- 1.1470048427581787 seconds for one epoch ---
--- 0.3175685405731201 seconds for one epoch ---
--- 1.133789300918579 seconds for one epoch ---
--- 0.30393552780151367 seconds for one epoch ---
--- 1.1620824337005615 seconds for one epoch ---
--- 0.3207738399505615 seconds for one epoch ---
--- 1.1610219478607178 seconds for one epoch ---
--- 0.3244762420654297 seconds for one epoch ---
--- 1.1524689197540283 seconds for one epoch ---
--- 0.30235719680786133 seconds for one epoch ---
--- 1.1338064670562744 seconds for one epoch ---
--- 0.3249504566192627 seconds for one epoch ---
--- 1.144580364227295 seconds for one epoch ---
--- 0.32027149200439453 seconds for one epoch ---
--- 1.1621084213256836 seconds for one epoch ---
--- 0.31684017181396484 seconds for one epoch ---
--- 1.1798956394195557 seconds for one epoch ---
--- 0.3344542980194092 seconds for one epoch ---
--- 1.1755542755126953 seconds for one epoch ---
--- 0.31808924674987793 seconds for one epoch ---
--- 1.1599128246307373 seconds for one epoch ---
--- 0.3256509304046631 seconds for one epoch ---
--- 1.178584098815918 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9967947]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.546315]
 [  0.      ]]
--- 0.3009498119354248 seconds for one epoch ---
Epoch 2050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2211.144287109375, (1031.2462, 4.616514, 1174.9183, 0.3633134)
   validation loss 1243.0653076171875, (933.62823, 0.4313806, 308.6424, 0.3633134)
decoder loss ratio: 36170.378668, decoder SINDy loss  ratio: 0.666248
--- 0.24768877029418945 seconds for one epoch ---
--- 0.31671619415283203 seconds for one epoch ---
--- 1.1577796936035156 seconds for one epoch ---
--- 0.31469178199768066 seconds for one epoch ---
--- 1.177436351776123 seconds for one epoch ---
--- 0.3194727897644043 seconds for one epoch ---
--- 1.1826136112213135 seconds for one epoch ---
--- 0.30658984184265137 seconds for one epoch ---
--- 1.18031644821167 seconds for one epoch ---
--- 0.3319978713989258 seconds for one epoch ---
--- 1.168715000152588 seconds for one epoch ---
--- 0.3076801300048828 seconds for one epoch ---
--- 1.1558470726013184 seconds for one epoch ---
--- 0.32100677490234375 seconds for one epoch ---
--- 1.1777079105377197 seconds for one epoch ---
--- 0.32006263732910156 seconds for one epoch ---
--- 1.1928503513336182 seconds for one epoch ---
--- 0.33148193359375 seconds for one epoch ---
--- 1.1807756423950195 seconds for one epoch ---
--- 0.3099350929260254 seconds for one epoch ---
--- 1.1918056011199951 seconds for one epoch ---
--- 0.32286643981933594 seconds for one epoch ---
--- 1.1801064014434814 seconds for one epoch ---
--- 0.3039820194244385 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9969093]
 [0.       ]]
[[  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [-13.6269045]
 [ -0.       ]]
--- 0.26642370223999023 seconds for one epoch ---
Epoch 2075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3086.375244140625, (1582.3948, 0.8467403, 1502.7688, 0.36488414)
   validation loss 731.9285278320312, (465.68347, 0.5865209, 265.29367, 0.36488414)
decoder loss ratio: 18041.386155, decoder SINDy loss  ratio: 0.572674
--- 0.3169217109680176 seconds for one epoch ---
--- 1.1556053161621094 seconds for one epoch ---
--- 0.313201904296875 seconds for one epoch ---
--- 1.1245179176330566 seconds for one epoch ---
--- 0.31601905822753906 seconds for one epoch ---
--- 1.1520745754241943 seconds for one epoch ---
--- 0.31510114669799805 seconds for one epoch ---
--- 1.1710069179534912 seconds for one epoch ---
--- 0.3199727535247803 seconds for one epoch ---
--- 1.2127115726470947 seconds for one epoch ---
--- 0.33236122131347656 seconds for one epoch ---
--- 1.1740531921386719 seconds for one epoch ---
--- 0.31119513511657715 seconds for one epoch ---
--- 1.1835925579071045 seconds for one epoch ---
--- 0.31940484046936035 seconds for one epoch ---
--- 1.2270801067352295 seconds for one epoch ---
--- 0.3206784725189209 seconds for one epoch ---
--- 1.209423542022705 seconds for one epoch ---
--- 0.3160557746887207 seconds for one epoch ---
--- 1.1986491680145264 seconds for one epoch ---
--- 0.3354525566101074 seconds for one epoch ---
--- 1.2044627666473389 seconds for one epoch ---
--- 0.3240225315093994 seconds for one epoch ---
--- 1.2105002403259277 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9970108]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-13.700653]
 [  0.      ]]
--- 0.3065216541290283 seconds for one epoch ---
Epoch 2100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2323.193115234375, (1265.9888, 0.9976412, 1055.8402, 0.36635545)
   validation loss 1490.7183837890625, (1184.5145, 0.5707175, 305.2668, 0.36635545)
decoder loss ratio: 45890.149159, decoder SINDy loss  ratio: 0.658961
--- 0.2603793144226074 seconds for one epoch ---
--- 0.31792140007019043 seconds for one epoch ---
--- 1.1984102725982666 seconds for one epoch ---
--- 0.31169986724853516 seconds for one epoch ---
--- 1.1737785339355469 seconds for one epoch ---
--- 0.3310885429382324 seconds for one epoch ---
--- 1.1810250282287598 seconds for one epoch ---
--- 0.3133120536804199 seconds for one epoch ---
--- 1.1686925888061523 seconds for one epoch ---
--- 0.31085634231567383 seconds for one epoch ---
--- 1.2115375995635986 seconds for one epoch ---
--- 0.30627918243408203 seconds for one epoch ---
--- 1.210531234741211 seconds for one epoch ---
--- 0.31538915634155273 seconds for one epoch ---
--- 1.2038648128509521 seconds for one epoch ---
--- 0.32136011123657227 seconds for one epoch ---
--- 1.2024562358856201 seconds for one epoch ---
--- 0.32428956031799316 seconds for one epoch ---
--- 1.207648754119873 seconds for one epoch ---
--- 0.319364070892334 seconds for one epoch ---
--- 1.1849024295806885 seconds for one epoch ---
--- 0.31946253776550293 seconds for one epoch ---
--- 1.2262332439422607 seconds for one epoch ---
--- 0.31844139099121094 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9971104]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [-13.77602]
 [ -0.     ]]
--- 0.270810604095459 seconds for one epoch ---
Epoch 2125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2313.490966796875, (964.90564, 2.140032, 1346.0775, 0.367879)
   validation loss 678.8512573242188, (407.2368, 0.54377884, 270.7028, 0.367879)
decoder loss ratio: 15777.060079, decoder SINDy loss  ratio: 0.584350
--- 0.3250560760498047 seconds for one epoch ---
--- 1.1798839569091797 seconds for one epoch ---
--- 0.3122828006744385 seconds for one epoch ---
--- 1.181487798690796 seconds for one epoch ---
--- 0.3235924243927002 seconds for one epoch ---
--- 1.2134535312652588 seconds for one epoch ---
--- 0.31177592277526855 seconds for one epoch ---
--- 1.2264125347137451 seconds for one epoch ---
--- 0.3111758232116699 seconds for one epoch ---
--- 1.2066290378570557 seconds for one epoch ---
--- 0.31975507736206055 seconds for one epoch ---
--- 1.206146240234375 seconds for one epoch ---
--- 0.3162810802459717 seconds for one epoch ---
--- 1.2171387672424316 seconds for one epoch ---
--- 0.32579708099365234 seconds for one epoch ---
--- 1.2034084796905518 seconds for one epoch ---
--- 0.3113572597503662 seconds for one epoch ---
--- 1.2138473987579346 seconds for one epoch ---
--- 0.310457706451416 seconds for one epoch ---
--- 1.2151918411254883 seconds for one epoch ---
--- 0.30333399772644043 seconds for one epoch ---
--- 1.2338860034942627 seconds for one epoch ---
--- 0.31276941299438477 seconds for one epoch ---
--- 1.1939342021942139 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.997188]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-13.836904]
 [  0.      ]]
--- 0.2976570129394531 seconds for one epoch ---
Epoch 2150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3619.016357421875, (1931.6216, 0.50594616, 1686.5197, 0.3691183)
   validation loss 1710.6204833984375, (1370.359, 0.4896864, 339.4026, 0.3691183)
decoder loss ratio: 53090.087048, decoder SINDy loss  ratio: 0.732648
--- 0.26041579246520996 seconds for one epoch ---
--- 0.3203117847442627 seconds for one epoch ---
--- 1.1945910453796387 seconds for one epoch ---
--- 0.32132840156555176 seconds for one epoch ---
--- 1.1919760704040527 seconds for one epoch ---
--- 0.3335416316986084 seconds for one epoch ---
--- 1.1958258152008057 seconds for one epoch ---
--- 0.32067108154296875 seconds for one epoch ---
--- 1.2027637958526611 seconds for one epoch ---
--- 0.3099937438964844 seconds for one epoch ---
--- 1.2070882320404053 seconds for one epoch ---
--- 0.2998771667480469 seconds for one epoch ---
--- 1.1953697204589844 seconds for one epoch ---
--- 0.32918262481689453 seconds for one epoch ---
--- 1.226055383682251 seconds for one epoch ---
--- 0.3129918575286865 seconds for one epoch ---
--- 1.2310261726379395 seconds for one epoch ---
--- 0.31168127059936523 seconds for one epoch ---
--- 1.2281746864318848 seconds for one epoch ---
--- 0.31585216522216797 seconds for one epoch ---
--- 1.1945686340332031 seconds for one epoch ---
--- 0.3148932456970215 seconds for one epoch ---
--- 1.231421947479248 seconds for one epoch ---
--- 0.3138151168823242 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9972618]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-13.897367]
 [  0.      ]]
--- 0.25391721725463867 seconds for one epoch ---
Epoch 2175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2769.881103515625, (1363.2993, 1.0924493, 1405.1191, 0.37034452)
   validation loss 770.1658935546875, (513.0519, 0.48586932, 256.2578, 0.37034452)
decoder loss ratio: 19876.520524, decoder SINDy loss  ratio: 0.553169
--- 0.31027650833129883 seconds for one epoch ---
--- 1.2153079509735107 seconds for one epoch ---
--- 0.3098452091217041 seconds for one epoch ---
--- 1.228158950805664 seconds for one epoch ---
--- 0.312213659286499 seconds for one epoch ---
--- 1.2089979648590088 seconds for one epoch ---
--- 0.319974422454834 seconds for one epoch ---
--- 1.2175981998443604 seconds for one epoch ---
--- 0.3260810375213623 seconds for one epoch ---
--- 1.2122752666473389 seconds for one epoch ---
--- 0.3234672546386719 seconds for one epoch ---
--- 1.2312004566192627 seconds for one epoch ---
--- 0.3357987403869629 seconds for one epoch ---
--- 1.2163774967193604 seconds for one epoch ---
--- 0.3136279582977295 seconds for one epoch ---
--- 1.2395446300506592 seconds for one epoch ---
--- 0.31843137741088867 seconds for one epoch ---
--- 1.257368803024292 seconds for one epoch ---
--- 0.31019115447998047 seconds for one epoch ---
--- 1.2223105430603027 seconds for one epoch ---
--- 0.3306870460510254 seconds for one epoch ---
--- 1.205345869064331 seconds for one epoch ---
--- 0.3156166076660156 seconds for one epoch ---
--- 1.2363934516906738 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9973625]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-13.982179]
 [ -0.      ]]
--- 0.27518320083618164 seconds for one epoch ---
Epoch 2200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3578.79443359375, (1117.4299, 1.980479, 2459.012, 0.37210998)
   validation loss 963.9476318359375, (685.0512, 0.6011164, 277.92316, 0.37210998)
decoder loss ratio: 26540.073118, decoder SINDy loss  ratio: 0.599936
--- 0.26392269134521484 seconds for one epoch ---
--- 0.3351006507873535 seconds for one epoch ---
--- 1.2174720764160156 seconds for one epoch ---
--- 0.30852842330932617 seconds for one epoch ---
--- 1.2221181392669678 seconds for one epoch ---
--- 0.3168666362762451 seconds for one epoch ---
--- 1.2383642196655273 seconds for one epoch ---
--- 0.3160099983215332 seconds for one epoch ---
--- 1.2121293544769287 seconds for one epoch ---
--- 0.3015632629394531 seconds for one epoch ---
--- 1.2286107540130615 seconds for one epoch ---
--- 0.32682085037231445 seconds for one epoch ---
--- 1.2348933219909668 seconds for one epoch ---
--- 0.3292815685272217 seconds for one epoch ---
--- 1.2084088325500488 seconds for one epoch ---
--- 0.3156733512878418 seconds for one epoch ---
--- 1.2308316230773926 seconds for one epoch ---
--- 0.31754469871520996 seconds for one epoch ---
--- 1.237128496170044 seconds for one epoch ---
--- 0.32317376136779785 seconds for one epoch ---
--- 1.2287781238555908 seconds for one epoch ---
--- 0.3195686340332031 seconds for one epoch ---
--- 1.2599141597747803 seconds for one epoch ---
--- 0.31404685974121094 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9974193]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.031347]
 [  0.      ]]
--- 0.2532172203063965 seconds for one epoch ---
Epoch 2225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3577.87255859375, (971.5916, 1.1191894, 2604.7886, 0.37310502)
   validation loss 855.9581909179688, (586.123, 0.5874666, 268.8746, 0.37310502)
decoder loss ratio: 22707.422026, decoder SINDy loss  ratio: 0.580404
--- 0.30846619606018066 seconds for one epoch ---
--- 1.2337696552276611 seconds for one epoch ---
--- 0.32062625885009766 seconds for one epoch ---
--- 1.256448745727539 seconds for one epoch ---
--- 0.31815385818481445 seconds for one epoch ---
--- 1.2380363941192627 seconds for one epoch ---
--- 0.31793880462646484 seconds for one epoch ---
--- 1.2802176475524902 seconds for one epoch ---
--- 0.330350399017334 seconds for one epoch ---
--- 1.2267770767211914 seconds for one epoch ---
--- 0.31925272941589355 seconds for one epoch ---
--- 1.2262063026428223 seconds for one epoch ---
--- 0.32337474822998047 seconds for one epoch ---
--- 1.253943920135498 seconds for one epoch ---
--- 0.313356876373291 seconds for one epoch ---
--- 1.271514654159546 seconds for one epoch ---
--- 0.309983491897583 seconds for one epoch ---
--- 1.2545902729034424 seconds for one epoch ---
--- 0.3019599914550781 seconds for one epoch ---
--- 1.2393357753753662 seconds for one epoch ---
--- 0.32289671897888184 seconds for one epoch ---
--- 1.2552075386047363 seconds for one epoch ---
--- 0.3149874210357666 seconds for one epoch ---
--- 1.277916669845581 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9975001]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.104616]
 [ -0.      ]]
--- 0.29603028297424316 seconds for one epoch ---
Epoch 2250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2336.488525390625, (1525.4137, 6.781802, 803.9185, 0.3745771)
   validation loss 769.4059448242188, (498.31598, 0.51477385, 270.2006, 0.3745771)
decoder loss ratio: 19305.626141, decoder SINDy loss  ratio: 0.583266
--- 0.2648794651031494 seconds for one epoch ---
--- 0.3196108341217041 seconds for one epoch ---
--- 1.2481639385223389 seconds for one epoch ---
--- 0.2999577522277832 seconds for one epoch ---
--- 1.285869836807251 seconds for one epoch ---
--- 0.30824732780456543 seconds for one epoch ---
--- 1.2468416690826416 seconds for one epoch ---
--- 0.3208284378051758 seconds for one epoch ---
--- 1.2556426525115967 seconds for one epoch ---
--- 0.3038899898529053 seconds for one epoch ---
--- 1.2691097259521484 seconds for one epoch ---
--- 0.330751895904541 seconds for one epoch ---
--- 1.259885311126709 seconds for one epoch ---
--- 0.3247394561767578 seconds for one epoch ---
--- 1.283942699432373 seconds for one epoch ---
--- 0.31482434272766113 seconds for one epoch ---
--- 1.238598346710205 seconds for one epoch ---
--- 0.3191390037536621 seconds for one epoch ---
--- 1.2812385559082031 seconds for one epoch ---
--- 0.3200702667236328 seconds for one epoch ---
--- 1.2499980926513672 seconds for one epoch ---
--- 0.314054012298584 seconds for one epoch ---
--- 1.2895803451538086 seconds for one epoch ---
--- 0.3155951499938965 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9975648]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.164318]
 [ -0.      ]]
--- 0.24803614616394043 seconds for one epoch ---
Epoch 2275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3141.839111328125, (1482.6283, 2.096423, 1656.7385, 0.3758037)
   validation loss 1480.9215087890625, (1174.0721, 0.61020017, 305.86328, 0.3758037)
decoder loss ratio: 45485.593120, decoder SINDy loss  ratio: 0.660249
--- 0.31922435760498047 seconds for one epoch ---
--- 1.2386763095855713 seconds for one epoch ---
--- 0.3284940719604492 seconds for one epoch ---
--- 1.2515795230865479 seconds for one epoch ---
--- 0.316347599029541 seconds for one epoch ---
--- 1.2508139610290527 seconds for one epoch ---
--- 0.315335750579834 seconds for one epoch ---
--- 1.294741153717041 seconds for one epoch ---
--- 0.3126661777496338 seconds for one epoch ---
--- 1.2536125183105469 seconds for one epoch ---
--- 0.312530517578125 seconds for one epoch ---
--- 1.2649991512298584 seconds for one epoch ---
--- 0.3101344108581543 seconds for one epoch ---
--- 1.2888703346252441 seconds for one epoch ---
--- 0.32100701332092285 seconds for one epoch ---
--- 1.2813215255737305 seconds for one epoch ---
--- 0.33415961265563965 seconds for one epoch ---
--- 1.2663438320159912 seconds for one epoch ---
--- 0.3144688606262207 seconds for one epoch ---
--- 1.283811092376709 seconds for one epoch ---
--- 0.3171675205230713 seconds for one epoch ---
--- 1.2778592109680176 seconds for one epoch ---
--- 0.31963634490966797 seconds for one epoch ---
--- 1.280569314956665 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9976209]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.218379]
 [  0.      ]]
--- 0.30508899688720703 seconds for one epoch ---
Epoch 2300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3267.9130859375, (1501.9894, 0.69410914, 1764.8525, 0.37702012)
   validation loss 956.828369140625, (700.1595, 0.5816002, 255.71027, 0.37702012)
decoder loss ratio: 27125.393974, decoder SINDy loss  ratio: 0.551987
--- 0.259368896484375 seconds for one epoch ---
--- 0.3164656162261963 seconds for one epoch ---
--- 1.2975449562072754 seconds for one epoch ---
--- 0.32205843925476074 seconds for one epoch ---
--- 1.2945818901062012 seconds for one epoch ---
--- 0.3277852535247803 seconds for one epoch ---
--- 1.2777531147003174 seconds for one epoch ---
--- 0.3278014659881592 seconds for one epoch ---
--- 1.298490285873413 seconds for one epoch ---
--- 0.33667635917663574 seconds for one epoch ---
--- 1.2747998237609863 seconds for one epoch ---
--- 0.32251715660095215 seconds for one epoch ---
--- 1.2773001194000244 seconds for one epoch ---
--- 0.317371129989624 seconds for one epoch ---
--- 1.2992539405822754 seconds for one epoch ---
--- 0.3231678009033203 seconds for one epoch ---
--- 1.287442684173584 seconds for one epoch ---
--- 0.3234255313873291 seconds for one epoch ---
--- 1.3110299110412598 seconds for one epoch ---
--- 0.5744426250457764 seconds for one epoch ---
--- 1.2839248180389404 seconds for one epoch ---
--- 0.31757164001464844 seconds for one epoch ---
--- 1.327390432357788 seconds for one epoch ---
--- 0.3182058334350586 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9976794]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.277077]
 [  0.      ]]
--- 0.27051806449890137 seconds for one epoch ---
Epoch 2325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4138.26171875, (2191.958, 0.8241943, 1945.1016, 0.37808964)
   validation loss 835.3223266601562, (566.0332, 0.51490396, 268.39615, 0.37808964)
decoder loss ratio: 21929.108966, decoder SINDy loss  ratio: 0.579371
--- 0.3176147937774658 seconds for one epoch ---
--- 1.2981650829315186 seconds for one epoch ---
--- 0.31920528411865234 seconds for one epoch ---
--- 1.2966601848602295 seconds for one epoch ---
--- 0.33718395233154297 seconds for one epoch ---
--- 1.2851696014404297 seconds for one epoch ---
--- 0.3200967311859131 seconds for one epoch ---
--- 1.2928614616394043 seconds for one epoch ---
--- 0.32753586769104004 seconds for one epoch ---
--- 1.3260688781738281 seconds for one epoch ---
--- 0.29826951026916504 seconds for one epoch ---
--- 1.2901928424835205 seconds for one epoch ---
--- 0.326352596282959 seconds for one epoch ---
--- 1.330409288406372 seconds for one epoch ---
--- 0.31111884117126465 seconds for one epoch ---
--- 1.3076307773590088 seconds for one epoch ---
--- 0.3256847858428955 seconds for one epoch ---
--- 1.3137750625610352 seconds for one epoch ---
--- 0.3317723274230957 seconds for one epoch ---
--- 1.2906773090362549 seconds for one epoch ---
--- 0.32300376892089844 seconds for one epoch ---
--- 1.273216962814331 seconds for one epoch ---
--- 0.32185816764831543 seconds for one epoch ---
--- 1.2882680892944336 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977325]
 [0.       ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-14.3307085]
 [ -0.       ]]
--- 0.30112648010253906 seconds for one epoch ---
Epoch 2350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4569.048828125, (1450.5706, 1.3343257, 3116.7644, 0.3792586)
   validation loss 899.03271484375, (622.7142, 0.46606797, 275.47324, 0.3792586)
decoder loss ratio: 24125.028117, decoder SINDy loss  ratio: 0.594648
--- 0.27805209159851074 seconds for one epoch ---
--- 0.32073187828063965 seconds for one epoch ---
--- 1.311765193939209 seconds for one epoch ---
--- 0.31559276580810547 seconds for one epoch ---
--- 1.3172316551208496 seconds for one epoch ---
--- 0.3294808864593506 seconds for one epoch ---
--- 1.3038852214813232 seconds for one epoch ---
--- 0.3161299228668213 seconds for one epoch ---
--- 1.2980365753173828 seconds for one epoch ---
--- 0.3139207363128662 seconds for one epoch ---
--- 1.314934253692627 seconds for one epoch ---
--- 0.31902003288269043 seconds for one epoch ---
--- 1.2837209701538086 seconds for one epoch ---
--- 0.3137640953063965 seconds for one epoch ---
--- 1.303812026977539 seconds for one epoch ---
--- 0.32172250747680664 seconds for one epoch ---
--- 1.3090100288391113 seconds for one epoch ---
--- 0.31987810134887695 seconds for one epoch ---
--- 1.3156933784484863 seconds for one epoch ---
--- 0.3253629207611084 seconds for one epoch ---
--- 1.3033206462860107 seconds for one epoch ---
--- 0.31468939781188965 seconds for one epoch ---
--- 1.3119924068450928 seconds for one epoch ---
--- 0.32312893867492676 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977917]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.393486]
 [ -0.      ]]
--- 0.2456963062286377 seconds for one epoch ---
Epoch 2375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3051.217041015625, (1204.1389, 0.31632945, 1846.3812, 0.38065)
   validation loss 814.7720947265625, (570.3391, 0.5613461, 243.49098, 0.38065)
decoder loss ratio: 22095.927325, decoder SINDy loss  ratio: 0.525610
--- 0.3154153823852539 seconds for one epoch ---
--- 1.3120481967926025 seconds for one epoch ---
--- 0.3174734115600586 seconds for one epoch ---
--- 1.2974650859832764 seconds for one epoch ---
--- 0.3263256549835205 seconds for one epoch ---
--- 1.3159472942352295 seconds for one epoch ---
--- 0.32013463973999023 seconds for one epoch ---
--- 1.3247482776641846 seconds for one epoch ---
--- 0.3110380172729492 seconds for one epoch ---
--- 1.3313307762145996 seconds for one epoch ---
--- 0.3084697723388672 seconds for one epoch ---
--- 1.3019323348999023 seconds for one epoch ---
--- 0.3147013187408447 seconds for one epoch ---
--- 1.322674036026001 seconds for one epoch ---
--- 0.3151843547821045 seconds for one epoch ---
--- 1.3141145706176758 seconds for one epoch ---
--- 0.3215451240539551 seconds for one epoch ---
--- 1.327592134475708 seconds for one epoch ---
--- 0.32092833518981934 seconds for one epoch ---
--- 1.3169543743133545 seconds for one epoch ---
--- 0.32639050483703613 seconds for one epoch ---
--- 1.308284044265747 seconds for one epoch ---
--- 0.3131253719329834 seconds for one epoch ---
--- 1.3383383750915527 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9978644]
 [0.       ]]
[[ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [-14.4726095]
 [  0.       ]]
--- 0.29788827896118164 seconds for one epoch ---
Epoch 2400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2399.146484375, (1011.92035, 1.9574578, 1384.8864, 0.38227248)
   validation loss 1012.6073608398438, (734.9861, 0.6041547, 276.6349, 0.38227248)
decoder loss ratio: 28474.636886, decoder SINDy loss  ratio: 0.597155
--- 0.2694077491760254 seconds for one epoch ---
--- 0.3135042190551758 seconds for one epoch ---
--- 1.3247320652008057 seconds for one epoch ---
--- 0.28026890754699707 seconds for one epoch ---
--- 1.3234264850616455 seconds for one epoch ---
--- 0.32154273986816406 seconds for one epoch ---
--- 1.3209104537963867 seconds for one epoch ---
--- 0.3084075450897217 seconds for one epoch ---
--- 1.340824842453003 seconds for one epoch ---
--- 0.32318115234375 seconds for one epoch ---
--- 1.291579008102417 seconds for one epoch ---
--- 0.3083353042602539 seconds for one epoch ---
--- 1.3119816780090332 seconds for one epoch ---
--- 0.32660770416259766 seconds for one epoch ---
--- 1.3143484592437744 seconds for one epoch ---
--- 0.3004953861236572 seconds for one epoch ---
--- 1.3298366069793701 seconds for one epoch ---
--- 0.32201623916625977 seconds for one epoch ---
--- 1.327676773071289 seconds for one epoch ---
--- 0.3169581890106201 seconds for one epoch ---
--- 1.3188235759735107 seconds for one epoch ---
--- 0.30762815475463867 seconds for one epoch ---
--- 1.358314037322998 seconds for one epoch ---
--- 0.31877946853637695 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99790776]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.520957]
 [ -0.      ]]
--- 0.26342296600341797 seconds for one epoch ---
Epoch 2425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3297.8671875, (1827.6598, 1.5510042, 1468.2731, 0.38329685)
   validation loss 832.34765625, (568.9327, 0.5176231, 262.51407, 0.38329685)
decoder loss ratio: 22041.439665, decoder SINDy loss  ratio: 0.566674
--- 0.3046891689300537 seconds for one epoch ---
--- 1.3178291320800781 seconds for one epoch ---
--- 0.3224647045135498 seconds for one epoch ---
--- 1.345625877380371 seconds for one epoch ---
--- 0.30571866035461426 seconds for one epoch ---
--- 1.3302114009857178 seconds for one epoch ---
--- 0.3152599334716797 seconds for one epoch ---
--- 1.3685026168823242 seconds for one epoch ---
--- 0.3311769962310791 seconds for one epoch ---
--- 1.3569912910461426 seconds for one epoch ---
--- 0.3189966678619385 seconds for one epoch ---
--- 1.3469250202178955 seconds for one epoch ---
--- 0.3325343132019043 seconds for one epoch ---
--- 1.3493092060089111 seconds for one epoch ---
--- 0.31644225120544434 seconds for one epoch ---
--- 1.31675386428833 seconds for one epoch ---
--- 0.31159377098083496 seconds for one epoch ---
--- 1.370703935623169 seconds for one epoch ---
--- 0.31249547004699707 seconds for one epoch ---
--- 1.352489709854126 seconds for one epoch ---
--- 0.3096804618835449 seconds for one epoch ---
--- 1.3129785060882568 seconds for one epoch ---
--- 0.32041335105895996 seconds for one epoch ---
--- 1.3548011779785156 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9979529]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.573194]
 [  0.      ]]
--- 0.31130194664001465 seconds for one epoch ---
Epoch 2450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4123.43603515625, (1549.7992, 1.3903332, 2571.862, 0.38444605)
   validation loss 784.5447998046875, (524.7514, 0.5512155, 258.85773, 0.38444605)
decoder loss ratio: 20329.780392, decoder SINDy loss  ratio: 0.558781
--- 0.2631561756134033 seconds for one epoch ---
--- 0.30113935470581055 seconds for one epoch ---
--- 1.3248388767242432 seconds for one epoch ---
--- 0.33033323287963867 seconds for one epoch ---
--- 1.3291513919830322 seconds for one epoch ---
--- 0.3187088966369629 seconds for one epoch ---
--- 1.3635344505310059 seconds for one epoch ---
--- 0.31354641914367676 seconds for one epoch ---
--- 1.349623203277588 seconds for one epoch ---
--- 0.3175084590911865 seconds for one epoch ---
--- 1.3365716934204102 seconds for one epoch ---
--- 0.280928373336792 seconds for one epoch ---
--- 1.3386547565460205 seconds for one epoch ---
--- 0.32303333282470703 seconds for one epoch ---
--- 1.3514585494995117 seconds for one epoch ---
--- 0.3206157684326172 seconds for one epoch ---
--- 1.3638885021209717 seconds for one epoch ---
--- 0.3171679973602295 seconds for one epoch ---
--- 1.3383195400238037 seconds for one epoch ---
--- 0.31391406059265137 seconds for one epoch ---
--- 1.3542799949645996 seconds for one epoch ---
--- 0.3118915557861328 seconds for one epoch ---
--- 1.3444321155548096 seconds for one epoch ---
--- 0.31425046920776367 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9979931]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.621528]
 [ -0.      ]]
--- 0.250136137008667 seconds for one epoch ---
Epoch 2475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3241.18896484375, (1361.8932, 0.6545963, 1878.2557, 0.38543516)
   validation loss 839.60302734375, (596.33014, 0.56319773, 242.32428, 0.38543516)
decoder loss ratio: 23102.864866, decoder SINDy loss  ratio: 0.523091
--- 0.3198847770690918 seconds for one epoch ---
--- 1.3566207885742188 seconds for one epoch ---
--- 0.3224782943725586 seconds for one epoch ---
--- 1.3503825664520264 seconds for one epoch ---
--- 0.3279390335083008 seconds for one epoch ---
--- 1.3675682544708252 seconds for one epoch ---
--- 0.31285810470581055 seconds for one epoch ---
--- 1.3687593936920166 seconds for one epoch ---
--- 0.31832098960876465 seconds for one epoch ---
--- 1.3602862358093262 seconds for one epoch ---
--- 0.31900477409362793 seconds for one epoch ---
--- 1.3522353172302246 seconds for one epoch ---
--- 0.3286714553833008 seconds for one epoch ---
--- 1.3629281520843506 seconds for one epoch ---
--- 0.30318450927734375 seconds for one epoch ---
--- 1.3350024223327637 seconds for one epoch ---
--- 0.32150745391845703 seconds for one epoch ---
--- 1.3399028778076172 seconds for one epoch ---
--- 0.31062889099121094 seconds for one epoch ---
--- 1.3410053253173828 seconds for one epoch ---
--- 0.29983973503112793 seconds for one epoch ---
--- 1.3778142929077148 seconds for one epoch ---
--- 0.31887364387512207 seconds for one epoch ---
--- 1.3863956928253174 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99802613]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.661564]
 [  0.      ]]
--- 0.3016788959503174 seconds for one epoch ---
Epoch 2500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1946.72802734375, (827.14856, 1.7000787, 1117.493, 0.3863008)
   validation loss 883.1255493164062, (621.8988, 0.55619353, 260.28424, 0.3863008)
decoder loss ratio: 24093.439320, decoder SINDy loss  ratio: 0.561860
THRESHOLDING: 1 active coefficients
--- 1.3564677238464355 seconds for one epoch ---
--- 0.3212876319885254 seconds for one epoch ---
--- 1.3471596240997314 seconds for one epoch ---
--- 0.30094480514526367 seconds for one epoch ---
--- 1.3499670028686523 seconds for one epoch ---
--- 0.32135677337646484 seconds for one epoch ---
--- 1.3655805587768555 seconds for one epoch ---
--- 0.30525970458984375 seconds for one epoch ---
--- 1.3774118423461914 seconds for one epoch ---
--- 0.31955623626708984 seconds for one epoch ---
--- 1.3526175022125244 seconds for one epoch ---
--- 0.31299543380737305 seconds for one epoch ---
--- 1.366159439086914 seconds for one epoch ---
--- 0.3057074546813965 seconds for one epoch ---
--- 1.379554271697998 seconds for one epoch ---
--- 0.30937790870666504 seconds for one epoch ---
--- 1.4029033184051514 seconds for one epoch ---
--- 0.30771851539611816 seconds for one epoch ---
--- 1.3485815525054932 seconds for one epoch ---
--- 0.31886863708496094 seconds for one epoch ---
--- 1.3801674842834473 seconds for one epoch ---
--- 0.32288312911987305 seconds for one epoch ---
--- 1.3975625038146973 seconds for one epoch ---
--- 0.32576441764831543 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99807066]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.717747]
 [  0.      ]]
--- 0.25989532470703125 seconds for one epoch ---
Epoch 2525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2015.890869140625, (1246.6218, 5.6685505, 763.213, 0.38747844)
   validation loss 1097.098388671875, (823.50507, 0.57495534, 272.63092, 0.38747844)
decoder loss ratio: 31904.015921, decoder SINDy loss  ratio: 0.588512
--- 0.306227445602417 seconds for one epoch ---
--- 1.355353832244873 seconds for one epoch ---
--- 0.3148674964904785 seconds for one epoch ---
--- 1.37119460105896 seconds for one epoch ---
--- 0.324721097946167 seconds for one epoch ---
--- 1.3764500617980957 seconds for one epoch ---
--- 0.29404282569885254 seconds for one epoch ---
--- 1.3758516311645508 seconds for one epoch ---
--- 0.33702778816223145 seconds for one epoch ---
--- 1.382089376449585 seconds for one epoch ---
--- 0.3141975402832031 seconds for one epoch ---
--- 1.3594081401824951 seconds for one epoch ---
--- 0.3108096122741699 seconds for one epoch ---
--- 1.3969264030456543 seconds for one epoch ---
--- 0.312300443649292 seconds for one epoch ---
--- 1.3533744812011719 seconds for one epoch ---
--- 0.3094511032104492 seconds for one epoch ---
--- 1.3730759620666504 seconds for one epoch ---
--- 0.32176923751831055 seconds for one epoch ---
--- 1.3999903202056885 seconds for one epoch ---
--- 0.32674670219421387 seconds for one epoch ---
--- 1.4006688594818115 seconds for one epoch ---
--- 0.30675721168518066 seconds for one epoch ---
--- 1.378981351852417 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99811953]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.780987]
 [ -0.      ]]
--- 0.29656267166137695 seconds for one epoch ---
Epoch 2550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2744.116455078125, (1707.7861, 0.5445411, 1035.397, 0.38887158)
   validation loss 940.1713256835938, (692.83826, 0.5865792, 246.35764, 0.38887158)
decoder loss ratio: 26841.756890, decoder SINDy loss  ratio: 0.531798
--- 0.261843204498291 seconds for one epoch ---
--- 0.3227846622467041 seconds for one epoch ---
--- 1.3917820453643799 seconds for one epoch ---
--- 0.31659579277038574 seconds for one epoch ---
--- 1.3826143741607666 seconds for one epoch ---
--- 0.3087654113769531 seconds for one epoch ---
--- 1.386437177658081 seconds for one epoch ---
--- 0.3208026885986328 seconds for one epoch ---
--- 1.3561720848083496 seconds for one epoch ---
--- 0.3220484256744385 seconds for one epoch ---
--- 1.409642219543457 seconds for one epoch ---
--- 0.31899213790893555 seconds for one epoch ---
--- 1.3759739398956299 seconds for one epoch ---
--- 0.32230162620544434 seconds for one epoch ---
--- 1.3899457454681396 seconds for one epoch ---
--- 0.3233170509338379 seconds for one epoch ---
--- 1.382826805114746 seconds for one epoch ---
--- 0.3067290782928467 seconds for one epoch ---
--- 1.3777339458465576 seconds for one epoch ---
--- 0.32350873947143555 seconds for one epoch ---
--- 1.39798903465271 seconds for one epoch ---
--- 0.3028905391693115 seconds for one epoch ---
--- 1.3898577690124512 seconds for one epoch ---
--- 0.3242323398590088 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9981625]
 [0.       ]]
[[  0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-14.8376465]
 [  0.       ]]
--- 0.26483988761901855 seconds for one epoch ---
Epoch 2575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6330.22216796875, (1380.5789, 4.273896, 4944.979, 0.39007837)
   validation loss 908.6998901367188, (665.65393, 0.64967024, 242.00624, 0.39007837)
decoder loss ratio: 25788.588900, decoder SINDy loss  ratio: 0.522405
--- 0.31410694122314453 seconds for one epoch ---
--- 1.4294359683990479 seconds for one epoch ---
--- 0.31758880615234375 seconds for one epoch ---
--- 1.389049768447876 seconds for one epoch ---
--- 0.3224351406097412 seconds for one epoch ---
--- 1.39979887008667 seconds for one epoch ---
--- 0.32268691062927246 seconds for one epoch ---
--- 1.4103994369506836 seconds for one epoch ---
--- 0.32502269744873047 seconds for one epoch ---
--- 1.3940656185150146 seconds for one epoch ---
--- 0.3180809020996094 seconds for one epoch ---
--- 1.3966641426086426 seconds for one epoch ---
--- 0.31226587295532227 seconds for one epoch ---
--- 1.40665602684021 seconds for one epoch ---
--- 0.3152604103088379 seconds for one epoch ---
--- 1.389441967010498 seconds for one epoch ---
--- 0.31993770599365234 seconds for one epoch ---
--- 1.423140287399292 seconds for one epoch ---
--- 0.3094296455383301 seconds for one epoch ---
--- 1.4145662784576416 seconds for one epoch ---
--- 0.31430554389953613 seconds for one epoch ---
--- 1.4067070484161377 seconds for one epoch ---
--- 0.3179941177368164 seconds for one epoch ---
--- 1.4177751541137695 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99819547]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-14.88237]
 [ -0.     ]]
--- 0.299027681350708 seconds for one epoch ---
Epoch 2600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2641.25537109375, (1336.6368, 0.8750259, 1303.3525, 0.39106146)
   validation loss 840.1436767578125, (585.8944, 0.6430368, 253.21516, 0.39106146)
decoder loss ratio: 22698.566569, decoder SINDy loss  ratio: 0.546601
--- 0.26134347915649414 seconds for one epoch ---
--- 0.3175368309020996 seconds for one epoch ---
--- 1.4073503017425537 seconds for one epoch ---
--- 0.33379125595092773 seconds for one epoch ---
--- 1.4197044372558594 seconds for one epoch ---
--- 0.31374335289001465 seconds for one epoch ---
--- 1.4229447841644287 seconds for one epoch ---
--- 0.31423473358154297 seconds for one epoch ---
--- 1.4123339653015137 seconds for one epoch ---
--- 0.3094320297241211 seconds for one epoch ---
--- 1.4059476852416992 seconds for one epoch ---
--- 0.3233504295349121 seconds for one epoch ---
--- 1.3925750255584717 seconds for one epoch ---
--- 0.32002830505371094 seconds for one epoch ---
--- 1.4118869304656982 seconds for one epoch ---
--- 0.3197903633117676 seconds for one epoch ---
--- 1.3897926807403564 seconds for one epoch ---
--- 0.32576680183410645 seconds for one epoch ---
--- 1.434079885482788 seconds for one epoch ---
--- 0.32765936851501465 seconds for one epoch ---
--- 1.4262380599975586 seconds for one epoch ---
--- 0.31067872047424316 seconds for one epoch ---
--- 1.4567551612854004 seconds for one epoch ---
--- 0.3233826160430908 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9982386]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.942597]
 [ -0.      ]]
--- 0.2558605670928955 seconds for one epoch ---
Epoch 2625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2156.070556640625, (1093.1537, 1.3378254, 1061.1868, 0.3924175)
   validation loss 1049.4559326171875, (784.30524, 0.6080385, 264.15015, 0.3924175)
decoder loss ratio: 30385.346488, decoder SINDy loss  ratio: 0.570205
--- 0.31775450706481934 seconds for one epoch ---
--- 1.4104251861572266 seconds for one epoch ---
--- 0.3149299621582031 seconds for one epoch ---
--- 1.4102699756622314 seconds for one epoch ---
--- 0.31334376335144043 seconds for one epoch ---
--- 1.411910057067871 seconds for one epoch ---
--- 0.3220808506011963 seconds for one epoch ---
--- 1.4013316631317139 seconds for one epoch ---
--- 0.3221414089202881 seconds for one epoch ---
--- 1.4454619884490967 seconds for one epoch ---
--- 0.3249053955078125 seconds for one epoch ---
--- 1.4390766620635986 seconds for one epoch ---
--- 0.3164653778076172 seconds for one epoch ---
--- 1.4066946506500244 seconds for one epoch ---
--- 0.3210306167602539 seconds for one epoch ---
--- 1.4317786693572998 seconds for one epoch ---
--- 0.3199028968811035 seconds for one epoch ---
--- 1.4438581466674805 seconds for one epoch ---
--- 0.32436418533325195 seconds for one epoch ---
--- 1.4548864364624023 seconds for one epoch ---
--- 0.3146178722381592 seconds for one epoch ---
--- 1.4450938701629639 seconds for one epoch ---
--- 0.326190710067749 seconds for one epoch ---
--- 1.428173303604126 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99827087]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.988132]
 [  0.      ]]
--- 0.2920701503753662 seconds for one epoch ---
Epoch 2650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3255.626220703125, (1323.723, 2.23643, 1929.2736, 0.39337158)
   validation loss 801.2075805664062, (543.893, 0.6993046, 256.22192, 0.39337158)
decoder loss ratio: 21071.359268, decoder SINDy loss  ratio: 0.553091
--- 0.2642223834991455 seconds for one epoch ---
--- 0.32453179359436035 seconds for one epoch ---
--- 1.4230458736419678 seconds for one epoch ---
--- 0.3147468566894531 seconds for one epoch ---
--- 1.4137892723083496 seconds for one epoch ---
--- 0.31345605850219727 seconds for one epoch ---
--- 1.4377317428588867 seconds for one epoch ---
--- 0.3238067626953125 seconds for one epoch ---
--- 1.4230737686157227 seconds for one epoch ---
--- 0.3271818161010742 seconds for one epoch ---
--- 1.4434173107147217 seconds for one epoch ---
--- 0.3143019676208496 seconds for one epoch ---
--- 1.4715368747711182 seconds for one epoch ---
--- 0.32099246978759766 seconds for one epoch ---
--- 1.4572319984436035 seconds for one epoch ---
--- 0.3006863594055176 seconds for one epoch ---
--- 1.4417181015014648 seconds for one epoch ---
--- 0.31704163551330566 seconds for one epoch ---
--- 1.4586081504821777 seconds for one epoch ---
--- 0.3190116882324219 seconds for one epoch ---
--- 1.4465737342834473 seconds for one epoch ---
--- 0.31656646728515625 seconds for one epoch ---
--- 1.4688959121704102 seconds for one epoch ---
--- 0.3113529682159424 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99828434]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.007305]
 [  0.      ]]
--- 0.26638364791870117 seconds for one epoch ---
Epoch 2675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1716.162841796875, (885.94794, 1.6569164, 828.1643, 0.39368278)
   validation loss 1051.0491943359375, (794.93616, 0.65198416, 255.0674, 0.39368278)
decoder loss ratio: 30797.206801, decoder SINDy loss  ratio: 0.550599
--- 0.3074212074279785 seconds for one epoch ---
--- 1.4511549472808838 seconds for one epoch ---
--- 0.3144092559814453 seconds for one epoch ---
--- 1.4627864360809326 seconds for one epoch ---
--- 0.3066418170928955 seconds for one epoch ---
--- 1.4631810188293457 seconds for one epoch ---
--- 0.31458353996276855 seconds for one epoch ---
--- 1.4428353309631348 seconds for one epoch ---
--- 0.30922365188598633 seconds for one epoch ---
--- 1.4341285228729248 seconds for one epoch ---
--- 0.3259758949279785 seconds for one epoch ---
--- 1.4630486965179443 seconds for one epoch ---
--- 0.33704257011413574 seconds for one epoch ---
--- 1.4629707336425781 seconds for one epoch ---
--- 0.30846095085144043 seconds for one epoch ---
--- 1.4590339660644531 seconds for one epoch ---
--- 0.3118436336517334 seconds for one epoch ---
--- 1.4614298343658447 seconds for one epoch ---
--- 0.3216404914855957 seconds for one epoch ---
--- 1.4782638549804688 seconds for one epoch ---
--- 0.32078027725219727 seconds for one epoch ---
--- 1.4783244132995605 seconds for one epoch ---
--- 0.3192296028137207 seconds for one epoch ---
--- 1.4442691802978516 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9983121]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.048674]
 [ -0.      ]]
--- 0.31069445610046387 seconds for one epoch ---
Epoch 2700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2927.578857421875, (884.8319, 2.055431, 2040.2969, 0.39470705)
   validation loss 1124.7662353515625, (841.099, 0.65193707, 282.62073, 0.39470705)
decoder loss ratio: 32585.635434, decoder SINDy loss  ratio: 0.610077
--- 0.2793440818786621 seconds for one epoch ---
--- 0.312394380569458 seconds for one epoch ---
--- 1.4617490768432617 seconds for one epoch ---
--- 0.2977263927459717 seconds for one epoch ---
--- 1.4660465717315674 seconds for one epoch ---
--- 0.31145501136779785 seconds for one epoch ---
--- 1.4681906700134277 seconds for one epoch ---
--- 0.3113718032836914 seconds for one epoch ---
--- 1.4362432956695557 seconds for one epoch ---
--- 0.31360888481140137 seconds for one epoch ---
--- 1.4902825355529785 seconds for one epoch ---
--- 0.321361780166626 seconds for one epoch ---
--- 1.459153652191162 seconds for one epoch ---
--- 0.320955753326416 seconds for one epoch ---
--- 1.44392728805542 seconds for one epoch ---
--- 0.31549835205078125 seconds for one epoch ---
--- 1.4621682167053223 seconds for one epoch ---
--- 0.3175041675567627 seconds for one epoch ---
--- 1.4730603694915771 seconds for one epoch ---
--- 0.32555317878723145 seconds for one epoch ---
--- 1.4587516784667969 seconds for one epoch ---
--- 0.2984127998352051 seconds for one epoch ---
--- 1.4884133338928223 seconds for one epoch ---
--- 0.3032999038696289 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9983399]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.091196]
 [ -0.      ]]
--- 0.2570314407348633 seconds for one epoch ---
Epoch 2725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3085.732421875, (1109.7994, 1.1374065, 1974.4001, 0.39562532)
   validation loss 772.9049072265625, (523.9942, 0.6443514, 247.87076, 0.39562532)
decoder loss ratio: 20300.445066, decoder SINDy loss  ratio: 0.535064
--- 0.3175468444824219 seconds for one epoch ---
--- 1.4904158115386963 seconds for one epoch ---
--- 0.3229391574859619 seconds for one epoch ---
--- 1.4684183597564697 seconds for one epoch ---
--- 0.3250102996826172 seconds for one epoch ---
--- 1.492187738418579 seconds for one epoch ---
--- 0.3250434398651123 seconds for one epoch ---
--- 1.4705486297607422 seconds for one epoch ---
--- 0.31230998039245605 seconds for one epoch ---
--- 1.4686291217803955 seconds for one epoch ---
--- 0.3301882743835449 seconds for one epoch ---
--- 1.4670789241790771 seconds for one epoch ---
--- 0.32938313484191895 seconds for one epoch ---
--- 1.454047441482544 seconds for one epoch ---
--- 0.2922706604003906 seconds for one epoch ---
--- 1.4488887786865234 seconds for one epoch ---
--- 0.3111991882324219 seconds for one epoch ---
--- 1.4769842624664307 seconds for one epoch ---
--- 0.31998658180236816 seconds for one epoch ---
--- 1.4832899570465088 seconds for one epoch ---
--- 0.3264451026916504 seconds for one epoch ---
--- 1.4581129550933838 seconds for one epoch ---
--- 0.3148386478424072 seconds for one epoch ---
--- 1.4794127941131592 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99836373]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.127034]
 [  0.      ]]
--- 0.30809974670410156 seconds for one epoch ---
Epoch 2750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2272.84814453125, (1193.9908, 4.082772, 1074.378, 0.3963829)
   validation loss 749.1914672851562, (512.92334, 0.6300681, 235.2417, 0.3963829)
decoder loss ratio: 19871.540660, decoder SINDy loss  ratio: 0.507802
--- 0.2747330665588379 seconds for one epoch ---
--- 0.2929041385650635 seconds for one epoch ---
--- 1.44935941696167 seconds for one epoch ---
--- 0.32131338119506836 seconds for one epoch ---
--- 1.4628627300262451 seconds for one epoch ---
--- 0.3263726234436035 seconds for one epoch ---
--- 1.4610438346862793 seconds for one epoch ---
--- 0.32854700088500977 seconds for one epoch ---
--- 1.461449384689331 seconds for one epoch ---
--- 0.31328606605529785 seconds for one epoch ---
--- 1.4731431007385254 seconds for one epoch ---
--- 0.3278954029083252 seconds for one epoch ---
--- 1.4716355800628662 seconds for one epoch ---
--- 0.3010425567626953 seconds for one epoch ---
--- 1.4934656620025635 seconds for one epoch ---
--- 0.31567883491516113 seconds for one epoch ---
--- 1.517265796661377 seconds for one epoch ---
--- 0.3281214237213135 seconds for one epoch ---
--- 1.5124456882476807 seconds for one epoch ---
--- 0.31685853004455566 seconds for one epoch ---
--- 1.4856898784637451 seconds for one epoch ---
--- 0.314633846282959 seconds for one epoch ---
--- 1.481949806213379 seconds for one epoch ---
--- 0.32413148880004883 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99838936]
 [0.        ]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [-15.1665125]
 [ -0.       ]]
--- 0.2564547061920166 seconds for one epoch ---
Epoch 2775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1913.1031494140625, (1217.0029, 1.589808, 694.113, 0.39728293)
   validation loss 1182.3343505859375, (879.1605, 0.685507, 302.09106, 0.39728293)
decoder loss ratio: 34060.204930, decoder SINDy loss  ratio: 0.652106
--- 0.3054771423339844 seconds for one epoch ---
--- 1.522470474243164 seconds for one epoch ---
--- 0.3277883529663086 seconds for one epoch ---
--- 1.492288589477539 seconds for one epoch ---
--- 0.31960511207580566 seconds for one epoch ---
--- 1.4615895748138428 seconds for one epoch ---
--- 0.31241488456726074 seconds for one epoch ---
--- 1.5044333934783936 seconds for one epoch ---
--- 0.31811976432800293 seconds for one epoch ---
--- 1.5052201747894287 seconds for one epoch ---
--- 0.32513856887817383 seconds for one epoch ---
--- 1.4812195301055908 seconds for one epoch ---
--- 0.32335972785949707 seconds for one epoch ---
--- 1.496274471282959 seconds for one epoch ---
--- 0.3212289810180664 seconds for one epoch ---
--- 1.5346708297729492 seconds for one epoch ---
--- 0.3247678279876709 seconds for one epoch ---
--- 1.5095419883728027 seconds for one epoch ---
--- 0.32796549797058105 seconds for one epoch ---
--- 1.5253467559814453 seconds for one epoch ---
--- 0.3125143051147461 seconds for one epoch ---
--- 1.499535322189331 seconds for one epoch ---
--- 0.3110649585723877 seconds for one epoch ---
--- 1.484445571899414 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99840724]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.195589]
 [  0.      ]]
--- 0.3076210021972656 seconds for one epoch ---
Epoch 2800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3729.875732421875, (1834.4059, 0.16463365, 1894.9072, 0.3979369)
   validation loss 1021.9827270507812, (745.8668, 0.5598777, 275.15808, 0.3979369)
decoder loss ratio: 28896.175538, decoder SINDy loss  ratio: 0.593967
--- 0.2664148807525635 seconds for one epoch ---
--- 0.3190953731536865 seconds for one epoch ---
--- 1.485154390335083 seconds for one epoch ---
--- 0.31893062591552734 seconds for one epoch ---
--- 1.4827065467834473 seconds for one epoch ---
--- 0.32159996032714844 seconds for one epoch ---
--- 1.4897708892822266 seconds for one epoch ---
--- 0.3251149654388428 seconds for one epoch ---
--- 1.519232988357544 seconds for one epoch ---
--- 0.3062124252319336 seconds for one epoch ---
--- 1.5049986839294434 seconds for one epoch ---
--- 0.31674671173095703 seconds for one epoch ---
--- 1.5209240913391113 seconds for one epoch ---
--- 0.32444334030151367 seconds for one epoch ---
--- 1.489694595336914 seconds for one epoch ---
--- 0.3240540027618408 seconds for one epoch ---
--- 1.4893150329589844 seconds for one epoch ---
--- 0.31093716621398926 seconds for one epoch ---
--- 1.5250029563903809 seconds for one epoch ---
--- 0.3021554946899414 seconds for one epoch ---
--- 1.4893670082092285 seconds for one epoch ---
--- 0.3191535472869873 seconds for one epoch ---
--- 1.5402827262878418 seconds for one epoch ---
--- 0.3184645175933838 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99842894]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.230721]
 [ -0.      ]]
--- 0.25574564933776855 seconds for one epoch ---
Epoch 2825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2364.871337890625, (1089.6173, 0.5059799, 1274.3494, 0.3986213)
   validation loss 1124.79248046875, (875.7872, 0.58170074, 248.02492, 0.3986213)
decoder loss ratio: 33929.515415, decoder SINDy loss  ratio: 0.535397
--- 0.3192596435546875 seconds for one epoch ---
--- 1.5235276222229004 seconds for one epoch ---
--- 0.3101513385772705 seconds for one epoch ---
--- 1.468512773513794 seconds for one epoch ---
--- 0.32233428955078125 seconds for one epoch ---
--- 1.5060269832611084 seconds for one epoch ---
--- 0.3098278045654297 seconds for one epoch ---
--- 1.529649257659912 seconds for one epoch ---
--- 0.3052241802215576 seconds for one epoch ---
--- 1.5139145851135254 seconds for one epoch ---
--- 0.31835198402404785 seconds for one epoch ---
--- 1.521852731704712 seconds for one epoch ---
--- 0.3582792282104492 seconds for one epoch ---
--- 1.5294554233551025 seconds for one epoch ---
--- 0.31037139892578125 seconds for one epoch ---
--- 1.5313122272491455 seconds for one epoch ---
--- 0.3035004138946533 seconds for one epoch ---
--- 1.5357167720794678 seconds for one epoch ---
--- 0.3177835941314697 seconds for one epoch ---
--- 1.531341314315796 seconds for one epoch ---
--- 0.32373046875 seconds for one epoch ---
--- 1.5063152313232422 seconds for one epoch ---
--- 0.3109860420227051 seconds for one epoch ---
--- 1.5504858493804932 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.998448]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.261998]
 [  0.      ]]
--- 0.30388712882995605 seconds for one epoch ---
Epoch 2850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4378.9658203125, (1524.5566, 1.204148, 2852.8057, 0.39936563)
   validation loss 851.9268188476562, (578.75464, 0.54679835, 272.226, 0.39936563)
decoder loss ratio: 22421.959464, decoder SINDy loss  ratio: 0.587638
--- 0.26480841636657715 seconds for one epoch ---
--- 0.3147614002227783 seconds for one epoch ---
--- 1.5310804843902588 seconds for one epoch ---
--- 0.3135337829589844 seconds for one epoch ---
--- 1.5019865036010742 seconds for one epoch ---
--- 0.3333125114440918 seconds for one epoch ---
--- 1.5089590549468994 seconds for one epoch ---
--- 0.3228135108947754 seconds for one epoch ---
--- 1.5294907093048096 seconds for one epoch ---
--- 0.32120227813720703 seconds for one epoch ---
--- 1.5327236652374268 seconds for one epoch ---
--- 0.31891560554504395 seconds for one epoch ---
--- 1.5527279376983643 seconds for one epoch ---
--- 0.3157775402069092 seconds for one epoch ---
--- 1.5507957935333252 seconds for one epoch ---
--- 0.33846020698547363 seconds for one epoch ---
--- 1.516026258468628 seconds for one epoch ---
--- 0.3169398307800293 seconds for one epoch ---
--- 1.5181479454040527 seconds for one epoch ---
--- 0.32809877395629883 seconds for one epoch ---
--- 1.5146691799163818 seconds for one epoch ---
--- 0.3170750141143799 seconds for one epoch ---
--- 1.523287057876587 seconds for one epoch ---
--- 0.31708431243896484 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99847496]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-15.30693]
 [  0.     ]]
--- 0.25425004959106445 seconds for one epoch ---
Epoch 2875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2875.646240234375, (1370.2576, 0.7496449, 1504.2386, 0.400455)
   validation loss 1248.1142578125, (963.553, 0.5916327, 283.56915, 0.400455)
decoder loss ratio: 37329.715189, decoder SINDy loss  ratio: 0.612124
--- 0.30196380615234375 seconds for one epoch ---
--- 1.5220777988433838 seconds for one epoch ---
--- 0.3154737949371338 seconds for one epoch ---
--- 1.5645849704742432 seconds for one epoch ---
--- 0.3043091297149658 seconds for one epoch ---
--- 1.5369279384613037 seconds for one epoch ---
--- 0.3126258850097656 seconds for one epoch ---
--- 1.5379304885864258 seconds for one epoch ---
--- 0.32569456100463867 seconds for one epoch ---
--- 1.5314185619354248 seconds for one epoch ---
--- 0.3069171905517578 seconds for one epoch ---
--- 1.550908088684082 seconds for one epoch ---
--- 0.314868688583374 seconds for one epoch ---
--- 1.5240252017974854 seconds for one epoch ---
--- 0.31624603271484375 seconds for one epoch ---
--- 1.5580708980560303 seconds for one epoch ---
--- 0.30048561096191406 seconds for one epoch ---
--- 1.5515472888946533 seconds for one epoch ---
--- 0.3121044635772705 seconds for one epoch ---
--- 1.5265843868255615 seconds for one epoch ---
--- 0.3186643123626709 seconds for one epoch ---
--- 1.5257940292358398 seconds for one epoch ---
--- 0.31837940216064453 seconds for one epoch ---
--- 1.5739238262176514 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99849117]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.335474]
 [ -0.      ]]
--- 0.29694294929504395 seconds for one epoch ---
Epoch 2900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3669.401123046875, (1232.2378, 1.8159511, 2434.9465, 0.4009597)
   validation loss 823.4053344726562, (582.77325, 0.68713546, 239.54404, 0.4009597)
decoder loss ratio: 22577.647614, decoder SINDy loss  ratio: 0.517089
--- 0.25213170051574707 seconds for one epoch ---
--- 0.30994272232055664 seconds for one epoch ---
--- 1.5611872673034668 seconds for one epoch ---
--- 0.31224775314331055 seconds for one epoch ---
--- 1.5478935241699219 seconds for one epoch ---
--- 0.3210573196411133 seconds for one epoch ---
--- 1.5475852489471436 seconds for one epoch ---
--- 0.2991907596588135 seconds for one epoch ---
--- 1.5592403411865234 seconds for one epoch ---
--- 0.32047247886657715 seconds for one epoch ---
--- 1.5382063388824463 seconds for one epoch ---
--- 0.3103034496307373 seconds for one epoch ---
--- 1.5376460552215576 seconds for one epoch ---
--- 0.3251323699951172 seconds for one epoch ---
--- 1.5545227527618408 seconds for one epoch ---
--- 0.29591870307922363 seconds for one epoch ---
--- 1.5337750911712646 seconds for one epoch ---
--- 0.3052043914794922 seconds for one epoch ---
--- 1.569669485092163 seconds for one epoch ---
--- 0.3244516849517822 seconds for one epoch ---
--- 1.5723621845245361 seconds for one epoch ---
--- 0.32090067863464355 seconds for one epoch ---
--- 1.5852634906768799 seconds for one epoch ---
--- 0.3153116703033447 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9985084]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.364843]
 [  0.      ]]
--- 0.2624945640563965 seconds for one epoch ---
Epoch 2925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3431.020751953125, (1192.3914, 3.5752249, 2234.6526, 0.4016571)
   validation loss 902.2207641601562, (635.00415, 0.6269302, 266.18796, 0.4016571)
decoder loss ratio: 24601.163202, decoder SINDy loss  ratio: 0.574604
--- 0.30074596405029297 seconds for one epoch ---
--- 1.5933785438537598 seconds for one epoch ---
--- 0.3169724941253662 seconds for one epoch ---
--- 1.5711703300476074 seconds for one epoch ---
--- 0.3115530014038086 seconds for one epoch ---
--- 1.5878727436065674 seconds for one epoch ---
--- 0.3137989044189453 seconds for one epoch ---
--- 1.5443265438079834 seconds for one epoch ---
--- 0.31310510635375977 seconds for one epoch ---
--- 1.573756456375122 seconds for one epoch ---
--- 0.31024909019470215 seconds for one epoch ---
--- 1.5920846462249756 seconds for one epoch ---
--- 0.3011934757232666 seconds for one epoch ---
--- 1.5533852577209473 seconds for one epoch ---
--- 0.3219285011291504 seconds for one epoch ---
--- 1.5556495189666748 seconds for one epoch ---
--- 0.2958993911743164 seconds for one epoch ---
--- 1.5720515251159668 seconds for one epoch ---
--- 0.29905152320861816 seconds for one epoch ---
--- 1.5477046966552734 seconds for one epoch ---
--- 0.32027387619018555 seconds for one epoch ---
--- 1.5732004642486572 seconds for one epoch ---
--- 0.30577850341796875 seconds for one epoch ---
--- 1.569206714630127 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9985219]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.387642]
 [ -0.      ]]
--- 0.2961905002593994 seconds for one epoch ---
Epoch 2950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3883.259521484375, (2208.476, 1.0988753, 1673.2823, 0.40217096)
   validation loss 770.5220336914062, (534.05133, 0.64919674, 235.4194, 0.40217096)
decoder loss ratio: 20690.075700, decoder SINDy loss  ratio: 0.508186
--- 0.2600698471069336 seconds for one epoch ---
--- 0.3216440677642822 seconds for one epoch ---
--- 1.5790371894836426 seconds for one epoch ---
--- 0.32219624519348145 seconds for one epoch ---
--- 1.5502605438232422 seconds for one epoch ---
--- 0.33266329765319824 seconds for one epoch ---
--- 1.5612192153930664 seconds for one epoch ---
--- 0.31142687797546387 seconds for one epoch ---
--- 1.5572724342346191 seconds for one epoch ---
--- 0.3047664165496826 seconds for one epoch ---
--- 1.5885183811187744 seconds for one epoch ---
--- 0.3117251396179199 seconds for one epoch ---
--- 1.5568394660949707 seconds for one epoch ---
--- 0.32236671447753906 seconds for one epoch ---
--- 1.5581903457641602 seconds for one epoch ---
--- 0.328934907913208 seconds for one epoch ---
--- 1.5378799438476562 seconds for one epoch ---
--- 0.31759214401245117 seconds for one epoch ---
--- 1.5665044784545898 seconds for one epoch ---
--- 0.30794501304626465 seconds for one epoch ---
--- 1.568800926208496 seconds for one epoch ---
--- 0.3219878673553467 seconds for one epoch ---
--- 1.5693135261535645 seconds for one epoch ---
--- 0.31160902976989746 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9985379]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-15.41722]
 [ -0.     ]]
--- 0.2597677707672119 seconds for one epoch ---
Epoch 2975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2128.26318359375, (1036.1062, 0.46300867, 1091.2913, 0.40287438)
   validation loss 755.1802368164062, (511.0302, 0.7012056, 243.04594, 0.40287438)
decoder loss ratio: 19798.197616, decoder SINDy loss  ratio: 0.524649
--- 0.3242154121398926 seconds for one epoch ---
--- 1.5520846843719482 seconds for one epoch ---
--- 0.3193533420562744 seconds for one epoch ---
--- 1.5748884677886963 seconds for one epoch ---
--- 0.31998562812805176 seconds for one epoch ---
--- 1.5795369148254395 seconds for one epoch ---
--- 0.3173980712890625 seconds for one epoch ---
--- 1.5677361488342285 seconds for one epoch ---
--- 0.3159193992614746 seconds for one epoch ---
--- 1.6110012531280518 seconds for one epoch ---
--- 0.3227527141571045 seconds for one epoch ---
--- 1.5757238864898682 seconds for one epoch ---
--- 0.32294464111328125 seconds for one epoch ---
--- 1.5815393924713135 seconds for one epoch ---
--- 0.3119843006134033 seconds for one epoch ---
--- 1.5640556812286377 seconds for one epoch ---
--- 0.30882930755615234 seconds for one epoch ---
--- 1.6073641777038574 seconds for one epoch ---
--- 0.32881760597229004 seconds for one epoch ---
--- 1.5773820877075195 seconds for one epoch ---
--- 0.3294341564178467 seconds for one epoch ---
--- 1.585047960281372 seconds for one epoch ---
--- 0.3233029842376709 seconds for one epoch ---
--- 1.602874755859375 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9985568]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.451646]
 [  0.      ]]
--- 0.2958354949951172 seconds for one epoch ---
Epoch 3000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2609.771728515625, (1441.2561, 0.33766243, 1167.7743, 0.4036696)
   validation loss 806.1243896484375, (551.0888, 0.71669745, 253.9152, 0.4036696)
decoder loss ratio: 21350.137083, decoder SINDy loss  ratio: 0.548112
THRESHOLDING: 1 active coefficients
--- 0.2582051753997803 seconds for one epoch ---
--- 0.3174123764038086 seconds for one epoch ---
--- 1.5781872272491455 seconds for one epoch ---
--- 0.297382116317749 seconds for one epoch ---
--- 1.6053977012634277 seconds for one epoch ---
--- 0.2702980041503906 seconds for one epoch ---
--- 1.5649926662445068 seconds for one epoch ---
--- 0.31684112548828125 seconds for one epoch ---
--- 1.5820138454437256 seconds for one epoch ---
--- 0.3107733726501465 seconds for one epoch ---
--- 1.606635332107544 seconds for one epoch ---
--- 0.3237147331237793 seconds for one epoch ---
--- 1.5739109516143799 seconds for one epoch ---
--- 0.6176624298095703 seconds for one epoch ---
--- 1.5984840393066406 seconds for one epoch ---
--- 0.33571648597717285 seconds for one epoch ---
--- 1.5856170654296875 seconds for one epoch ---
--- 0.3169257640838623 seconds for one epoch ---
--- 1.6278233528137207 seconds for one epoch ---
--- 0.32341551780700684 seconds for one epoch ---
--- 1.5961675643920898 seconds for one epoch ---
--- 0.326793909072876 seconds for one epoch ---
--- 1.6070778369903564 seconds for one epoch ---
--- 0.3139352798461914 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99857086]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.475206]
 [  0.      ]]
--- 0.26702117919921875 seconds for one epoch ---
Epoch 3025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2662.48388671875, (1332.3832, 1.2176487, 1328.4788, 0.40418682)
   validation loss 1973.5155029296875, (1642.0776, 0.5748155, 330.45886, 0.40418682)
decoder loss ratio: 63616.938419, decoder SINDy loss  ratio: 0.713342
--- 0.30460453033447266 seconds for one epoch ---
--- 1.5588483810424805 seconds for one epoch ---
--- 0.3138129711151123 seconds for one epoch ---
--- 1.6150717735290527 seconds for one epoch ---
--- 0.3079955577850342 seconds for one epoch ---
--- 1.5887398719787598 seconds for one epoch ---
--- 0.31551694869995117 seconds for one epoch ---
--- 1.6177599430084229 seconds for one epoch ---
--- 0.32940244674682617 seconds for one epoch ---
--- 1.6060001850128174 seconds for one epoch ---
--- 0.31377291679382324 seconds for one epoch ---
--- 1.596928596496582 seconds for one epoch ---
--- 0.32911157608032227 seconds for one epoch ---
--- 1.6488149166107178 seconds for one epoch ---
--- 0.31415748596191406 seconds for one epoch ---
--- 1.5971555709838867 seconds for one epoch ---
--- 0.3191206455230713 seconds for one epoch ---
--- 1.5824940204620361 seconds for one epoch ---
--- 0.31983470916748047 seconds for one epoch ---
--- 1.6519875526428223 seconds for one epoch ---
--- 0.32259130477905273 seconds for one epoch ---
--- 1.6178574562072754 seconds for one epoch ---
--- 0.3295454978942871 seconds for one epoch ---
--- 1.6277430057525635 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9985834]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.500766]
 [ -0.      ]]
--- 0.30174899101257324 seconds for one epoch ---
Epoch 3050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2080.62109375, (1094.7811, 0.501486, 984.93365, 0.4048252)
   validation loss 968.0042114257812, (723.99506, 0.6983856, 242.90594, 0.4048252)
decoder loss ratio: 28048.825386, decoder SINDy loss  ratio: 0.524347
--- 0.27615833282470703 seconds for one epoch ---
--- 0.3242805004119873 seconds for one epoch ---
--- 1.599890947341919 seconds for one epoch ---
--- 0.3249673843383789 seconds for one epoch ---
--- 1.6233747005462646 seconds for one epoch ---
--- 0.33263492584228516 seconds for one epoch ---
--- 1.6072399616241455 seconds for one epoch ---
--- 0.3311288356781006 seconds for one epoch ---
--- 1.5959339141845703 seconds for one epoch ---
--- 0.3278954029083252 seconds for one epoch ---
--- 1.6484954357147217 seconds for one epoch ---
--- 0.3119499683380127 seconds for one epoch ---
--- 1.6451876163482666 seconds for one epoch ---
--- 0.3342735767364502 seconds for one epoch ---
--- 1.6219477653503418 seconds for one epoch ---
--- 0.3121950626373291 seconds for one epoch ---
--- 1.6537971496582031 seconds for one epoch ---
--- 0.3408029079437256 seconds for one epoch ---
--- 1.6129863262176514 seconds for one epoch ---
--- 0.31052184104919434 seconds for one epoch ---
--- 1.5985405445098877 seconds for one epoch ---
--- 0.3340613842010498 seconds for one epoch ---
--- 1.6112644672393799 seconds for one epoch ---
--- 0.32924795150756836 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9986013]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.531273]
 [ -0.      ]]
--- 0.26356005668640137 seconds for one epoch ---
Epoch 3075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3533.885986328125, (1981.5898, 2.0277622, 1549.8628, 0.40539846)
   validation loss 1499.3883056640625, (1189.9807, 0.6010038, 308.4012, 0.40539846)
decoder loss ratio: 46101.918715, decoder SINDy loss  ratio: 0.665727
--- 0.3154137134552002 seconds for one epoch ---
--- 1.6494042873382568 seconds for one epoch ---
--- 0.3276231288909912 seconds for one epoch ---
--- 1.6008329391479492 seconds for one epoch ---
--- 0.3198208808898926 seconds for one epoch ---
--- 1.6308982372283936 seconds for one epoch ---
--- 0.31354475021362305 seconds for one epoch ---
--- 1.6219606399536133 seconds for one epoch ---
--- 0.32207155227661133 seconds for one epoch ---
--- 1.6669971942901611 seconds for one epoch ---
--- 0.31250786781311035 seconds for one epoch ---
--- 1.6417875289916992 seconds for one epoch ---
--- 0.31676650047302246 seconds for one epoch ---
--- 1.6581225395202637 seconds for one epoch ---
--- 0.3214752674102783 seconds for one epoch ---
--- 1.6416399478912354 seconds for one epoch ---
--- 0.3296809196472168 seconds for one epoch ---
--- 1.6475751399993896 seconds for one epoch ---
--- 0.3206808567047119 seconds for one epoch ---
--- 1.6556715965270996 seconds for one epoch ---
--- 0.3170154094696045 seconds for one epoch ---
--- 1.6614880561828613 seconds for one epoch ---
--- 0.32539892196655273 seconds for one epoch ---
--- 1.6455028057098389 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9986129]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.556694]
 [  0.      ]]
--- 0.30157923698425293 seconds for one epoch ---
Epoch 3100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2321.87744140625, (1271.3884, 0.47490227, 1049.6082, 0.40607673)
   validation loss 704.3618774414062, (446.5664, 0.7053949, 256.68405, 0.40607673)
decoder loss ratio: 17300.757852, decoder SINDy loss  ratio: 0.554089
--- 0.2589099407196045 seconds for one epoch ---
--- 0.3179285526275635 seconds for one epoch ---
--- 1.602299690246582 seconds for one epoch ---
--- 0.32338404655456543 seconds for one epoch ---
--- 1.633549451828003 seconds for one epoch ---
--- 0.3018052577972412 seconds for one epoch ---
--- 1.6244316101074219 seconds for one epoch ---
--- 0.32148313522338867 seconds for one epoch ---
--- 1.6174490451812744 seconds for one epoch ---
--- 0.3278660774230957 seconds for one epoch ---
--- 1.6710140705108643 seconds for one epoch ---
--- 0.3277416229248047 seconds for one epoch ---
--- 1.619788408279419 seconds for one epoch ---
--- 0.3132145404815674 seconds for one epoch ---
--- 1.6319591999053955 seconds for one epoch ---
--- 0.32157325744628906 seconds for one epoch ---
--- 1.659092664718628 seconds for one epoch ---
--- 0.31979966163635254 seconds for one epoch ---
--- 1.6435167789459229 seconds for one epoch ---
--- 0.3176863193511963 seconds for one epoch ---
--- 1.6676888465881348 seconds for one epoch ---
--- 0.32379579544067383 seconds for one epoch ---
--- 1.6431574821472168 seconds for one epoch ---
--- 0.32082557678222656 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9986341]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.596857]
 [ -0.      ]]
--- 0.26624369621276855 seconds for one epoch ---
Epoch 3125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2951.126708984375, (1236.3401, 0.79163086, 1713.588, 0.40693483)
   validation loss 924.9354248046875, (670.3238, 0.71814644, 253.48657, 0.40693483)
decoder loss ratio: 25969.507416, decoder SINDy loss  ratio: 0.547186
--- 0.2987020015716553 seconds for one epoch ---
--- 1.6515452861785889 seconds for one epoch ---
--- 0.30079150199890137 seconds for one epoch ---
--- 1.6312427520751953 seconds for one epoch ---
--- 0.3278520107269287 seconds for one epoch ---
--- 1.6350786685943604 seconds for one epoch ---
--- 0.32271862030029297 seconds for one epoch ---
--- 1.6557905673980713 seconds for one epoch ---
--- 0.3178985118865967 seconds for one epoch ---
--- 1.633181095123291 seconds for one epoch ---
--- 0.2890439033508301 seconds for one epoch ---
--- 1.6260452270507812 seconds for one epoch ---
--- 0.3273935317993164 seconds for one epoch ---
--- 1.664656162261963 seconds for one epoch ---
--- 0.32114553451538086 seconds for one epoch ---
--- 1.6025633811950684 seconds for one epoch ---
--- 0.3231937885284424 seconds for one epoch ---
--- 1.6295666694641113 seconds for one epoch ---
--- 0.31363582611083984 seconds for one epoch ---
--- 1.6204078197479248 seconds for one epoch ---
--- 0.2994670867919922 seconds for one epoch ---
--- 1.63608980178833 seconds for one epoch ---
--- 0.325608491897583 seconds for one epoch ---
--- 1.6891734600067139 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9986477]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.623124]
 [  0.      ]]
--- 0.30292677879333496 seconds for one epoch ---
Epoch 3150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5916.31103515625, (2228.674, 0.35246605, 3686.8767, 0.40753746)
   validation loss 756.8873901367188, (514.33923, 0.6721132, 241.46852, 0.40753746)
decoder loss ratio: 19926.394834, decoder SINDy loss  ratio: 0.521244
--- 0.2742466926574707 seconds for one epoch ---
--- 0.3271210193634033 seconds for one epoch ---
--- 1.6737401485443115 seconds for one epoch ---
--- 0.31104445457458496 seconds for one epoch ---
--- 1.623248815536499 seconds for one epoch ---
--- 0.30606579780578613 seconds for one epoch ---
--- 1.667771816253662 seconds for one epoch ---
--- 0.33003997802734375 seconds for one epoch ---
--- 1.6835131645202637 seconds for one epoch ---
--- 0.323836088180542 seconds for one epoch ---
--- 1.684661626815796 seconds for one epoch ---
--- 0.3128492832183838 seconds for one epoch ---
--- 1.6582708358764648 seconds for one epoch ---
--- 0.3190774917602539 seconds for one epoch ---
--- 1.6326212882995605 seconds for one epoch ---
--- 0.3406374454498291 seconds for one epoch ---
--- 1.6881647109985352 seconds for one epoch ---
--- 0.3167088031768799 seconds for one epoch ---
--- 1.6893105506896973 seconds for one epoch ---
--- 0.3138275146484375 seconds for one epoch ---
--- 1.6863837242126465 seconds for one epoch ---
--- 0.3147246837615967 seconds for one epoch ---
--- 1.7119882106781006 seconds for one epoch ---
--- 0.31272172927856445 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99865973]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.646661]
 [ -0.      ]]
--- 0.26500558853149414 seconds for one epoch ---
Epoch 3175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3325.061767578125, (1071.636, 4.476201, 2248.5415, 0.40801406)
   validation loss 975.4408569335938, (701.4131, 0.660371, 272.95932, 0.40801406)
decoder loss ratio: 27173.960656, decoder SINDy loss  ratio: 0.589221
--- 0.3092620372772217 seconds for one epoch ---
--- 1.6933376789093018 seconds for one epoch ---
--- 0.323697566986084 seconds for one epoch ---
--- 1.676440954208374 seconds for one epoch ---
--- 0.3147754669189453 seconds for one epoch ---
--- 1.679558277130127 seconds for one epoch ---
--- 0.3220186233520508 seconds for one epoch ---
--- 1.6724853515625 seconds for one epoch ---
--- 0.32277560234069824 seconds for one epoch ---
--- 1.6928253173828125 seconds for one epoch ---
--- 0.3286247253417969 seconds for one epoch ---
--- 1.632072925567627 seconds for one epoch ---
--- 0.3219122886657715 seconds for one epoch ---
--- 1.6808762550354004 seconds for one epoch ---
--- 0.31913137435913086 seconds for one epoch ---
--- 1.6566851139068604 seconds for one epoch ---
--- 0.32363295555114746 seconds for one epoch ---
--- 1.71099853515625 seconds for one epoch ---
--- 0.30899858474731445 seconds for one epoch ---
--- 1.6607027053833008 seconds for one epoch ---
--- 0.3194735050201416 seconds for one epoch ---
--- 1.6698575019836426 seconds for one epoch ---
--- 0.31071901321411133 seconds for one epoch ---
--- 1.7089462280273438 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9986689]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.666052]
 [  0.      ]]
--- 0.30452895164489746 seconds for one epoch ---
Epoch 3200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5130.38037109375, (1411.647, 7.977336, 3710.3472, 0.4084776)
   validation loss 752.7478637695312, (506.79004, 0.7896625, 244.75969, 0.4084776)
decoder loss ratio: 19633.925939, decoder SINDy loss  ratio: 0.528348
--- 0.2670624256134033 seconds for one epoch ---
--- 0.30714941024780273 seconds for one epoch ---
--- 1.6574132442474365 seconds for one epoch ---
--- 0.323408842086792 seconds for one epoch ---
--- 1.6818413734436035 seconds for one epoch ---
--- 0.3166358470916748 seconds for one epoch ---
--- 1.6529643535614014 seconds for one epoch ---
--- 0.3236958980560303 seconds for one epoch ---
--- 1.6708388328552246 seconds for one epoch ---
--- 0.32139110565185547 seconds for one epoch ---
--- 1.6989545822143555 seconds for one epoch ---
--- 0.31409454345703125 seconds for one epoch ---
--- 1.7124965190887451 seconds for one epoch ---
--- 0.31995534896850586 seconds for one epoch ---
--- 1.6658966541290283 seconds for one epoch ---
--- 0.3205854892730713 seconds for one epoch ---
--- 1.6639831066131592 seconds for one epoch ---
--- 0.3139777183532715 seconds for one epoch ---
--- 1.7169396877288818 seconds for one epoch ---
--- 0.3169703483581543 seconds for one epoch ---
--- 1.7028028964996338 seconds for one epoch ---
--- 0.32417821884155273 seconds for one epoch ---
--- 1.704798698425293 seconds for one epoch ---
--- 0.325650691986084 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9986813]
 [0.       ]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [  0.       ]
 [-15.6914215]
 [  0.       ]]
--- 0.2701730728149414 seconds for one epoch ---
Epoch 3225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2809.07861328125, (1545.1753, 0.3273728, 1263.1666, 0.40905762)
   validation loss 989.0951538085938, (725.38605, 0.6905891, 262.60944, 0.40905762)
decoder loss ratio: 28102.714800, decoder SINDy loss  ratio: 0.566879
--- 0.305034875869751 seconds for one epoch ---
--- 1.7085397243499756 seconds for one epoch ---
--- 0.3216414451599121 seconds for one epoch ---
--- 1.6644625663757324 seconds for one epoch ---
--- 0.3336598873138428 seconds for one epoch ---
--- 1.695293664932251 seconds for one epoch ---
--- 0.3242378234863281 seconds for one epoch ---
--- 1.6758983135223389 seconds for one epoch ---
--- 0.3202064037322998 seconds for one epoch ---
--- 1.6613972187042236 seconds for one epoch ---
--- 0.3231217861175537 seconds for one epoch ---
--- 1.6859686374664307 seconds for one epoch ---
--- 0.3347287178039551 seconds for one epoch ---
--- 1.6729326248168945 seconds for one epoch ---
--- 0.31108903884887695 seconds for one epoch ---
--- 1.6883583068847656 seconds for one epoch ---
--- 0.3135833740234375 seconds for one epoch ---
--- 1.717299222946167 seconds for one epoch ---
--- 0.3174912929534912 seconds for one epoch ---
--- 1.6842329502105713 seconds for one epoch ---
--- 0.3263833522796631 seconds for one epoch ---
--- 1.6849794387817383 seconds for one epoch ---
--- 0.3190641403198242 seconds for one epoch ---
--- 1.726179838180542 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99869204]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.713381]
 [ -0.      ]]
--- 0.2722761631011963 seconds for one epoch ---
Epoch 3250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 7997.52978515625, (1532.672, 5.3968754, 6459.0513, 0.4095467)
   validation loss 811.6129150390625, (552.38196, 0.62179834, 258.1996, 0.4095467)
decoder loss ratio: 21400.236030, decoder SINDy loss  ratio: 0.557360
--- 0.2681901454925537 seconds for one epoch ---
--- 0.3269810676574707 seconds for one epoch ---
--- 1.6955289840698242 seconds for one epoch ---
--- 0.3271210193634033 seconds for one epoch ---
--- 1.6748261451721191 seconds for one epoch ---
--- 0.3286099433898926 seconds for one epoch ---
--- 1.718578815460205 seconds for one epoch ---
--- 0.32498812675476074 seconds for one epoch ---
--- 1.6619138717651367 seconds for one epoch ---
--- 0.30889058113098145 seconds for one epoch ---
--- 1.6957919597625732 seconds for one epoch ---
--- 0.30741310119628906 seconds for one epoch ---
--- 1.710453987121582 seconds for one epoch ---
--- 0.3217592239379883 seconds for one epoch ---
--- 1.741337537765503 seconds for one epoch ---
--- 0.33430004119873047 seconds for one epoch ---
--- 1.6787476539611816 seconds for one epoch ---
--- 0.3259141445159912 seconds for one epoch ---
--- 1.7207210063934326 seconds for one epoch ---
--- 0.322101354598999 seconds for one epoch ---
--- 1.705415964126587 seconds for one epoch ---
--- 0.317685604095459 seconds for one epoch ---
--- 1.7148213386535645 seconds for one epoch ---
--- 0.32389211654663086 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987092]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.749277]
 [  0.      ]]
--- 0.27330994606018066 seconds for one epoch ---
Epoch 3275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2798.72412109375, (1285.1257, 1.3303698, 1511.8577, 0.4103752)
   validation loss 744.9083862304688, (494.3511, 0.6969443, 249.44995, 0.4103752)
decoder loss ratio: 19152.020029, decoder SINDy loss  ratio: 0.538473
--- 0.3205099105834961 seconds for one epoch ---
--- 1.6930651664733887 seconds for one epoch ---
--- 0.3234140872955322 seconds for one epoch ---
--- 1.6947283744812012 seconds for one epoch ---
--- 0.3287177085876465 seconds for one epoch ---
--- 1.7048118114471436 seconds for one epoch ---
--- 0.3043985366821289 seconds for one epoch ---
--- 1.6916439533233643 seconds for one epoch ---
--- 0.3193187713623047 seconds for one epoch ---
--- 1.7207133769989014 seconds for one epoch ---
--- 0.32138562202453613 seconds for one epoch ---
--- 1.7189290523529053 seconds for one epoch ---
--- 0.32793140411376953 seconds for one epoch ---
--- 1.6979751586914062 seconds for one epoch ---
--- 0.3174114227294922 seconds for one epoch ---
--- 1.7437036037445068 seconds for one epoch ---
--- 0.31884241104125977 seconds for one epoch ---
--- 1.7392261028289795 seconds for one epoch ---
--- 0.3083178997039795 seconds for one epoch ---
--- 1.7547492980957031 seconds for one epoch ---
--- 0.3194761276245117 seconds for one epoch ---
--- 1.6996240615844727 seconds for one epoch ---
--- 0.31998562812805176 seconds for one epoch ---
--- 1.708745002746582 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987238]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.779298]
 [ -0.      ]]
--- 0.29624366760253906 seconds for one epoch ---
Epoch 3300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3928.29443359375, (2008.5914, 1.0349047, 1918.2571, 0.41111776)
   validation loss 956.0242919921875, (688.4573, 0.70773864, 266.44812, 0.41111776)
decoder loss ratio: 26672.030063, decoder SINDy loss  ratio: 0.575166
--- 0.25420594215393066 seconds for one epoch ---
--- 0.32085680961608887 seconds for one epoch ---
--- 1.715991497039795 seconds for one epoch ---
--- 0.3128855228424072 seconds for one epoch ---
--- 1.7097346782684326 seconds for one epoch ---
--- 0.32128024101257324 seconds for one epoch ---
--- 1.7287659645080566 seconds for one epoch ---
--- 0.3383331298828125 seconds for one epoch ---
--- 1.711824893951416 seconds for one epoch ---
--- 0.3196864128112793 seconds for one epoch ---
--- 1.7413487434387207 seconds for one epoch ---
--- 0.322066068649292 seconds for one epoch ---
--- 1.7567410469055176 seconds for one epoch ---
--- 0.33623766899108887 seconds for one epoch ---
--- 1.7219667434692383 seconds for one epoch ---
--- 0.3310105800628662 seconds for one epoch ---
--- 1.7241549491882324 seconds for one epoch ---
--- 0.31792116165161133 seconds for one epoch ---
--- 1.785179853439331 seconds for one epoch ---
--- 0.327193021774292 seconds for one epoch ---
--- 1.7624766826629639 seconds for one epoch ---
--- 0.3214418888092041 seconds for one epoch ---
--- 1.7605693340301514 seconds for one epoch ---
--- 0.33891963958740234 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99873215]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-15.797493]
 [ -0.      ]]
--- 0.26481080055236816 seconds for one epoch ---
Epoch 3325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4468.57861328125, (1637.8706, 4.032219, 2826.264, 0.4115347)
   validation loss 762.5883178710938, (502.70532, 0.693002, 258.7784, 0.4115347)
decoder loss ratio: 19475.676919, decoder SINDy loss  ratio: 0.558610
--- 0.3033561706542969 seconds for one epoch ---
--- 1.754518747329712 seconds for one epoch ---
--- 0.3310813903808594 seconds for one epoch ---
--- 1.685868263244629 seconds for one epoch ---
--- 0.323291540145874 seconds for one epoch ---
--- 1.728689432144165 seconds for one epoch ---
--- 0.3129911422729492 seconds for one epoch ---
--- 1.7211639881134033 seconds for one epoch ---
--- 0.32831549644470215 seconds for one epoch ---
--- 1.7155120372772217 seconds for one epoch ---
--- 0.33002185821533203 seconds for one epoch ---
--- 1.7506256103515625 seconds for one epoch ---
--- 0.32567811012268066 seconds for one epoch ---
--- 1.7746548652648926 seconds for one epoch ---
--- 0.3296489715576172 seconds for one epoch ---
--- 1.7312157154083252 seconds for one epoch ---
--- 0.3196525573730469 seconds for one epoch ---
--- 1.7467398643493652 seconds for one epoch ---
--- 0.32034873962402344 seconds for one epoch ---
--- 1.75508713722229 seconds for one epoch ---
--- 0.32286787033081055 seconds for one epoch ---
--- 1.7531287670135498 seconds for one epoch ---
--- 0.32279348373413086 seconds for one epoch ---
--- 1.7514348030090332 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987421]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.817877]
 [  0.      ]]
--- 0.30869626998901367 seconds for one epoch ---
Epoch 3350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2398.315673828125, (953.9261, 1.4834551, 1442.4943, 0.41195154)
   validation loss 786.3018188476562, (540.07275, 0.76572937, 245.05139, 0.41195154)
decoder loss ratio: 20923.356094, decoder SINDy loss  ratio: 0.528978
--- 0.2639310359954834 seconds for one epoch ---
--- 0.3229508399963379 seconds for one epoch ---
--- 1.7349750995635986 seconds for one epoch ---
--- 0.3108189105987549 seconds for one epoch ---
--- 1.7574231624603271 seconds for one epoch ---
--- 0.30940890312194824 seconds for one epoch ---
--- 1.7688069343566895 seconds for one epoch ---
--- 0.33134913444519043 seconds for one epoch ---
--- 1.7785162925720215 seconds for one epoch ---
--- 0.328702449798584 seconds for one epoch ---
--- 1.764552354812622 seconds for one epoch ---
--- 0.32702064514160156 seconds for one epoch ---
--- 1.7230355739593506 seconds for one epoch ---
--- 0.31938815116882324 seconds for one epoch ---
--- 1.7314035892486572 seconds for one epoch ---
--- 0.30324459075927734 seconds for one epoch ---
--- 1.7176172733306885 seconds for one epoch ---
--- 0.3072526454925537 seconds for one epoch ---
--- 1.7609679698944092 seconds for one epoch ---
--- 0.31280088424682617 seconds for one epoch ---
--- 1.7178492546081543 seconds for one epoch ---
--- 0.31485700607299805 seconds for one epoch ---
--- 1.776695728302002 seconds for one epoch ---
--- 0.31381821632385254 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987488]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.833396]
 [  0.      ]]
--- 0.26326966285705566 seconds for one epoch ---
Epoch 3375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3096.509521484375, (2350.2146, 1.4006915, 744.48206, 0.41233635)
   validation loss 811.910400390625, (572.4505, 0.8073293, 238.24025, 0.41233635)
decoder loss ratio: 22177.726207, decoder SINDy loss  ratio: 0.514275
--- 0.299283504486084 seconds for one epoch ---
--- 1.7286570072174072 seconds for one epoch ---
--- 0.3036613464355469 seconds for one epoch ---
--- 1.7261219024658203 seconds for one epoch ---
--- 0.3197019100189209 seconds for one epoch ---
--- 1.7686059474945068 seconds for one epoch ---
--- 0.31806182861328125 seconds for one epoch ---
--- 1.7679352760314941 seconds for one epoch ---
--- 0.3233506679534912 seconds for one epoch ---
--- 1.751723289489746 seconds for one epoch ---
--- 0.3218264579772949 seconds for one epoch ---
--- 1.7714896202087402 seconds for one epoch ---
--- 0.32880711555480957 seconds for one epoch ---
--- 1.7487351894378662 seconds for one epoch ---
--- 0.3156440258026123 seconds for one epoch ---
--- 1.7591931819915771 seconds for one epoch ---
--- 0.3327763080596924 seconds for one epoch ---
--- 1.737137794494629 seconds for one epoch ---
--- 0.3260006904602051 seconds for one epoch ---
--- 1.736598014831543 seconds for one epoch ---
--- 0.3300471305847168 seconds for one epoch ---
--- 1.7446184158325195 seconds for one epoch ---
--- 0.3200712203979492 seconds for one epoch ---
--- 1.7691984176635742 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99876153]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.862301]
 [ -0.      ]]
--- 0.3050112724304199 seconds for one epoch ---
Epoch 3400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3065.56298828125, (1099.6119, 1.2124751, 1964.3256, 0.412981)
   validation loss 1569.5196533203125, (1259.1143, 0.74291193, 309.2495, 0.412981)
decoder loss ratio: 48780.272266, decoder SINDy loss  ratio: 0.667559
--- 0.26483654975891113 seconds for one epoch ---
--- 0.3303217887878418 seconds for one epoch ---
--- 1.7721655368804932 seconds for one epoch ---
--- 0.3191490173339844 seconds for one epoch ---
--- 1.7877321243286133 seconds for one epoch ---
--- 0.31455159187316895 seconds for one epoch ---
--- 1.7835509777069092 seconds for one epoch ---
--- 0.32160329818725586 seconds for one epoch ---
--- 1.7942748069763184 seconds for one epoch ---
--- 0.32187843322753906 seconds for one epoch ---
--- 1.7632184028625488 seconds for one epoch ---
--- 0.31342315673828125 seconds for one epoch ---
--- 1.7660326957702637 seconds for one epoch ---
--- 0.3064093589782715 seconds for one epoch ---
--- 1.7545812129974365 seconds for one epoch ---
--- 0.3202478885650635 seconds for one epoch ---
--- 1.7748603820800781 seconds for one epoch ---
--- 0.3150179386138916 seconds for one epoch ---
--- 1.8149018287658691 seconds for one epoch ---
--- 0.324601411819458 seconds for one epoch ---
--- 1.7756834030151367 seconds for one epoch ---
--- 0.3185696601867676 seconds for one epoch ---
--- 1.7566425800323486 seconds for one epoch ---
--- 0.3258826732635498 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987711]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.881648]
 [ -0.      ]]
--- 0.2545483112335205 seconds for one epoch ---
Epoch 3425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2366.693115234375, (1267.898, 0.7764388, 1097.6053, 0.41340333)
   validation loss 738.4839477539062, (501.9089, 0.8595984, 235.30205, 0.41340333)
decoder loss ratio: 19444.822333, decoder SINDy loss  ratio: 0.507933
--- 0.3215596675872803 seconds for one epoch ---
--- 1.7793617248535156 seconds for one epoch ---
--- 0.3236720561981201 seconds for one epoch ---
--- 1.7531828880310059 seconds for one epoch ---
--- 0.32245373725891113 seconds for one epoch ---
--- 1.7726004123687744 seconds for one epoch ---
--- 0.3211789131164551 seconds for one epoch ---
--- 1.7566032409667969 seconds for one epoch ---
--- 0.31636500358581543 seconds for one epoch ---
--- 1.7566401958465576 seconds for one epoch ---
--- 0.3184196949005127 seconds for one epoch ---
--- 1.7783288955688477 seconds for one epoch ---
--- 0.32009196281433105 seconds for one epoch ---
--- 1.7780406475067139 seconds for one epoch ---
--- 0.3032655715942383 seconds for one epoch ---
--- 1.7924811840057373 seconds for one epoch ---
--- 0.3212857246398926 seconds for one epoch ---
--- 1.8114235401153564 seconds for one epoch ---
--- 0.3187863826751709 seconds for one epoch ---
--- 1.7662482261657715 seconds for one epoch ---
--- 0.3300905227661133 seconds for one epoch ---
--- 1.7711679935455322 seconds for one epoch ---
--- 0.31554603576660156 seconds for one epoch ---
--- 1.8264126777648926 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99877644]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.895127]
 [  0.      ]]
--- 0.3071465492248535 seconds for one epoch ---
Epoch 3450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3201.783935546875, (1568.8461, 3.2960477, 1629.228, 0.41373706)
   validation loss 711.4879760742188, (470.71463, 0.89409536, 239.46545, 0.41373706)
decoder loss ratio: 18236.301968, decoder SINDy loss  ratio: 0.516920
--- 0.25652623176574707 seconds for one epoch ---
--- 0.3202540874481201 seconds for one epoch ---
--- 1.760066270828247 seconds for one epoch ---
--- 0.32526445388793945 seconds for one epoch ---
--- 1.7671070098876953 seconds for one epoch ---
--- 0.33684396743774414 seconds for one epoch ---
--- 1.8214044570922852 seconds for one epoch ---
--- 0.3298654556274414 seconds for one epoch ---
--- 1.8071107864379883 seconds for one epoch ---
--- 0.3275938034057617 seconds for one epoch ---
--- 1.8002662658691406 seconds for one epoch ---
--- 0.3158903121948242 seconds for one epoch ---
--- 1.7985320091247559 seconds for one epoch ---
--- 0.3178067207336426 seconds for one epoch ---
--- 1.7793738842010498 seconds for one epoch ---
--- 0.32317233085632324 seconds for one epoch ---
--- 1.8173069953918457 seconds for one epoch ---
--- 0.31746768951416016 seconds for one epoch ---
--- 1.7696032524108887 seconds for one epoch ---
--- 0.32212018966674805 seconds for one epoch ---
--- 1.8308618068695068 seconds for one epoch ---
--- 0.3220033645629883 seconds for one epoch ---
--- 1.8195323944091797 seconds for one epoch ---
--- 0.331301212310791 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987869]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.916793]
 [ -0.      ]]
--- 0.262742280960083 seconds for one epoch ---
Epoch 3475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1641.3857421875, (732.05493, 0.3122567, 908.6043, 0.4142622)
   validation loss 786.6119995117188, (533.40717, 0.8131211, 251.97745, 0.4142622)
decoder loss ratio: 20665.119628, decoder SINDy loss  ratio: 0.543929
--- 0.30599308013916016 seconds for one epoch ---
--- 1.8171329498291016 seconds for one epoch ---
--- 0.31679296493530273 seconds for one epoch ---
--- 1.8273346424102783 seconds for one epoch ---
--- 0.3189578056335449 seconds for one epoch ---
--- 1.7816567420959473 seconds for one epoch ---
--- 0.32700109481811523 seconds for one epoch ---
--- 1.7684531211853027 seconds for one epoch ---
--- 0.336580753326416 seconds for one epoch ---
--- 1.8109679222106934 seconds for one epoch ---
--- 0.33548927307128906 seconds for one epoch ---
--- 1.8210573196411133 seconds for one epoch ---
--- 0.3247387409210205 seconds for one epoch ---
--- 1.828732967376709 seconds for one epoch ---
--- 0.32760167121887207 seconds for one epoch ---
--- 1.807924747467041 seconds for one epoch ---
--- 0.32501983642578125 seconds for one epoch ---
--- 1.7894737720489502 seconds for one epoch ---
--- 0.31805419921875 seconds for one epoch ---
--- 1.8163599967956543 seconds for one epoch ---
--- 0.3168332576751709 seconds for one epoch ---
--- 1.8362531661987305 seconds for one epoch ---
--- 0.3198280334472656 seconds for one epoch ---
--- 1.8353359699249268 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987964]
 [0.       ]]
[[ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [  0.       ]
 [ -0.       ]
 [-15.9402075]
 [  0.       ]]
--- 0.30431580543518066 seconds for one epoch ---
Epoch 3500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1983.7235107421875, (663.0839, 1.5005627, 1318.7242, 0.4148507)
   validation loss 903.7036743164062, (632.758, 0.7422746, 269.78857, 0.4148507)
decoder loss ratio: 24514.143266, decoder SINDy loss  ratio: 0.582377
THRESHOLDING: 1 active coefficients
--- 1.7803466320037842 seconds for one epoch ---
--- 0.3154618740081787 seconds for one epoch ---
--- 1.831411361694336 seconds for one epoch ---
--- 0.32605981826782227 seconds for one epoch ---
--- 1.800736427307129 seconds for one epoch ---
--- 0.3159933090209961 seconds for one epoch ---
--- 1.8152451515197754 seconds for one epoch ---
--- 0.32216477394104004 seconds for one epoch ---
--- 1.8197402954101562 seconds for one epoch ---
--- 0.32259416580200195 seconds for one epoch ---
--- 1.8367934226989746 seconds for one epoch ---
--- 0.31574296951293945 seconds for one epoch ---
--- 1.8424408435821533 seconds for one epoch ---
--- 0.31703948974609375 seconds for one epoch ---
--- 1.8188285827636719 seconds for one epoch ---
--- 0.3190488815307617 seconds for one epoch ---
--- 1.841374158859253 seconds for one epoch ---
--- 0.3097348213195801 seconds for one epoch ---
--- 1.818204641342163 seconds for one epoch ---
--- 0.32259082794189453 seconds for one epoch ---
--- 1.825817346572876 seconds for one epoch ---
--- 0.3282158374786377 seconds for one epoch ---
--- 1.8610143661499023 seconds for one epoch ---
--- 0.32190585136413574 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988077]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.967053]
 [ -0.      ]]
--- 0.25352001190185547 seconds for one epoch ---
Epoch 3525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1926.9459228515625, (863.92487, 1.2479851, 1061.3577, 0.415428)
   validation loss 756.9625244140625, (511.51752, 0.77674365, 244.25285, 0.415428)
decoder loss ratio: 19817.076646, decoder SINDy loss  ratio: 0.527254
--- 0.30941319465637207 seconds for one epoch ---
--- 1.8421690464019775 seconds for one epoch ---
--- 0.3142540454864502 seconds for one epoch ---
--- 1.84617018699646 seconds for one epoch ---
--- 0.3040964603424072 seconds for one epoch ---
--- 1.8214378356933594 seconds for one epoch ---
--- 0.32915496826171875 seconds for one epoch ---
--- 1.8348419666290283 seconds for one epoch ---
--- 0.317366361618042 seconds for one epoch ---
--- 1.8332362174987793 seconds for one epoch ---
--- 0.3207871913909912 seconds for one epoch ---
--- 1.825305461883545 seconds for one epoch ---
--- 0.3218536376953125 seconds for one epoch ---
--- 1.8785364627838135 seconds for one epoch ---
--- 0.32163095474243164 seconds for one epoch ---
--- 1.849931240081787 seconds for one epoch ---
--- 0.31867098808288574 seconds for one epoch ---
--- 1.8694374561309814 seconds for one epoch ---
--- 0.3204503059387207 seconds for one epoch ---
--- 1.8792505264282227 seconds for one epoch ---
--- 0.32320117950439453 seconds for one epoch ---
--- 1.8434624671936035 seconds for one epoch ---
--- 0.316664457321167 seconds for one epoch ---
--- 1.8370633125305176 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988184]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.991288]
 [  0.      ]]
--- 0.29712414741516113 seconds for one epoch ---
Epoch 3550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1271.6722412109375, (696.4105, 0.88653135, 573.95917, 0.41597232)
   validation loss 1003.8186645507812, (737.50476, 0.8947239, 265.0032, 0.41597232)
decoder loss ratio: 28572.214796, decoder SINDy loss  ratio: 0.572047
--- 0.2737581729888916 seconds for one epoch ---
--- 0.3293633460998535 seconds for one epoch ---
--- 1.8709361553192139 seconds for one epoch ---
--- 0.3182549476623535 seconds for one epoch ---
--- 1.8679158687591553 seconds for one epoch ---
--- 0.3254077434539795 seconds for one epoch ---
--- 1.8955857753753662 seconds for one epoch ---
--- 0.3070831298828125 seconds for one epoch ---
--- 1.8988037109375 seconds for one epoch ---
--- 0.32808876037597656 seconds for one epoch ---
--- 1.8792743682861328 seconds for one epoch ---
--- 0.3244936466217041 seconds for one epoch ---
--- 1.8446192741394043 seconds for one epoch ---
--- 0.3248789310455322 seconds for one epoch ---
--- 1.8864471912384033 seconds for one epoch ---
--- 0.33283090591430664 seconds for one epoch ---
--- 1.8789739608764648 seconds for one epoch ---
--- 0.3243093490600586 seconds for one epoch ---
--- 1.8909296989440918 seconds for one epoch ---
--- 0.3143656253814697 seconds for one epoch ---
--- 1.8999748229980469 seconds for one epoch ---
--- 0.3247404098510742 seconds for one epoch ---
--- 1.9108431339263916 seconds for one epoch ---
--- 0.32485127449035645 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99882674]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.011414]
 [  0.      ]]
--- 0.2633180618286133 seconds for one epoch ---
Epoch 3575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2986.57763671875, (1009.73346, 0.9618701, 1975.4658, 0.41643056)
   validation loss 970.8182983398438, (688.1915, 0.72830206, 281.48196, 0.41643056)
decoder loss ratio: 26661.734560, decoder SINDy loss  ratio: 0.607618
--- 0.3000063896179199 seconds for one epoch ---
--- 1.8461878299713135 seconds for one epoch ---
--- 0.32576513290405273 seconds for one epoch ---
--- 1.8818268775939941 seconds for one epoch ---
--- 0.3278381824493408 seconds for one epoch ---
--- 1.883063554763794 seconds for one epoch ---
--- 0.3206939697265625 seconds for one epoch ---
--- 1.8686556816101074 seconds for one epoch ---
--- 0.31470584869384766 seconds for one epoch ---
--- 1.836244821548462 seconds for one epoch ---
--- 0.32335543632507324 seconds for one epoch ---
--- 1.880180835723877 seconds for one epoch ---
--- 0.31926584243774414 seconds for one epoch ---
--- 1.9089226722717285 seconds for one epoch ---
--- 0.31501150131225586 seconds for one epoch ---
--- 1.881047248840332 seconds for one epoch ---
--- 0.3236217498779297 seconds for one epoch ---
--- 1.8969473838806152 seconds for one epoch ---
--- 0.3208303451538086 seconds for one epoch ---
--- 1.8717873096466064 seconds for one epoch ---
--- 0.31743955612182617 seconds for one epoch ---
--- 1.908369541168213 seconds for one epoch ---
--- 0.3268148899078369 seconds for one epoch ---
--- 1.879422664642334 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988348]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.027477]
 [ -0.      ]]
--- 0.2969949245452881 seconds for one epoch ---
Epoch 3600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3014.030517578125, (1291.9268, 0.6038867, 1721.0831, 0.4168148)
   validation loss 803.8645629882812, (553.051, 0.79643756, 249.60031, 0.4168148)
decoder loss ratio: 21426.156862, decoder SINDy loss  ratio: 0.538797
--- 0.27613401412963867 seconds for one epoch ---
--- 0.3166203498840332 seconds for one epoch ---
--- 1.8653295040130615 seconds for one epoch ---
--- 0.3343634605407715 seconds for one epoch ---
--- 1.8605601787567139 seconds for one epoch ---
--- 0.3192124366760254 seconds for one epoch ---
--- 1.855618953704834 seconds for one epoch ---
--- 0.32259511947631836 seconds for one epoch ---
--- 1.9171581268310547 seconds for one epoch ---
--- 0.3222320079803467 seconds for one epoch ---
--- 1.9141325950622559 seconds for one epoch ---
--- 0.32387590408325195 seconds for one epoch ---
--- 1.9157724380493164 seconds for one epoch ---
--- 0.3103981018066406 seconds for one epoch ---
--- 1.8723986148834229 seconds for one epoch ---
--- 0.31243205070495605 seconds for one epoch ---
--- 1.8619441986083984 seconds for one epoch ---
--- 0.3273048400878906 seconds for one epoch ---
--- 1.8610119819641113 seconds for one epoch ---
--- 0.3257436752319336 seconds for one epoch ---
--- 1.860079050064087 seconds for one epoch ---
--- 0.3197152614593506 seconds for one epoch ---
--- 1.931091070175171 seconds for one epoch ---
--- 0.31977343559265137 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99884117]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.045435]
 [  0.      ]]
--- 0.2575340270996094 seconds for one epoch ---
Epoch 3625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3387.39697265625, (1493.7134, 1.0822928, 1892.1841, 0.4172937)
   validation loss 791.5753784179688, (525.73267, 0.8310362, 264.5944, 0.4172937)
decoder loss ratio: 20367.796193, decoder SINDy loss  ratio: 0.571164
--- 0.30690550804138184 seconds for one epoch ---
--- 1.8742876052856445 seconds for one epoch ---
--- 0.3272426128387451 seconds for one epoch ---
--- 1.908668041229248 seconds for one epoch ---
--- 0.3181772232055664 seconds for one epoch ---
--- 1.8664350509643555 seconds for one epoch ---
--- 0.32627224922180176 seconds for one epoch ---
--- 1.8619489669799805 seconds for one epoch ---
--- 0.323528528213501 seconds for one epoch ---
--- 1.885007381439209 seconds for one epoch ---
--- 0.32071423530578613 seconds for one epoch ---
--- 1.9140193462371826 seconds for one epoch ---
--- 0.3299107551574707 seconds for one epoch ---
--- 1.925328254699707 seconds for one epoch ---
--- 0.31363916397094727 seconds for one epoch ---
--- 1.882685661315918 seconds for one epoch ---
--- 0.3182213306427002 seconds for one epoch ---
--- 1.9271175861358643 seconds for one epoch ---
--- 0.3269331455230713 seconds for one epoch ---
--- 1.9075934886932373 seconds for one epoch ---
--- 0.325911283493042 seconds for one epoch ---
--- 1.9314992427825928 seconds for one epoch ---
--- 0.31583166122436523 seconds for one epoch ---
--- 1.8866708278656006 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988512]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.070173]
 [ -0.      ]]
--- 0.3089606761932373 seconds for one epoch ---
Epoch 3650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1075.2027587890625, (577.3678, 0.32892245, 497.08813, 0.41780052)
   validation loss 772.0250244140625, (516.3389, 0.8277086, 254.44061, 0.41780052)
decoder loss ratio: 20003.866483, decoder SINDy loss  ratio: 0.549246
--- 0.2731931209564209 seconds for one epoch ---
--- 0.33792662620544434 seconds for one epoch ---
--- 1.9245657920837402 seconds for one epoch ---
--- 0.33679819107055664 seconds for one epoch ---
--- 1.8797979354858398 seconds for one epoch ---
--- 0.30994510650634766 seconds for one epoch ---
--- 1.8771731853485107 seconds for one epoch ---
--- 0.32299232482910156 seconds for one epoch ---
--- 1.8706891536712646 seconds for one epoch ---
--- 0.3223097324371338 seconds for one epoch ---
--- 1.9249253273010254 seconds for one epoch ---
--- 0.32492828369140625 seconds for one epoch ---
--- 1.9072356224060059 seconds for one epoch ---
--- 0.3310821056365967 seconds for one epoch ---
--- 1.9179811477661133 seconds for one epoch ---
--- 0.32370996475219727 seconds for one epoch ---
--- 1.8878297805786133 seconds for one epoch ---
--- 0.3192329406738281 seconds for one epoch ---
--- 1.9144399166107178 seconds for one epoch ---
--- 0.31880831718444824 seconds for one epoch ---
--- 1.901256799697876 seconds for one epoch ---
--- 0.31521105766296387 seconds for one epoch ---
--- 1.8863210678100586 seconds for one epoch ---
--- 0.32582759857177734 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99885976]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.088104]
 [ -0.      ]]
--- 0.2713894844055176 seconds for one epoch ---
Epoch 3675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2540.3076171875, (1402.9889, 0.4716456, 1136.4288, 0.41825405)
   validation loss 1094.573486328125, (829.0183, 0.8096334, 264.32727, 0.41825405)
decoder loss ratio: 32117.608590, decoder SINDy loss  ratio: 0.570588
--- 0.2996177673339844 seconds for one epoch ---
--- 1.8877184391021729 seconds for one epoch ---
--- 0.3231518268585205 seconds for one epoch ---
--- 1.8969576358795166 seconds for one epoch ---
--- 0.32631349563598633 seconds for one epoch ---
--- 1.9435842037200928 seconds for one epoch ---
--- 0.3231053352355957 seconds for one epoch ---
--- 1.9232501983642578 seconds for one epoch ---
--- 0.3209538459777832 seconds for one epoch ---
--- 1.9278502464294434 seconds for one epoch ---
--- 0.3113374710083008 seconds for one epoch ---
--- 1.909759521484375 seconds for one epoch ---
--- 0.32209062576293945 seconds for one epoch ---
--- 1.914360761642456 seconds for one epoch ---
--- 0.3252871036529541 seconds for one epoch ---
--- 1.9236080646514893 seconds for one epoch ---
--- 0.31285572052001953 seconds for one epoch ---
--- 1.8939158916473389 seconds for one epoch ---
--- 0.30659914016723633 seconds for one epoch ---
--- 1.905989646911621 seconds for one epoch ---
--- 0.32123637199401855 seconds for one epoch ---
--- 1.9492771625518799 seconds for one epoch ---
--- 0.3270118236541748 seconds for one epoch ---
--- 1.941795825958252 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99886596]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.105986]
 [  0.      ]]
--- 0.2952444553375244 seconds for one epoch ---
Epoch 3700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3015.0517578125, (1556.1873, 1.2182813, 1457.2275, 0.41869813)
   validation loss 878.4150390625, (640.3597, 0.8899726, 236.74669, 0.41869813)
decoder loss ratio: 24808.645723, decoder SINDy loss  ratio: 0.511051
--- 0.2644338607788086 seconds for one epoch ---
--- 0.3267691135406494 seconds for one epoch ---
--- 1.9282894134521484 seconds for one epoch ---
--- 0.3197286128997803 seconds for one epoch ---
--- 1.904494285583496 seconds for one epoch ---
--- 0.31548261642456055 seconds for one epoch ---
--- 1.903738260269165 seconds for one epoch ---
--- 0.31873369216918945 seconds for one epoch ---
--- 1.9320409297943115 seconds for one epoch ---
--- 0.311753511428833 seconds for one epoch ---
--- 1.9030396938323975 seconds for one epoch ---
--- 0.321580171585083 seconds for one epoch ---
--- 1.9393255710601807 seconds for one epoch ---
--- 0.3154306411743164 seconds for one epoch ---
--- 1.9213199615478516 seconds for one epoch ---
--- 0.32073378562927246 seconds for one epoch ---
--- 1.9340872764587402 seconds for one epoch ---
--- 0.31404614448547363 seconds for one epoch ---
--- 1.9292924404144287 seconds for one epoch ---
--- 0.3337428569793701 seconds for one epoch ---
--- 1.9322764873504639 seconds for one epoch ---
--- 0.31964683532714844 seconds for one epoch ---
--- 1.9617321491241455 seconds for one epoch ---
--- 0.31658220291137695 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988736]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.126484]
 [  0.      ]]
--- 0.2675797939300537 seconds for one epoch ---
Epoch 3725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2288.564208984375, (1192.1257, 0.67660016, 1095.3427, 0.41920194)
   validation loss 888.94482421875, (647.4838, 0.9099414, 240.13187, 0.41920194)
decoder loss ratio: 25084.647488, decoder SINDy loss  ratio: 0.518358
--- 0.30300378799438477 seconds for one epoch ---
--- 1.9141883850097656 seconds for one epoch ---
--- 0.31725311279296875 seconds for one epoch ---
--- 1.9620048999786377 seconds for one epoch ---
--- 0.32333850860595703 seconds for one epoch ---
--- 1.8969528675079346 seconds for one epoch ---
--- 0.30955958366394043 seconds for one epoch ---
--- 1.9211945533752441 seconds for one epoch ---
--- 0.30632805824279785 seconds for one epoch ---
--- 1.9764435291290283 seconds for one epoch ---
--- 0.3325667381286621 seconds for one epoch ---
--- 1.9610280990600586 seconds for one epoch ---
--- 0.32035160064697266 seconds for one epoch ---
--- 1.9184293746948242 seconds for one epoch ---
--- 0.31860804557800293 seconds for one epoch ---
--- 1.9345791339874268 seconds for one epoch ---
--- 0.31423330307006836 seconds for one epoch ---
--- 1.973724603652954 seconds for one epoch ---
--- 0.32013678550720215 seconds for one epoch ---
--- 1.9872815608978271 seconds for one epoch ---
--- 0.3214695453643799 seconds for one epoch ---
--- 1.9361581802368164 seconds for one epoch ---
--- 0.31931304931640625 seconds for one epoch ---
--- 1.922175645828247 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99887955]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.140179]
 [ -0.      ]]
--- 0.29149317741394043 seconds for one epoch ---
Epoch 3750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3334.859375, (1311.8442, 0.21850404, 2022.3771, 0.41947618)
   validation loss 916.9141845703125, (656.15515, 0.8091935, 259.53033, 0.41947618)
decoder loss ratio: 25420.589699, decoder SINDy loss  ratio: 0.560233
--- 0.26768994331359863 seconds for one epoch ---
--- 0.3104221820831299 seconds for one epoch ---
--- 1.9638786315917969 seconds for one epoch ---
--- 0.3226020336151123 seconds for one epoch ---
--- 1.9551904201507568 seconds for one epoch ---
--- 0.3124725818634033 seconds for one epoch ---
--- 1.9249939918518066 seconds for one epoch ---
--- 0.32564473152160645 seconds for one epoch ---
--- 1.9397554397583008 seconds for one epoch ---
--- 0.31792640686035156 seconds for one epoch ---
--- 1.9885449409484863 seconds for one epoch ---
--- 0.32843780517578125 seconds for one epoch ---
--- 1.92948579788208 seconds for one epoch ---
--- 0.32254743576049805 seconds for one epoch ---
--- 1.9946582317352295 seconds for one epoch ---
--- 0.3098902702331543 seconds for one epoch ---
--- 1.922642707824707 seconds for one epoch ---
--- 0.321185827255249 seconds for one epoch ---
--- 1.9334783554077148 seconds for one epoch ---
--- 0.3223876953125 seconds for one epoch ---
--- 1.9692528247833252 seconds for one epoch ---
--- 0.3174095153808594 seconds for one epoch ---
--- 1.9743499755859375 seconds for one epoch ---
--- 0.32601237297058105 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988826]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.146801]
 [ -0.      ]]
--- 0.26309871673583984 seconds for one epoch ---
Epoch 3775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2544.38818359375, (1195.5087, 1.5418929, 1346.918, 0.41960278)
   validation loss 1327.5015869140625, (1067.265, 0.787888, 259.02914, 0.41960278)
decoder loss ratio: 41347.699521, decoder SINDy loss  ratio: 0.559151
--- 0.30847620964050293 seconds for one epoch ---
--- 1.9928770065307617 seconds for one epoch ---
--- 0.31648850440979004 seconds for one epoch ---
--- 1.9243676662445068 seconds for one epoch ---
--- 0.3235788345336914 seconds for one epoch ---
--- 1.991914987564087 seconds for one epoch ---
--- 0.3213205337524414 seconds for one epoch ---
--- 1.9456684589385986 seconds for one epoch ---
--- 0.3236362934112549 seconds for one epoch ---
--- 1.9865076541900635 seconds for one epoch ---
--- 0.2995178699493408 seconds for one epoch ---
--- 2.0059351921081543 seconds for one epoch ---
--- 0.3131725788116455 seconds for one epoch ---
--- 1.9384665489196777 seconds for one epoch ---
--- 0.3139457702636719 seconds for one epoch ---
--- 1.9792003631591797 seconds for one epoch ---
--- 0.30122876167297363 seconds for one epoch ---
--- 1.997572422027588 seconds for one epoch ---
--- 0.32374072074890137 seconds for one epoch ---
--- 1.9652085304260254 seconds for one epoch ---
--- 0.3196229934692383 seconds for one epoch ---
--- 1.9900038242340088 seconds for one epoch ---
--- 0.3286702632904053 seconds for one epoch ---
--- 2.002779960632324 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.998888]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.162785]
 [  0.      ]]
--- 0.317718505859375 seconds for one epoch ---
Epoch 3800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1408.3524169921875, (670.7292, 0.82883143, 736.3744, 0.42001376)
   validation loss 956.52001953125, (669.85345, 0.7156778, 285.53082, 0.42001376)
decoder loss ratio: 25951.285748, decoder SINDy loss  ratio: 0.616358
--- 0.27170491218566895 seconds for one epoch ---
--- 0.3306007385253906 seconds for one epoch ---
--- 1.9837963581085205 seconds for one epoch ---
--- 0.31134843826293945 seconds for one epoch ---
--- 2.0008699893951416 seconds for one epoch ---
--- 0.32225823402404785 seconds for one epoch ---
--- 1.9452998638153076 seconds for one epoch ---
--- 0.3004484176635742 seconds for one epoch ---
--- 2.003511428833008 seconds for one epoch ---
--- 0.3337428569793701 seconds for one epoch ---
--- 1.9682273864746094 seconds for one epoch ---
--- 0.3076953887939453 seconds for one epoch ---
--- 1.979642391204834 seconds for one epoch ---
--- 0.3062450885772705 seconds for one epoch ---
--- 1.9866359233856201 seconds for one epoch ---
--- 0.3234989643096924 seconds for one epoch ---
--- 1.9593160152435303 seconds for one epoch ---
--- 0.3101379871368408 seconds for one epoch ---
--- 2.002903699874878 seconds for one epoch ---
--- 0.30875563621520996 seconds for one epoch ---
--- 1.953934669494629 seconds for one epoch ---
--- 0.31133151054382324 seconds for one epoch ---
--- 1.9747824668884277 seconds for one epoch ---
--- 0.32840418815612793 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988955]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.17959]
 [ -0.     ]]
--- 0.2689821720123291 seconds for one epoch ---
Epoch 3825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2124.016357421875, (1264.9772, 1.2089947, 857.4098, 0.42044243)
   validation loss 893.8860473632812, (638.2181, 0.7801696, 254.46738, 0.42044243)
decoder loss ratio: 24725.676361, decoder SINDy loss  ratio: 0.549304
--- 0.31024861335754395 seconds for one epoch ---
--- 2.0175769329071045 seconds for one epoch ---
--- 0.3295412063598633 seconds for one epoch ---
--- 1.9692082405090332 seconds for one epoch ---
--- 0.3244342803955078 seconds for one epoch ---
--- 2.0243897438049316 seconds for one epoch ---
--- 0.3322122097015381 seconds for one epoch ---
--- 2.0136067867279053 seconds for one epoch ---
--- 0.31336402893066406 seconds for one epoch ---
--- 1.9863755702972412 seconds for one epoch ---
--- 0.29834675788879395 seconds for one epoch ---
--- 2.0005970001220703 seconds for one epoch ---
--- 0.32480335235595703 seconds for one epoch ---
--- 2.0048184394836426 seconds for one epoch ---
--- 0.3308830261230469 seconds for one epoch ---
--- 1.9889636039733887 seconds for one epoch ---
--- 0.31844329833984375 seconds for one epoch ---
--- 1.991018295288086 seconds for one epoch ---
--- 0.31058573722839355 seconds for one epoch ---
--- 2.022718906402588 seconds for one epoch ---
--- 0.3220200538635254 seconds for one epoch ---
--- 2.0063724517822266 seconds for one epoch ---
--- 0.32705092430114746 seconds for one epoch ---
--- 1.967726469039917 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99890286]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.19918]
 [  0.     ]]
--- 0.30860304832458496 seconds for one epoch ---
Epoch 3850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3017.1337890625, (1090.4348, 2.497549, 1923.7806, 0.4208674)
   validation loss 757.1546020507812, (507.70737, 0.77186626, 248.25449, 0.4208674)
decoder loss ratio: 19669.464814, decoder SINDy loss  ratio: 0.535892
--- 0.2694664001464844 seconds for one epoch ---
--- 0.31982421875 seconds for one epoch ---
--- 2.0029702186584473 seconds for one epoch ---
--- 0.3183472156524658 seconds for one epoch ---
--- 2.0139143466949463 seconds for one epoch ---
--- 0.3066718578338623 seconds for one epoch ---
--- 1.9718258380889893 seconds for one epoch ---
--- 0.3249084949493408 seconds for one epoch ---
--- 1.9825615882873535 seconds for one epoch ---
--- 0.32031965255737305 seconds for one epoch ---
--- 2.004399061203003 seconds for one epoch ---
--- 0.32885313034057617 seconds for one epoch ---
--- 2.0111799240112305 seconds for one epoch ---
--- 0.316148042678833 seconds for one epoch ---
--- 2.007669687271118 seconds for one epoch ---
--- 0.3280456066131592 seconds for one epoch ---
--- 2.0072078704833984 seconds for one epoch ---
--- 0.32709455490112305 seconds for one epoch ---
--- 2.0285465717315674 seconds for one epoch ---
--- 0.32642436027526855 seconds for one epoch ---
--- 2.0234177112579346 seconds for one epoch ---
--- 0.31133484840393066 seconds for one epoch ---
--- 2.0130248069763184 seconds for one epoch ---
--- 0.3070523738861084 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99890804]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.211668]
 [ -0.      ]]
--- 0.25435853004455566 seconds for one epoch ---
Epoch 3875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2577.280517578125, (1455.1211, 0.16172148, 1121.5765, 0.42117944)
   validation loss 1196.628173828125, (918.4179, 0.78070015, 277.00842, 0.42117944)
decoder loss ratio: 35581.104188, decoder SINDy loss  ratio: 0.597962
--- 0.2844724655151367 seconds for one epoch ---
--- 1.9883933067321777 seconds for one epoch ---
--- 0.30762314796447754 seconds for one epoch ---
--- 2.037353754043579 seconds for one epoch ---
--- 0.3082575798034668 seconds for one epoch ---
--- 1.975569248199463 seconds for one epoch ---
--- 0.6889915466308594 seconds for one epoch ---
--- 2.0088231563568115 seconds for one epoch ---
--- 0.3190476894378662 seconds for one epoch ---
--- 2.021357536315918 seconds for one epoch ---
--- 0.3272571563720703 seconds for one epoch ---
--- 2.0093095302581787 seconds for one epoch ---
--- 0.3099477291107178 seconds for one epoch ---
--- 1.999737024307251 seconds for one epoch ---
--- 0.3193366527557373 seconds for one epoch ---
--- 2.0409321784973145 seconds for one epoch ---
--- 0.31246376037597656 seconds for one epoch ---
--- 2.0081238746643066 seconds for one epoch ---
--- 0.3067631721496582 seconds for one epoch ---
--- 1.9887604713439941 seconds for one epoch ---
--- 0.31978845596313477 seconds for one epoch ---
--- 2.020310401916504 seconds for one epoch ---
--- 0.31853771209716797 seconds for one epoch ---
--- 1.9915390014648438 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99891376]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.228685]
 [  0.      ]]
--- 0.2999234199523926 seconds for one epoch ---
Epoch 3900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3400.869384765625, (1236.127, 1.1388179, 2163.1821, 0.4215431)
   validation loss 827.6643676757812, (574.6002, 0.8215822, 251.82095, 0.4215431)
decoder loss ratio: 22261.010062, decoder SINDy loss  ratio: 0.543591
--- 0.2757706642150879 seconds for one epoch ---
--- 0.32965803146362305 seconds for one epoch ---
--- 2.023667097091675 seconds for one epoch ---
--- 0.3343849182128906 seconds for one epoch ---
--- 2.0026049613952637 seconds for one epoch ---
--- 0.3175356388092041 seconds for one epoch ---
--- 2.0353267192840576 seconds for one epoch ---
--- 0.31442975997924805 seconds for one epoch ---
--- 1.995535135269165 seconds for one epoch ---
--- 0.31638455390930176 seconds for one epoch ---
--- 2.051138162612915 seconds for one epoch ---
--- 0.3209397792816162 seconds for one epoch ---
--- 2.0084266662597656 seconds for one epoch ---
--- 0.2990396022796631 seconds for one epoch ---
--- 2.0089917182922363 seconds for one epoch ---
--- 0.3191542625427246 seconds for one epoch ---
--- 1.9944863319396973 seconds for one epoch ---
--- 0.3105587959289551 seconds for one epoch ---
--- 2.06225323677063 seconds for one epoch ---
--- 0.3143892288208008 seconds for one epoch ---
--- 2.0114829540252686 seconds for one epoch ---
--- 0.3292500972747803 seconds for one epoch ---
--- 2.0100483894348145 seconds for one epoch ---
--- 0.3196732997894287 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99891686]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.235401]
 [  0.      ]]
--- 0.26424217224121094 seconds for one epoch ---
Epoch 3925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2858.839599609375, (1479.7344, 5.594062, 1373.0894, 0.42174602)
   validation loss 781.4551391601562, (541.7044, 0.9148771, 238.41414, 0.42174602)
decoder loss ratio: 20986.569157, decoder SINDy loss  ratio: 0.514650
--- 0.30223655700683594 seconds for one epoch ---
--- 2.0166983604431152 seconds for one epoch ---
--- 0.3287394046783447 seconds for one epoch ---
--- 2.0049562454223633 seconds for one epoch ---
--- 0.3208191394805908 seconds for one epoch ---
--- 2.054368495941162 seconds for one epoch ---
--- 0.3218200206756592 seconds for one epoch ---
--- 2.0798380374908447 seconds for one epoch ---
--- 0.31420397758483887 seconds for one epoch ---
--- 2.0124220848083496 seconds for one epoch ---
--- 0.328094482421875 seconds for one epoch ---
--- 2.0406696796417236 seconds for one epoch ---
--- 0.3299901485443115 seconds for one epoch ---
--- 2.030338764190674 seconds for one epoch ---
--- 0.31703734397888184 seconds for one epoch ---
--- 2.045823335647583 seconds for one epoch ---
--- 0.31173229217529297 seconds for one epoch ---
--- 2.0757241249084473 seconds for one epoch ---
--- 0.3247227668762207 seconds for one epoch ---
--- 2.042598247528076 seconds for one epoch ---
--- 0.3124563694000244 seconds for one epoch ---
--- 2.029421806335449 seconds for one epoch ---
--- 0.31511664390563965 seconds for one epoch ---
--- 2.0391721725463867 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.998925]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.258276]
 [ -0.      ]]
--- 0.3002135753631592 seconds for one epoch ---
Epoch 3950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2087.16259765625, (929.45135, 0.555248, 1156.7338, 0.42228562)
   validation loss 784.1815795898438, (536.01904, 0.8536076, 246.88661, 0.42228562)
decoder loss ratio: 20766.308295, decoder SINDy loss  ratio: 0.532939
--- 0.2746009826660156 seconds for one epoch ---
--- 0.3249201774597168 seconds for one epoch ---
--- 2.0573174953460693 seconds for one epoch ---
--- 0.3109762668609619 seconds for one epoch ---
--- 2.0682373046875 seconds for one epoch ---
--- 0.3200716972351074 seconds for one epoch ---
--- 2.039170026779175 seconds for one epoch ---
--- 0.31982851028442383 seconds for one epoch ---
--- 2.027249336242676 seconds for one epoch ---
--- 0.32318711280822754 seconds for one epoch ---
--- 2.067265272140503 seconds for one epoch ---
--- 0.30099058151245117 seconds for one epoch ---
--- 2.0628480911254883 seconds for one epoch ---
--- 0.3223862648010254 seconds for one epoch ---
--- 2.0445001125335693 seconds for one epoch ---
--- 0.3103611469268799 seconds for one epoch ---
--- 2.0626304149627686 seconds for one epoch ---
--- 0.3244812488555908 seconds for one epoch ---
--- 2.019495725631714 seconds for one epoch ---
--- 0.31551671028137207 seconds for one epoch ---
--- 2.0360777378082275 seconds for one epoch ---
--- 0.31205177307128906 seconds for one epoch ---
--- 2.0278432369232178 seconds for one epoch ---
--- 0.3189046382904053 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989326]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.278543]
 [  0.      ]]
--- 0.2734518051147461 seconds for one epoch ---
Epoch 3975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2228.143310546875, (892.7385, 1.1253886, 1333.8566, 0.42274094)
   validation loss 842.5517578125, (605.8309, 0.8804481, 235.41772, 0.42274094)
decoder loss ratio: 23470.939734, decoder SINDy loss  ratio: 0.508182
--- 0.31084609031677246 seconds for one epoch ---
--- 2.060616970062256 seconds for one epoch ---
--- 0.3178126811981201 seconds for one epoch ---
--- 2.0242106914520264 seconds for one epoch ---
--- 0.3168299198150635 seconds for one epoch ---
--- 2.0370113849639893 seconds for one epoch ---
--- 0.3153998851776123 seconds for one epoch ---
--- 2.0840084552764893 seconds for one epoch ---
--- 0.32256388664245605 seconds for one epoch ---
--- 2.040571451187134 seconds for one epoch ---
--- 0.3157181739807129 seconds for one epoch ---
--- 2.074187755584717 seconds for one epoch ---
--- 0.30858826637268066 seconds for one epoch ---
--- 2.0351943969726562 seconds for one epoch ---
--- 0.31667423248291016 seconds for one epoch ---
--- 2.0627758502960205 seconds for one epoch ---
--- 0.31748414039611816 seconds for one epoch ---
--- 2.04768705368042 seconds for one epoch ---
--- 0.32524824142456055 seconds for one epoch ---
--- 2.0625431537628174 seconds for one epoch ---
--- 0.3050405979156494 seconds for one epoch ---
--- 2.033825397491455 seconds for one epoch ---
--- 0.31323671340942383 seconds for one epoch ---
--- 2.111621856689453 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989377]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.292988]
 [ -0.      ]]
--- 0.297074556350708 seconds for one epoch ---
Epoch 4000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3976.53564453125, (2253.1333, 1.6682763, 1721.311, 0.42308703)
   validation loss 902.2554321289062, (654.6044, 0.8713907, 246.35657, 0.42308703)
decoder loss ratio: 25360.509742, decoder SINDy loss  ratio: 0.531795
THRESHOLDING: 1 active coefficients
--- 2.0334811210632324 seconds for one epoch ---
--- 0.32775259017944336 seconds for one epoch ---
--- 2.0474660396575928 seconds for one epoch ---
--- 0.310380220413208 seconds for one epoch ---
--- 2.043025493621826 seconds for one epoch ---
--- 0.3179476261138916 seconds for one epoch ---
--- 2.099609613418579 seconds for one epoch ---
--- 0.3226203918457031 seconds for one epoch ---
--- 2.052063465118408 seconds for one epoch ---
--- 0.3316917419433594 seconds for one epoch ---
--- 2.0415728092193604 seconds for one epoch ---
--- 0.32764124870300293 seconds for one epoch ---
--- 2.0755741596221924 seconds for one epoch ---
--- 0.32120299339294434 seconds for one epoch ---
--- 2.072620153427124 seconds for one epoch ---
--- 0.32425951957702637 seconds for one epoch ---
--- 2.0680575370788574 seconds for one epoch ---
--- 0.32510948181152344 seconds for one epoch ---
--- 2.0754778385162354 seconds for one epoch ---
--- 0.3309183120727539 seconds for one epoch ---
--- 2.0574727058410645 seconds for one epoch ---
--- 0.2962985038757324 seconds for one epoch ---
--- 2.0868566036224365 seconds for one epoch ---
--- 0.3025391101837158 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99894214]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.304474]
 [ -0.      ]]
--- 0.26568150520324707 seconds for one epoch ---
Epoch 4025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3801.93994140625, (1451.7137, 0.6834721, 2349.1194, 0.42337433)
   validation loss 834.236328125, (585.3354, 0.8747726, 247.60277, 0.42337433)
decoder loss ratio: 22676.909125, decoder SINDy loss  ratio: 0.534485
--- 0.2975494861602783 seconds for one epoch ---
--- 2.0560965538024902 seconds for one epoch ---
--- 0.31774449348449707 seconds for one epoch ---
--- 2.047419309616089 seconds for one epoch ---
--- 0.33146119117736816 seconds for one epoch ---
--- 2.0826809406280518 seconds for one epoch ---
--- 0.31716227531433105 seconds for one epoch ---
--- 2.0793373584747314 seconds for one epoch ---
--- 0.32622241973876953 seconds for one epoch ---
--- 2.089625358581543 seconds for one epoch ---
--- 0.3233048915863037 seconds for one epoch ---
--- 2.066056966781616 seconds for one epoch ---
--- 0.3156256675720215 seconds for one epoch ---
--- 2.063843011856079 seconds for one epoch ---
--- 0.3218116760253906 seconds for one epoch ---
--- 2.064361572265625 seconds for one epoch ---
--- 0.31612515449523926 seconds for one epoch ---
--- 2.0686707496643066 seconds for one epoch ---
--- 0.3280370235443115 seconds for one epoch ---
--- 2.096625328063965 seconds for one epoch ---
--- 0.3305199146270752 seconds for one epoch ---
--- 2.079760789871216 seconds for one epoch ---
--- 0.3325204849243164 seconds for one epoch ---
--- 2.107862710952759 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99894434]
 [0.        ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.30993]
 [  0.     ]]
--- 0.2970924377441406 seconds for one epoch ---
Epoch 4050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1964.7200927734375, (933.03613, 2.6559582, 1028.6045, 0.42346817)
   validation loss 863.7553100585938, (614.263, 0.83080155, 248.23804, 0.42346817)
decoder loss ratio: 23797.615046, decoder SINDy loss  ratio: 0.535857
--- 0.2705953121185303 seconds for one epoch ---
--- 0.32877111434936523 seconds for one epoch ---
--- 2.077562093734741 seconds for one epoch ---
--- 0.3180093765258789 seconds for one epoch ---
--- 2.0467545986175537 seconds for one epoch ---
--- 0.31889915466308594 seconds for one epoch ---
--- 2.1213109493255615 seconds for one epoch ---
--- 0.314727783203125 seconds for one epoch ---
--- 2.0948681831359863 seconds for one epoch ---
--- 0.3159482479095459 seconds for one epoch ---
--- 2.1240744590759277 seconds for one epoch ---
--- 0.31393909454345703 seconds for one epoch ---
--- 2.094371795654297 seconds for one epoch ---
--- 0.32236242294311523 seconds for one epoch ---
--- 2.1314916610717773 seconds for one epoch ---
--- 0.3223719596862793 seconds for one epoch ---
--- 2.1029014587402344 seconds for one epoch ---
--- 0.33255481719970703 seconds for one epoch ---
--- 2.0943615436553955 seconds for one epoch ---
--- 0.32381463050842285 seconds for one epoch ---
--- 2.0957655906677246 seconds for one epoch ---
--- 0.32933950424194336 seconds for one epoch ---
--- 2.137218475341797 seconds for one epoch ---
--- 0.32120251655578613 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989464]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.316053]
 [  0.      ]]
--- 0.2644495964050293 seconds for one epoch ---
Epoch 4075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3975.273681640625, (1334.549, 1.0591214, 2639.2422, 0.42362508)
   validation loss 791.3234252929688, (540.28, 0.8167159, 249.80307, 0.42362508)
decoder loss ratio: 20931.386302, decoder SINDy loss  ratio: 0.539235
--- 0.31374073028564453 seconds for one epoch ---
--- 2.0760343074798584 seconds for one epoch ---
--- 0.324005126953125 seconds for one epoch ---
--- 2.098243236541748 seconds for one epoch ---
--- 0.33407139778137207 seconds for one epoch ---
--- 2.092451333999634 seconds for one epoch ---
--- 0.3242189884185791 seconds for one epoch ---
--- 2.056657075881958 seconds for one epoch ---
--- 0.3198816776275635 seconds for one epoch ---
--- 2.140395164489746 seconds for one epoch ---
--- 0.3227806091308594 seconds for one epoch ---
--- 2.123176336288452 seconds for one epoch ---
--- 0.313370943069458 seconds for one epoch ---
--- 2.1395668983459473 seconds for one epoch ---
--- 0.33649444580078125 seconds for one epoch ---
--- 2.07863712310791 seconds for one epoch ---
--- 0.3188669681549072 seconds for one epoch ---
--- 2.0976829528808594 seconds for one epoch ---
--- 0.3205235004425049 seconds for one epoch ---
--- 2.1285550594329834 seconds for one epoch ---
--- 0.3215928077697754 seconds for one epoch ---
--- 2.09500789642334 seconds for one epoch ---
--- 0.3195760250091553 seconds for one epoch ---
--- 2.1168010234832764 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99895024]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.327215]
 [ -0.      ]]
--- 0.2964913845062256 seconds for one epoch ---
Epoch 4100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1781.9500732421875, (854.8595, 1.0764816, 925.59015, 0.42389604)
   validation loss 797.1697387695312, (551.9527, 0.94104546, 243.85208, 0.42389604)
decoder loss ratio: 21383.605743, decoder SINDy loss  ratio: 0.526389
--- 0.2803609371185303 seconds for one epoch ---
--- 0.32137084007263184 seconds for one epoch ---
--- 2.132364273071289 seconds for one epoch ---
--- 0.32407569885253906 seconds for one epoch ---
--- 2.0670530796051025 seconds for one epoch ---
--- 0.3163161277770996 seconds for one epoch ---
--- 2.1007070541381836 seconds for one epoch ---
--- 0.3282938003540039 seconds for one epoch ---
--- 2.0909690856933594 seconds for one epoch ---
--- 0.331754207611084 seconds for one epoch ---
--- 2.0813958644866943 seconds for one epoch ---
--- 0.3269662857055664 seconds for one epoch ---
--- 2.135880708694458 seconds for one epoch ---
--- 0.31726551055908203 seconds for one epoch ---
--- 2.131477117538452 seconds for one epoch ---
--- 0.319821834564209 seconds for one epoch ---
--- 2.09793758392334 seconds for one epoch ---
--- 0.3241734504699707 seconds for one epoch ---
--- 2.137204647064209 seconds for one epoch ---
--- 0.3201174736022949 seconds for one epoch ---
--- 2.0908799171447754 seconds for one epoch ---
--- 0.3230559825897217 seconds for one epoch ---
--- 2.090336561203003 seconds for one epoch ---
--- 0.304872989654541 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989561]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.342804]
 [ -0.      ]]
--- 0.2455437183380127 seconds for one epoch ---
Epoch 4125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2429.62060546875, (1115.8942, 0.47650322, 1312.8256, 0.4242865)
   validation loss 755.1295166015625, (494.98157, 0.876767, 258.84683, 0.4242865)
decoder loss ratio: 19176.445246, decoder SINDy loss  ratio: 0.558757
--- 0.3185749053955078 seconds for one epoch ---
--- 2.110835552215576 seconds for one epoch ---
--- 0.3238813877105713 seconds for one epoch ---
--- 2.151934862136841 seconds for one epoch ---
--- 0.3247227668762207 seconds for one epoch ---
--- 2.132868766784668 seconds for one epoch ---
--- 0.3119354248046875 seconds for one epoch ---
--- 2.118717908859253 seconds for one epoch ---
--- 0.3035144805908203 seconds for one epoch ---
--- 2.09895396232605 seconds for one epoch ---
--- 0.3217153549194336 seconds for one epoch ---
--- 2.113778591156006 seconds for one epoch ---
--- 0.3098115921020508 seconds for one epoch ---
--- 2.1427953243255615 seconds for one epoch ---
--- 0.3251302242279053 seconds for one epoch ---
--- 2.1225783824920654 seconds for one epoch ---
--- 0.3137643337249756 seconds for one epoch ---
--- 2.1486949920654297 seconds for one epoch ---
--- 0.31284213066101074 seconds for one epoch ---
--- 2.082235097885132 seconds for one epoch ---
--- 0.3165280818939209 seconds for one epoch ---
--- 2.151531219482422 seconds for one epoch ---
--- 0.3134775161743164 seconds for one epoch ---
--- 2.154696226119995 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989593]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.353527]
 [  0.      ]]
--- 0.30984997749328613 seconds for one epoch ---
Epoch 4150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5355.17529296875, (1851.0582, 4.667538, 3499.0254, 0.42452508)
   validation loss 952.0557861328125, (663.5477, 0.7853429, 287.29822, 0.42452508)
decoder loss ratio: 25706.991010, decoder SINDy loss  ratio: 0.620174
--- 0.24193739891052246 seconds for one epoch ---
--- 0.31714630126953125 seconds for one epoch ---
--- 2.110558032989502 seconds for one epoch ---
--- 0.309528112411499 seconds for one epoch ---
--- 2.151458263397217 seconds for one epoch ---
--- 0.3260366916656494 seconds for one epoch ---
--- 2.1067843437194824 seconds for one epoch ---
--- 0.3192448616027832 seconds for one epoch ---
--- 2.1524813175201416 seconds for one epoch ---
--- 0.3252997398376465 seconds for one epoch ---
--- 2.1343636512756348 seconds for one epoch ---
--- 0.3088696002960205 seconds for one epoch ---
--- 2.1618306636810303 seconds for one epoch ---
--- 0.3034355640411377 seconds for one epoch ---
--- 2.1553702354431152 seconds for one epoch ---
--- 0.32207608222961426 seconds for one epoch ---
--- 2.115983247756958 seconds for one epoch ---
--- 0.3270707130432129 seconds for one epoch ---
--- 2.163501262664795 seconds for one epoch ---
--- 0.33317041397094727 seconds for one epoch ---
--- 2.1272103786468506 seconds for one epoch ---
--- 0.31147122383117676 seconds for one epoch ---
--- 2.1522185802459717 seconds for one epoch ---
--- 0.31825971603393555 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989637]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.365953]
 [ -0.      ]]
--- 0.26861047744750977 seconds for one epoch ---
Epoch 4175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3029.49169921875, (2140.8335, 0.92223436, 887.3114, 0.42487165)
   validation loss 821.5311889648438, (567.07294, 0.8839234, 253.1495, 0.42487165)
decoder loss ratio: 21969.390062, decoder SINDy loss  ratio: 0.546459
--- 0.29944396018981934 seconds for one epoch ---
--- 2.134028434753418 seconds for one epoch ---
--- 0.31732797622680664 seconds for one epoch ---
--- 2.151167154312134 seconds for one epoch ---
--- 0.31676769256591797 seconds for one epoch ---
--- 2.1568384170532227 seconds for one epoch ---
--- 0.31983351707458496 seconds for one epoch ---
--- 2.1827709674835205 seconds for one epoch ---
--- 0.31160402297973633 seconds for one epoch ---
--- 2.1825196743011475 seconds for one epoch ---
--- 0.32366251945495605 seconds for one epoch ---
--- 2.1306333541870117 seconds for one epoch ---
--- 0.31091952323913574 seconds for one epoch ---
--- 2.1762502193450928 seconds for one epoch ---
--- 0.3246123790740967 seconds for one epoch ---
--- 2.179965019226074 seconds for one epoch ---
--- 0.30635690689086914 seconds for one epoch ---
--- 2.1613214015960693 seconds for one epoch ---
--- 0.31253623962402344 seconds for one epoch ---
--- 2.182795763015747 seconds for one epoch ---
--- 0.32465052604675293 seconds for one epoch ---
--- 2.156336545944214 seconds for one epoch ---
--- 0.3228762149810791 seconds for one epoch ---
--- 2.192988634109497 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989687]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [-16.37991]
 [  0.     ]]
--- 0.3022282123565674 seconds for one epoch ---
Epoch 4200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5284.34130859375, (877.498, 3.7794757, 4402.6387, 0.42515156)
   validation loss 776.9157104492188, (518.56116, 0.83480006, 257.0946, 0.42515156)
decoder loss ratio: 20089.959493, decoder SINDy loss  ratio: 0.554975
--- 0.2634696960449219 seconds for one epoch ---
--- 0.3242371082305908 seconds for one epoch ---
--- 2.116886615753174 seconds for one epoch ---
--- 0.3256685733795166 seconds for one epoch ---
--- 2.1338887214660645 seconds for one epoch ---
--- 0.3219161033630371 seconds for one epoch ---
--- 2.181828260421753 seconds for one epoch ---
--- 0.3193051815032959 seconds for one epoch ---
--- 2.123202085494995 seconds for one epoch ---
--- 0.31793975830078125 seconds for one epoch ---
--- 2.1363685131073 seconds for one epoch ---
--- 0.32884645462036133 seconds for one epoch ---
--- 2.182694911956787 seconds for one epoch ---
--- 0.314176082611084 seconds for one epoch ---
--- 2.1932461261749268 seconds for one epoch ---
--- 0.31467485427856445 seconds for one epoch ---
--- 2.144380807876587 seconds for one epoch ---
--- 0.3197634220123291 seconds for one epoch ---
--- 2.13403582572937 seconds for one epoch ---
--- 0.3227121829986572 seconds for one epoch ---
--- 2.187450647354126 seconds for one epoch ---
--- 0.31689929962158203 seconds for one epoch ---
--- 2.194430112838745 seconds for one epoch ---
--- 0.3187551498413086 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989722]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.389498]
 [ -0.      ]]
--- 0.2464456558227539 seconds for one epoch ---
Epoch 4225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2387.0009765625, (1523.6384, 0.27400362, 862.6632, 0.42537785)
   validation loss 745.2999267578125, (497.63632, 0.8652384, 246.37302, 0.42537785)
decoder loss ratio: 19279.295050, decoder SINDy loss  ratio: 0.531831
--- 0.2971987724304199 seconds for one epoch ---
--- 2.1573328971862793 seconds for one epoch ---
--- 0.32045745849609375 seconds for one epoch ---
--- 2.177443265914917 seconds for one epoch ---
--- 0.31064295768737793 seconds for one epoch ---
--- 2.154223918914795 seconds for one epoch ---
--- 0.30712223052978516 seconds for one epoch ---
--- 2.1735737323760986 seconds for one epoch ---
--- 0.3271026611328125 seconds for one epoch ---
--- 2.1925203800201416 seconds for one epoch ---
--- 0.3118736743927002 seconds for one epoch ---
--- 2.149927854537964 seconds for one epoch ---
--- 0.32520127296447754 seconds for one epoch ---
--- 2.1474785804748535 seconds for one epoch ---
--- 0.31951141357421875 seconds for one epoch ---
--- 2.1562345027923584 seconds for one epoch ---
--- 0.3238532543182373 seconds for one epoch ---
--- 2.1852123737335205 seconds for one epoch ---
--- 0.3299288749694824 seconds for one epoch ---
--- 2.2044665813446045 seconds for one epoch ---
--- 0.31679344177246094 seconds for one epoch ---
--- 2.215628147125244 seconds for one epoch ---
--- 0.313946008682251 seconds for one epoch ---
--- 2.2095677852630615 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99897844]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.406942]
 [  0.      ]]
--- 0.30318331718444824 seconds for one epoch ---
Epoch 4250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4461.6318359375, (1146.8933, 1.8181248, 3312.4949, 0.42576763)
   validation loss 732.981689453125, (493.04398, 0.8565812, 238.65538, 0.42576763)
decoder loss ratio: 19101.379586, decoder SINDy loss  ratio: 0.515171
--- 0.27738189697265625 seconds for one epoch ---
--- 0.3117218017578125 seconds for one epoch ---
--- 2.167478561401367 seconds for one epoch ---
--- 0.3160731792449951 seconds for one epoch ---
--- 2.174306631088257 seconds for one epoch ---
--- 0.3029637336730957 seconds for one epoch ---
--- 2.1445488929748535 seconds for one epoch ---
--- 0.31260156631469727 seconds for one epoch ---
--- 2.2075116634368896 seconds for one epoch ---
--- 0.3145482540130615 seconds for one epoch ---
--- 2.191594123840332 seconds for one epoch ---
--- 0.3280215263366699 seconds for one epoch ---
--- 2.149603843688965 seconds for one epoch ---
--- 0.3281135559082031 seconds for one epoch ---
--- 2.1828086376190186 seconds for one epoch ---
--- 0.3249940872192383 seconds for one epoch ---
--- 2.2083563804626465 seconds for one epoch ---
--- 0.3191108703613281 seconds for one epoch ---
--- 2.1542277336120605 seconds for one epoch ---
--- 0.3158586025238037 seconds for one epoch ---
--- 2.180406093597412 seconds for one epoch ---
--- 0.3124234676361084 seconds for one epoch ---
--- 2.207540273666382 seconds for one epoch ---
--- 0.3160738945007324 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989804]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.415337]
 [  0.      ]]
--- 0.256397008895874 seconds for one epoch ---
Epoch 4275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4108.7158203125, (2107.0774, 0.9052698, 2000.3076, 0.42601785)
   validation loss 912.68798828125, (645.44354, 0.8487679, 265.9697, 0.42601785)
decoder loss ratio: 25005.603375, decoder SINDy loss  ratio: 0.574133
--- 0.30541396141052246 seconds for one epoch ---
--- 2.215015411376953 seconds for one epoch ---
--- 0.3318605422973633 seconds for one epoch ---
--- 2.16628360748291 seconds for one epoch ---
--- 0.3314096927642822 seconds for one epoch ---
--- 2.155363082885742 seconds for one epoch ---
--- 0.3247983455657959 seconds for one epoch ---
--- 2.177687168121338 seconds for one epoch ---
--- 0.31754231452941895 seconds for one epoch ---
--- 2.1999258995056152 seconds for one epoch ---
--- 0.3300611972808838 seconds for one epoch ---
--- 2.2061429023742676 seconds for one epoch ---
--- 0.32324886322021484 seconds for one epoch ---
--- 2.206117868423462 seconds for one epoch ---
--- 0.3293187618255615 seconds for one epoch ---
--- 2.2098336219787598 seconds for one epoch ---
--- 0.3191664218902588 seconds for one epoch ---
--- 2.181734561920166 seconds for one epoch ---
--- 0.3197915554046631 seconds for one epoch ---
--- 2.1965904235839844 seconds for one epoch ---
--- 0.32631778717041016 seconds for one epoch ---
--- 2.2250447273254395 seconds for one epoch ---
--- 0.3310713768005371 seconds for one epoch ---
--- 2.1801276206970215 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989828]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.421268]
 [ -0.      ]]
--- 0.29544973373413086 seconds for one epoch ---
Epoch 4300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2887.394287109375, (1367.6732, 2.1515856, 1517.1434, 0.42614332)
   validation loss 826.4970092773438, (579.67633, 0.8433412, 245.55122, 0.42614332)
decoder loss ratio: 22457.667409, decoder SINDy loss  ratio: 0.530057
--- 0.27205920219421387 seconds for one epoch ---
--- 0.34364819526672363 seconds for one epoch ---
--- 2.2020676136016846 seconds for one epoch ---
--- 0.3237028121948242 seconds for one epoch ---
--- 2.191615581512451 seconds for one epoch ---
--- 0.3335747718811035 seconds for one epoch ---
--- 2.2174315452575684 seconds for one epoch ---
--- 0.32646846771240234 seconds for one epoch ---
--- 2.1909186840057373 seconds for one epoch ---
--- 0.33180761337280273 seconds for one epoch ---
--- 2.1888387203216553 seconds for one epoch ---
--- 0.32248425483703613 seconds for one epoch ---
--- 2.2137584686279297 seconds for one epoch ---
--- 0.32378196716308594 seconds for one epoch ---
--- 2.1897125244140625 seconds for one epoch ---
--- 0.32124781608581543 seconds for one epoch ---
--- 2.2143640518188477 seconds for one epoch ---
--- 0.32221412658691406 seconds for one epoch ---
--- 2.244992733001709 seconds for one epoch ---
--- 0.3255043029785156 seconds for one epoch ---
--- 2.2001967430114746 seconds for one epoch ---
--- 0.3437178134918213 seconds for one epoch ---
--- 2.181875467300415 seconds for one epoch ---
--- 0.32148194313049316 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99898636]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.43034]
 [  0.     ]]
--- 0.2708771228790283 seconds for one epoch ---
Epoch 4325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5700.29931640625, (983.19794, 3.255059, 4713.42, 0.42635742)
   validation loss 998.4876098632812, (737.114, 0.85024375, 260.09708, 0.42635742)
decoder loss ratio: 28557.076576, decoder SINDy loss  ratio: 0.561456
--- 0.30705857276916504 seconds for one epoch ---
--- 2.1889350414276123 seconds for one epoch ---
--- 0.3228135108947754 seconds for one epoch ---
--- 2.232107400894165 seconds for one epoch ---
--- 0.32373595237731934 seconds for one epoch ---
--- 2.1902010440826416 seconds for one epoch ---
--- 0.3208487033843994 seconds for one epoch ---
--- 2.201995611190796 seconds for one epoch ---
--- 0.32574939727783203 seconds for one epoch ---
--- 2.2175252437591553 seconds for one epoch ---
--- 0.33077406883239746 seconds for one epoch ---
--- 2.2154994010925293 seconds for one epoch ---
--- 0.3121333122253418 seconds for one epoch ---
--- 2.1934399604797363 seconds for one epoch ---
--- 0.32463669776916504 seconds for one epoch ---
--- 2.2458157539367676 seconds for one epoch ---
--- 0.33341479301452637 seconds for one epoch ---
--- 2.1870648860931396 seconds for one epoch ---
--- 0.30911731719970703 seconds for one epoch ---
--- 2.209479808807373 seconds for one epoch ---
--- 0.3218708038330078 seconds for one epoch ---
--- 2.208620309829712 seconds for one epoch ---
--- 0.32208871841430664 seconds for one epoch ---
--- 2.258059501647949 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989893]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.436563]
 [ -0.      ]]
--- 0.31266021728515625 seconds for one epoch ---
Epoch 4350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1835.904052734375, (703.0746, 0.52013034, 1131.8828, 0.42649528)
   validation loss 865.6076049804688, (602.2356, 0.85982686, 262.0857, 0.42649528)
decoder loss ratio: 23331.652505, decoder SINDy loss  ratio: 0.565749
--- 0.2631385326385498 seconds for one epoch ---
--- 0.3180856704711914 seconds for one epoch ---
--- 2.2320001125335693 seconds for one epoch ---
--- 0.3237128257751465 seconds for one epoch ---
--- 2.2213659286499023 seconds for one epoch ---
--- 0.32758522033691406 seconds for one epoch ---
--- 2.2150378227233887 seconds for one epoch ---
--- 0.31584596633911133 seconds for one epoch ---
--- 2.209627866744995 seconds for one epoch ---
--- 0.3269658088684082 seconds for one epoch ---
--- 2.2213635444641113 seconds for one epoch ---
--- 0.32643651962280273 seconds for one epoch ---
--- 2.2193267345428467 seconds for one epoch ---
--- 0.3213684558868408 seconds for one epoch ---
--- 2.253598213195801 seconds for one epoch ---
--- 0.319033145904541 seconds for one epoch ---
--- 2.1953983306884766 seconds for one epoch ---
--- 0.31458568572998047 seconds for one epoch ---
--- 2.2602009773254395 seconds for one epoch ---
--- 0.31673407554626465 seconds for one epoch ---
--- 2.2511119842529297 seconds for one epoch ---
--- 0.32093286514282227 seconds for one epoch ---
--- 2.228642463684082 seconds for one epoch ---
--- 0.331312894821167 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989914]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.445377]
 [ -0.      ]]
--- 0.26036715507507324 seconds for one epoch ---
Epoch 4375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3008.8916015625, (1464.5582, 0.13073632, 1543.7759, 0.42673942)
   validation loss 858.43017578125, (607.9076, 0.9293791, 249.16644, 0.42673942)
decoder loss ratio: 23551.395518, decoder SINDy loss  ratio: 0.537861
--- 0.2976970672607422 seconds for one epoch ---
--- 2.226778030395508 seconds for one epoch ---
--- 0.306354284286499 seconds for one epoch ---
--- 2.247229814529419 seconds for one epoch ---
--- 0.3374369144439697 seconds for one epoch ---
--- 2.248359203338623 seconds for one epoch ---
--- 0.30847620964050293 seconds for one epoch ---
--- 2.2173736095428467 seconds for one epoch ---
--- 0.3207404613494873 seconds for one epoch ---
--- 2.250384569168091 seconds for one epoch ---
--- 0.31799840927124023 seconds for one epoch ---
--- 2.2162437438964844 seconds for one epoch ---
--- 0.3197464942932129 seconds for one epoch ---
--- 2.2590386867523193 seconds for one epoch ---
--- 0.3239457607269287 seconds for one epoch ---
--- 2.2141311168670654 seconds for one epoch ---
--- 0.31514477729797363 seconds for one epoch ---
--- 2.270589590072632 seconds for one epoch ---
--- 0.32439327239990234 seconds for one epoch ---
--- 2.26326060295105 seconds for one epoch ---
--- 0.3332099914550781 seconds for one epoch ---
--- 2.2569711208343506 seconds for one epoch ---
--- 0.3257906436920166 seconds for one epoch ---
--- 2.2540011405944824 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99899614]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.457355]
 [  0.      ]]
--- 0.2969019412994385 seconds for one epoch ---
Epoch 4400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2153.773193359375, (959.49945, 2.479523, 1191.3673, 0.4269975)
   validation loss 735.861083984375, (484.18356, 0.8665366, 250.38399, 0.4269975)
decoder loss ratio: 18758.111819, decoder SINDy loss  ratio: 0.540489
--- 0.27279138565063477 seconds for one epoch ---
--- 0.31845712661743164 seconds for one epoch ---
--- 2.2322945594787598 seconds for one epoch ---
--- 0.3252875804901123 seconds for one epoch ---
--- 2.21052885055542 seconds for one epoch ---
--- 0.3306427001953125 seconds for one epoch ---
--- 2.2008650302886963 seconds for one epoch ---
--- 0.3121023178100586 seconds for one epoch ---
--- 2.2564573287963867 seconds for one epoch ---
--- 0.3208465576171875 seconds for one epoch ---
--- 2.1982383728027344 seconds for one epoch ---
--- 0.3152801990509033 seconds for one epoch ---
--- 2.2455315589904785 seconds for one epoch ---
--- 0.3323476314544678 seconds for one epoch ---
--- 2.2305545806884766 seconds for one epoch ---
--- 0.3160817623138428 seconds for one epoch ---
--- 2.2331316471099854 seconds for one epoch ---
--- 0.3117640018463135 seconds for one epoch ---
--- 2.2222678661346436 seconds for one epoch ---
--- 0.3251166343688965 seconds for one epoch ---
--- 2.2684743404388428 seconds for one epoch ---
--- 0.32625913619995117 seconds for one epoch ---
--- 2.234147548675537 seconds for one epoch ---
--- 0.3180093765258789 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99900234]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.473549]
 [  0.      ]]
--- 0.26729536056518555 seconds for one epoch ---
Epoch 4425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2488.467041015625, (1457.2468, 0.45962146, 1030.333, 0.42744166)
   validation loss 937.699462890625, (659.4962, 0.8130866, 276.9627, 0.42744166)
decoder loss ratio: 25550.028337, decoder SINDy loss  ratio: 0.597863
--- 0.29944276809692383 seconds for one epoch ---
--- 2.2877302169799805 seconds for one epoch ---
--- 0.3121516704559326 seconds for one epoch ---
--- 2.259777069091797 seconds for one epoch ---
--- 0.33487725257873535 seconds for one epoch ---
--- 2.2415904998779297 seconds for one epoch ---
--- 0.32625699043273926 seconds for one epoch ---
--- 2.2432236671447754 seconds for one epoch ---
--- 0.3161633014678955 seconds for one epoch ---
--- 2.23568058013916 seconds for one epoch ---
--- 0.3315002918243408 seconds for one epoch ---
--- 2.2939348220825195 seconds for one epoch ---
--- 0.30487895011901855 seconds for one epoch ---
--- 2.289865732192993 seconds for one epoch ---
--- 0.3287465572357178 seconds for one epoch ---
--- 2.2511203289031982 seconds for one epoch ---
--- 0.32631468772888184 seconds for one epoch ---
--- 2.243985891342163 seconds for one epoch ---
--- 0.3146958351135254 seconds for one epoch ---
--- 2.265061855316162 seconds for one epoch ---
--- 0.3135383129119873 seconds for one epoch ---
--- 2.3043837547302246 seconds for one epoch ---
--- 0.32224321365356445 seconds for one epoch ---
--- 2.265018939971924 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990057]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.486069]
 [ -0.      ]]
--- 0.2909996509552002 seconds for one epoch ---
Epoch 4450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2857.346923828125, (1778.4469, 0.35480845, 1078.1174, 0.4277551)
   validation loss 1238.754150390625, (951.96875, 0.8579825, 285.49963, 0.4277551)
decoder loss ratio: 36880.922065, decoder SINDy loss  ratio: 0.616291
--- 0.25183725357055664 seconds for one epoch ---
--- 0.3321666717529297 seconds for one epoch ---
--- 2.2254714965820312 seconds for one epoch ---
--- 0.3143644332885742 seconds for one epoch ---
--- 2.3172433376312256 seconds for one epoch ---
--- 0.317488431930542 seconds for one epoch ---
--- 2.249268054962158 seconds for one epoch ---
--- 0.30774927139282227 seconds for one epoch ---
--- 2.2334022521972656 seconds for one epoch ---
--- 0.31210923194885254 seconds for one epoch ---
--- 2.307990312576294 seconds for one epoch ---
--- 0.3188447952270508 seconds for one epoch ---
--- 2.301145315170288 seconds for one epoch ---
--- 0.32964015007019043 seconds for one epoch ---
--- 2.2722296714782715 seconds for one epoch ---
--- 0.31368160247802734 seconds for one epoch ---
--- 2.3045217990875244 seconds for one epoch ---
--- 0.32505106925964355 seconds for one epoch ---
--- 2.3067808151245117 seconds for one epoch ---
--- 0.3145740032196045 seconds for one epoch ---
--- 2.2593765258789062 seconds for one epoch ---
--- 0.3236820697784424 seconds for one epoch ---
--- 2.3024659156799316 seconds for one epoch ---
--- 0.32086706161499023 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990098]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.496805]
 [ -0.      ]]
--- 0.2683894634246826 seconds for one epoch ---
Epoch 4475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2749.818603515625, (1405.0515, 5.2172794, 1339.1217, 0.42796656)
   validation loss 816.6240844726562, (557.79254, 0.8710162, 257.53253, 0.42796656)
decoder loss ratio: 21609.851428, decoder SINDy loss  ratio: 0.555920
--- 0.32502222061157227 seconds for one epoch ---
--- 2.2564382553100586 seconds for one epoch ---
--- 0.33533596992492676 seconds for one epoch ---
--- 2.2486190795898438 seconds for one epoch ---
--- 0.330202579498291 seconds for one epoch ---
--- 2.266554594039917 seconds for one epoch ---
--- 0.31560516357421875 seconds for one epoch ---
--- 2.300065517425537 seconds for one epoch ---
--- 0.3267834186553955 seconds for one epoch ---
--- 2.2805423736572266 seconds for one epoch ---
--- 0.30890631675720215 seconds for one epoch ---
--- 2.3087384700775146 seconds for one epoch ---
--- 0.32705163955688477 seconds for one epoch ---
--- 2.273191452026367 seconds for one epoch ---
--- 0.33478426933288574 seconds for one epoch ---
--- 2.3026716709136963 seconds for one epoch ---
--- 0.3168332576751709 seconds for one epoch ---
--- 2.305422782897949 seconds for one epoch ---
--- 0.3259623050689697 seconds for one epoch ---
--- 2.2784109115600586 seconds for one epoch ---
--- 0.32576894760131836 seconds for one epoch ---
--- 2.308776617050171 seconds for one epoch ---
--- 0.29384779930114746 seconds for one epoch ---
--- 2.2824878692626953 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99901307]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.505339]
 [  0.      ]]
--- 0.3108701705932617 seconds for one epoch ---
Epoch 4500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1626.4613037109375, (846.8899, 0.24156591, 778.9017, 0.42812315)
   validation loss 927.922119140625, (666.8881, 0.9637465, 259.64215, 0.42812315)
decoder loss ratio: 25836.403637, decoder SINDy loss  ratio: 0.560474
THRESHOLDING: 1 active coefficients
--- 0.26369380950927734 seconds for one epoch ---
--- 0.3321957588195801 seconds for one epoch ---
--- 2.273843288421631 seconds for one epoch ---
--- 0.3251183032989502 seconds for one epoch ---
--- 2.3107500076293945 seconds for one epoch ---
--- 0.31944704055786133 seconds for one epoch ---
--- 2.2971606254577637 seconds for one epoch ---
--- 0.3300607204437256 seconds for one epoch ---
--- 2.294996500015259 seconds for one epoch ---
--- 0.32440853118896484 seconds for one epoch ---
--- 2.2783613204956055 seconds for one epoch ---
--- 0.32990360260009766 seconds for one epoch ---
--- 2.283966064453125 seconds for one epoch ---
--- 0.31726980209350586 seconds for one epoch ---
--- 2.277726411819458 seconds for one epoch ---
--- 0.3333001136779785 seconds for one epoch ---
--- 2.3411436080932617 seconds for one epoch ---
--- 0.3223879337310791 seconds for one epoch ---
--- 2.314216375350952 seconds for one epoch ---
--- 0.3187870979309082 seconds for one epoch ---
--- 2.309994697570801 seconds for one epoch ---
--- 0.31673264503479004 seconds for one epoch ---
--- 2.347780704498291 seconds for one epoch ---
--- 0.3333733081817627 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990149]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.512459]
 [ -0.      ]]
--- 0.27313899993896484 seconds for one epoch ---
Epoch 4525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3363.439453125, (1893.4076, 2.2139387, 1467.3895, 0.42830563)
   validation loss 949.4151000976562, (701.6096, 0.9392072, 246.43802, 0.42830563)
decoder loss ratio: 27181.574693, decoder SINDy loss  ratio: 0.531971
--- 0.32282042503356934 seconds for one epoch ---
--- 2.3050053119659424 seconds for one epoch ---
--- 0.32711148262023926 seconds for one epoch ---
--- 2.300771713256836 seconds for one epoch ---
--- 0.3344388008117676 seconds for one epoch ---
--- 2.304837942123413 seconds for one epoch ---
--- 0.32578420639038086 seconds for one epoch ---
--- 2.3453292846679688 seconds for one epoch ---
--- 0.3311636447906494 seconds for one epoch ---
--- 2.319432258605957 seconds for one epoch ---
--- 0.32938432693481445 seconds for one epoch ---
--- 2.3125052452087402 seconds for one epoch ---
--- 0.3007988929748535 seconds for one epoch ---
--- 2.299056053161621 seconds for one epoch ---
--- 0.3289501667022705 seconds for one epoch ---
--- 2.3052361011505127 seconds for one epoch ---
--- 0.3203730583190918 seconds for one epoch ---
--- 2.355466365814209 seconds for one epoch ---
--- 0.32699084281921387 seconds for one epoch ---
--- 2.3215301036834717 seconds for one epoch ---
--- 0.3286750316619873 seconds for one epoch ---
--- 2.306943655014038 seconds for one epoch ---
--- 0.3126530647277832 seconds for one epoch ---
--- 2.3345088958740234 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990184]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.524899]
 [  0.      ]]
--- 0.30063509941101074 seconds for one epoch ---
Epoch 4550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2145.665771484375, (974.3079, 1.0619395, 1169.8673, 0.42858228)
   validation loss 801.3883056640625, (552.05676, 0.91851336, 247.98445, 0.42858228)
decoder loss ratio: 21387.637400, decoder SINDy loss  ratio: 0.535309
--- 0.2740459442138672 seconds for one epoch ---
--- 0.3354008197784424 seconds for one epoch ---
--- 2.3059566020965576 seconds for one epoch ---
--- 0.33595991134643555 seconds for one epoch ---
--- 2.342890739440918 seconds for one epoch ---
--- 0.3125145435333252 seconds for one epoch ---
--- 2.3534889221191406 seconds for one epoch ---
--- 0.33515310287475586 seconds for one epoch ---
--- 2.29903507232666 seconds for one epoch ---
--- 0.27782273292541504 seconds for one epoch ---
--- 2.3010456562042236 seconds for one epoch ---
--- 0.33352017402648926 seconds for one epoch ---
--- 2.326385021209717 seconds for one epoch ---
--- 0.323483943939209 seconds for one epoch ---
--- 2.315762758255005 seconds for one epoch ---
--- 0.3241391181945801 seconds for one epoch ---
--- 2.3627638816833496 seconds for one epoch ---
--- 0.3152942657470703 seconds for one epoch ---
--- 2.3076441287994385 seconds for one epoch ---
--- 0.3166961669921875 seconds for one epoch ---
--- 2.3508317470550537 seconds for one epoch ---
--- 0.31669020652770996 seconds for one epoch ---
--- 2.3493614196777344 seconds for one epoch ---
--- 0.30649900436401367 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99902004]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.528639]
 [ -0.      ]]
--- 0.2535557746887207 seconds for one epoch ---
Epoch 4575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2668.503173828125, (727.0799, 0.4462857, 1940.5483, 0.42870674)
   validation loss 840.9129028320312, (578.70386, 0.87710977, 260.9032, 0.42870674)
decoder loss ratio: 22419.992111, decoder SINDy loss  ratio: 0.563196
--- 0.3159050941467285 seconds for one epoch ---
--- 2.3661653995513916 seconds for one epoch ---
--- 0.3241300582885742 seconds for one epoch ---
--- 2.344472646713257 seconds for one epoch ---
--- 0.32564425468444824 seconds for one epoch ---
--- 2.332531213760376 seconds for one epoch ---
--- 0.302487850189209 seconds for one epoch ---
--- 2.3353352546691895 seconds for one epoch ---
--- 0.31890058517456055 seconds for one epoch ---
--- 2.320261001586914 seconds for one epoch ---
--- 0.32537031173706055 seconds for one epoch ---
--- 2.367687940597534 seconds for one epoch ---
--- 0.32808923721313477 seconds for one epoch ---
--- 2.358057737350464 seconds for one epoch ---
--- 0.32427072525024414 seconds for one epoch ---
--- 2.3180031776428223 seconds for one epoch ---
--- 0.3114180564880371 seconds for one epoch ---
--- 2.3034207820892334 seconds for one epoch ---
--- 0.29173707962036133 seconds for one epoch ---
--- 2.379657506942749 seconds for one epoch ---
--- 0.3183746337890625 seconds for one epoch ---
--- 2.3320698738098145 seconds for one epoch ---
--- 0.3180055618286133 seconds for one epoch ---
--- 2.3678553104400635 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99902374]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.538979]
 [  0.      ]]
--- 0.307464599609375 seconds for one epoch ---
Epoch 4600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2687.30517578125, (1289.1124, 2.2752903, 1395.4885, 0.42890856)
   validation loss 745.5988159179688, (499.69894, 0.8781792, 244.5928, 0.42890856)
decoder loss ratio: 19359.204610, decoder SINDy loss  ratio: 0.527988
--- 0.27051377296447754 seconds for one epoch ---
--- 0.311809778213501 seconds for one epoch ---
--- 2.3507988452911377 seconds for one epoch ---
--- 0.33550143241882324 seconds for one epoch ---
--- 2.3607547283172607 seconds for one epoch ---
--- 0.32112574577331543 seconds for one epoch ---
--- 2.330291748046875 seconds for one epoch ---
--- 0.319652795791626 seconds for one epoch ---
--- 2.3647704124450684 seconds for one epoch ---
--- 0.3144824504852295 seconds for one epoch ---
--- 2.355036735534668 seconds for one epoch ---
--- 0.3154287338256836 seconds for one epoch ---
--- 2.3555960655212402 seconds for one epoch ---
--- 0.32155442237854004 seconds for one epoch ---
--- 2.328498363494873 seconds for one epoch ---
--- 0.3267078399658203 seconds for one epoch ---
--- 2.3149170875549316 seconds for one epoch ---
--- 0.31687188148498535 seconds for one epoch ---
--- 2.3600258827209473 seconds for one epoch ---
--- 0.3214249610900879 seconds for one epoch ---
--- 2.342643976211548 seconds for one epoch ---
--- 0.32621264457702637 seconds for one epoch ---
--- 2.374866008758545 seconds for one epoch ---
--- 0.32111167907714844 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990244]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.544294]
 [  0.      ]]
--- 0.2708616256713867 seconds for one epoch ---
Epoch 4625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4658.13134765625, (1148.293, 2.434565, 3506.9744, 0.42907983)
   validation loss 811.6426391601562, (569.96014, 0.92128414, 240.33214, 0.42907983)
decoder loss ratio: 22081.245475, decoder SINDy loss  ratio: 0.518791
--- 0.3104405403137207 seconds for one epoch ---
--- 2.3354077339172363 seconds for one epoch ---
--- 0.32268476486206055 seconds for one epoch ---
--- 2.3755505084991455 seconds for one epoch ---
--- 0.32260894775390625 seconds for one epoch ---
--- 2.332819700241089 seconds for one epoch ---
--- 0.31859493255615234 seconds for one epoch ---
--- 2.362154722213745 seconds for one epoch ---
--- 0.33381199836730957 seconds for one epoch ---
--- 2.3333897590637207 seconds for one epoch ---
--- 0.3229641914367676 seconds for one epoch ---
--- 2.3948824405670166 seconds for one epoch ---
--- 0.3160724639892578 seconds for one epoch ---
--- 2.3876421451568604 seconds for one epoch ---
--- 0.3174569606781006 seconds for one epoch ---
--- 2.3570377826690674 seconds for one epoch ---
--- 0.3250007629394531 seconds for one epoch ---
--- 2.3697333335876465 seconds for one epoch ---
--- 0.3275480270385742 seconds for one epoch ---
--- 2.3612213134765625 seconds for one epoch ---
--- 0.3184623718261719 seconds for one epoch ---
--- 2.4057841300964355 seconds for one epoch ---
--- 0.2983856201171875 seconds for one epoch ---
--- 2.343282699584961 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990274]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.553549]
 [ -0.      ]]
--- 0.30081820487976074 seconds for one epoch ---
Epoch 4650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2531.525146484375, (877.15375, 1.9796507, 1651.9623, 0.4293216)
   validation loss 746.4302978515625, (505.642, 0.89975643, 239.45926, 0.4293216)
decoder loss ratio: 19589.448847, decoder SINDy loss  ratio: 0.516906
--- 0.2727053165435791 seconds for one epoch ---
--- 0.32914257049560547 seconds for one epoch ---
--- 2.383058786392212 seconds for one epoch ---
--- 0.32114171981811523 seconds for one epoch ---
--- 2.3573617935180664 seconds for one epoch ---
--- 0.3205723762512207 seconds for one epoch ---
--- 2.3579084873199463 seconds for one epoch ---
--- 0.3210594654083252 seconds for one epoch ---
--- 2.3804709911346436 seconds for one epoch ---
--- 0.3266303539276123 seconds for one epoch ---
--- 2.331977605819702 seconds for one epoch ---
--- 0.3187291622161865 seconds for one epoch ---
--- 2.403376579284668 seconds for one epoch ---
--- 0.33546972274780273 seconds for one epoch ---
--- 2.342434883117676 seconds for one epoch ---
--- 0.3198063373565674 seconds for one epoch ---
--- 2.3503448963165283 seconds for one epoch ---
--- 0.3339834213256836 seconds for one epoch ---
--- 2.384709119796753 seconds for one epoch ---
--- 0.33486413955688477 seconds for one epoch ---
--- 2.3484275341033936 seconds for one epoch ---
--- 0.32633304595947266 seconds for one epoch ---
--- 2.3590691089630127 seconds for one epoch ---
--- 0.31418585777282715 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990301]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.561266]
 [  0.      ]]
--- 0.26632070541381836 seconds for one epoch ---
Epoch 4675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2244.653076171875, (972.19824, 1.3728142, 1270.6526, 0.42952475)
   validation loss 729.5654907226562, (486.6706, 0.8627797, 241.60258, 0.42952475)
decoder loss ratio: 18854.463680, decoder SINDy loss  ratio: 0.521533
--- 0.30782151222229004 seconds for one epoch ---
--- 2.411242961883545 seconds for one epoch ---
--- 0.31377434730529785 seconds for one epoch ---
--- 2.335219144821167 seconds for one epoch ---
--- 0.3263664245605469 seconds for one epoch ---
--- 2.361015558242798 seconds for one epoch ---
--- 0.31290555000305176 seconds for one epoch ---
--- 2.3766400814056396 seconds for one epoch ---
--- 0.32341933250427246 seconds for one epoch ---
--- 2.3492250442504883 seconds for one epoch ---
--- 0.32940220832824707 seconds for one epoch ---
--- 2.37300443649292 seconds for one epoch ---
--- 0.31539273262023926 seconds for one epoch ---
--- 2.401573419570923 seconds for one epoch ---
--- 0.3270895481109619 seconds for one epoch ---
--- 2.353818416595459 seconds for one epoch ---
--- 0.3175699710845947 seconds for one epoch ---
--- 2.380828619003296 seconds for one epoch ---
--- 0.2886791229248047 seconds for one epoch ---
--- 2.35556697845459 seconds for one epoch ---
--- 0.3225691318511963 seconds for one epoch ---
--- 2.381725311279297 seconds for one epoch ---
--- 0.32671284675598145 seconds for one epoch ---
--- 2.42212176322937 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99903405]
 [0.        ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.56831]
 [ -0.     ]]
--- 0.3123915195465088 seconds for one epoch ---
Epoch 4700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2077.14794921875, (1004.9047, 1.241198, 1070.5723, 0.42968264)
   validation loss 997.834228515625, (759.3553, 0.87333614, 237.17592, 0.42968264)
decoder loss ratio: 29418.742065, decoder SINDy loss  ratio: 0.511978
--- 0.26401209831237793 seconds for one epoch ---
--- 0.30543947219848633 seconds for one epoch ---
--- 2.3497345447540283 seconds for one epoch ---
--- 0.3134799003601074 seconds for one epoch ---
--- 2.3692049980163574 seconds for one epoch ---
--- 0.3329763412475586 seconds for one epoch ---
--- 2.395658493041992 seconds for one epoch ---
--- 0.3090250492095947 seconds for one epoch ---
--- 2.393101215362549 seconds for one epoch ---
--- 0.3193225860595703 seconds for one epoch ---
--- 2.417315721511841 seconds for one epoch ---
--- 0.33197522163391113 seconds for one epoch ---
--- 2.401276111602783 seconds for one epoch ---
--- 0.3292505741119385 seconds for one epoch ---
--- 2.4200186729431152 seconds for one epoch ---
--- 0.3149549961090088 seconds for one epoch ---
--- 2.432770013809204 seconds for one epoch ---
--- 0.30979323387145996 seconds for one epoch ---
--- 2.4152896404266357 seconds for one epoch ---
--- 0.3251824378967285 seconds for one epoch ---
--- 2.4252984523773193 seconds for one epoch ---
--- 0.32407450675964355 seconds for one epoch ---
--- 2.3692550659179688 seconds for one epoch ---
--- 0.3212854862213135 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990362]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.575256]
 [ -0.      ]]
--- 0.2655506134033203 seconds for one epoch ---
Epoch 4725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3024.066162109375, (1570.5789, 0.7277535, 1452.3296, 0.42984897)
   validation loss 893.3784790039062, (638.4073, 0.85813165, 253.68317, 0.42984897)
decoder loss ratio: 24733.006645, decoder SINDy loss  ratio: 0.547611
--- 0.3074321746826172 seconds for one epoch ---
--- 2.3792858123779297 seconds for one epoch ---
--- 0.3217275142669678 seconds for one epoch ---
--- 2.3956210613250732 seconds for one epoch ---
--- 0.3136112689971924 seconds for one epoch ---
--- 2.364527463912964 seconds for one epoch ---
--- 0.3190493583679199 seconds for one epoch ---
--- 2.426476240158081 seconds for one epoch ---
--- 0.32584595680236816 seconds for one epoch ---
--- 2.3725826740264893 seconds for one epoch ---
--- 0.3054494857788086 seconds for one epoch ---
--- 2.361457347869873 seconds for one epoch ---
--- 0.30890679359436035 seconds for one epoch ---
--- 2.3817708492279053 seconds for one epoch ---
--- 0.304990291595459 seconds for one epoch ---
--- 2.4126901626586914 seconds for one epoch ---
--- 0.32872867584228516 seconds for one epoch ---
--- 2.380251407623291 seconds for one epoch ---
--- 0.31536364555358887 seconds for one epoch ---
--- 2.41497540473938 seconds for one epoch ---
--- 0.3138570785522461 seconds for one epoch ---
--- 2.430704116821289 seconds for one epoch ---
--- 0.314685583114624 seconds for one epoch ---
--- 2.3877625465393066 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99904054]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.587334]
 [  0.      ]]
--- 0.30739688873291016 seconds for one epoch ---
Epoch 4750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2258.585693359375, (1374.7397, 0.38510692, 883.03064, 0.4301746)
   validation loss 850.912841796875, (599.0885, 0.938474, 250.4557, 0.4301746)
decoder loss ratio: 23209.728591, decoder SINDy loss  ratio: 0.540644
--- 0.26003050804138184 seconds for one epoch ---
--- 0.3274862766265869 seconds for one epoch ---
--- 2.3847062587738037 seconds for one epoch ---
--- 0.3331449031829834 seconds for one epoch ---
--- 2.419968843460083 seconds for one epoch ---
--- 0.317702054977417 seconds for one epoch ---
--- 2.439016103744507 seconds for one epoch ---
--- 0.32929134368896484 seconds for one epoch ---
--- 2.3948843479156494 seconds for one epoch ---
--- 0.3149998188018799 seconds for one epoch ---
--- 2.3905093669891357 seconds for one epoch ---
--- 0.3259553909301758 seconds for one epoch ---
--- 2.37615704536438 seconds for one epoch ---
--- 0.323275089263916 seconds for one epoch ---
--- 2.3900601863861084 seconds for one epoch ---
--- 0.3205244541168213 seconds for one epoch ---
--- 2.4242072105407715 seconds for one epoch ---
--- 0.32932019233703613 seconds for one epoch ---
--- 2.4020657539367676 seconds for one epoch ---
--- 0.31729578971862793 seconds for one epoch ---
--- 2.3959741592407227 seconds for one epoch ---
--- 0.33229780197143555 seconds for one epoch ---
--- 2.4024252891540527 seconds for one epoch ---
--- 0.31860947608947754 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990439]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.596823]
 [  0.      ]]
--- 0.25677919387817383 seconds for one epoch ---
Epoch 4775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1611.6688232421875, (734.61926, 1.456903, 875.1624, 0.43035656)
   validation loss 853.7626953125, (613.7275, 0.9735588, 238.6313, 0.43035656)
decoder loss ratio: 23776.867977, decoder SINDy loss  ratio: 0.515119
--- 0.31618762016296387 seconds for one epoch ---
--- 2.429940700531006 seconds for one epoch ---
--- 0.3208909034729004 seconds for one epoch ---
--- 2.392324447631836 seconds for one epoch ---
--- 0.3300139904022217 seconds for one epoch ---
--- 2.4405088424682617 seconds for one epoch ---
--- 0.3046445846557617 seconds for one epoch ---
--- 2.4500885009765625 seconds for one epoch ---
--- 0.32167816162109375 seconds for one epoch ---
--- 2.3983852863311768 seconds for one epoch ---
--- 0.3065030574798584 seconds for one epoch ---
--- 2.393446207046509 seconds for one epoch ---
--- 0.3269813060760498 seconds for one epoch ---
--- 2.3580820560455322 seconds for one epoch ---
--- 0.3213531970977783 seconds for one epoch ---
--- 2.403179168701172 seconds for one epoch ---
--- 0.32447052001953125 seconds for one epoch ---
--- 2.4058871269226074 seconds for one epoch ---
--- 0.31665873527526855 seconds for one epoch ---
--- 2.4615039825439453 seconds for one epoch ---
--- 0.3173232078552246 seconds for one epoch ---
--- 2.4037511348724365 seconds for one epoch ---
--- 0.32550549507141113 seconds for one epoch ---
--- 2.427090644836426 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99904776]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.609957]
 [ -0.      ]]
--- 0.30178141593933105 seconds for one epoch ---
Epoch 4800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1904.677978515625, (1215.7671, 0.48490492, 687.9953, 0.43069965)
   validation loss 1016.2225952148438, (758.17883, 0.99434197, 256.61868, 0.43069965)
decoder loss ratio: 29373.164247, decoder SINDy loss  ratio: 0.553948
--- 0.2661588191986084 seconds for one epoch ---
--- 0.3301668167114258 seconds for one epoch ---
--- 2.4502358436584473 seconds for one epoch ---
--- 0.3216111660003662 seconds for one epoch ---
--- 2.440157890319824 seconds for one epoch ---
--- 0.31513524055480957 seconds for one epoch ---
--- 2.4534754753112793 seconds for one epoch ---
--- 0.3261570930480957 seconds for one epoch ---
--- 2.4430899620056152 seconds for one epoch ---
--- 0.3095407485961914 seconds for one epoch ---
--- 2.4088287353515625 seconds for one epoch ---
--- 0.32400083541870117 seconds for one epoch ---
--- 2.407784938812256 seconds for one epoch ---
--- 0.3029458522796631 seconds for one epoch ---
--- 2.4666619300842285 seconds for one epoch ---
--- 0.3216829299926758 seconds for one epoch ---
--- 2.4657607078552246 seconds for one epoch ---
--- 0.319368839263916 seconds for one epoch ---
--- 2.4693613052368164 seconds for one epoch ---
--- 0.3278636932373047 seconds for one epoch ---
--- 2.4232568740844727 seconds for one epoch ---
--- 0.3281843662261963 seconds for one epoch ---
--- 2.4150962829589844 seconds for one epoch ---
--- 0.32666635513305664 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990486]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.615206]
 [ -0.      ]]
--- 0.26535820960998535 seconds for one epoch ---
Epoch 4825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1514.3082275390625, (873.0173, 0.74544185, 640.11475, 0.43080893)
   validation loss 765.546142578125, (525.999, 0.9934072, 238.12292, 0.43080893)
decoder loss ratio: 20378.115342, decoder SINDy loss  ratio: 0.514022
--- 0.3011479377746582 seconds for one epoch ---
--- 2.464038133621216 seconds for one epoch ---
--- 0.3207361698150635 seconds for one epoch ---
--- 2.3809211254119873 seconds for one epoch ---
--- 0.31010007858276367 seconds for one epoch ---
--- 2.474108934402466 seconds for one epoch ---
--- 0.3375558853149414 seconds for one epoch ---
--- 2.441473960876465 seconds for one epoch ---
--- 0.3229224681854248 seconds for one epoch ---
--- 2.482233762741089 seconds for one epoch ---
--- 0.33080101013183594 seconds for one epoch ---
--- 2.429870367050171 seconds for one epoch ---
--- 0.31040096282958984 seconds for one epoch ---
--- 2.433487892150879 seconds for one epoch ---
--- 0.32518529891967773 seconds for one epoch ---
--- 2.4889490604400635 seconds for one epoch ---
--- 0.3284163475036621 seconds for one epoch ---
--- 2.459054470062256 seconds for one epoch ---
--- 0.32149720191955566 seconds for one epoch ---
--- 2.4841206073760986 seconds for one epoch ---
--- 0.3161323070526123 seconds for one epoch ---
--- 2.477844476699829 seconds for one epoch ---
--- 0.3122091293334961 seconds for one epoch ---
--- 2.478121280670166 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990492]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.619308]
 [  0.      ]]
--- 0.30182719230651855 seconds for one epoch ---
Epoch 4850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3272.9794921875, (883.6787, 3.104323, 2385.7656, 0.43089467)
   validation loss 948.2701416015625, (686.62787, 0.9841035, 260.2272, 0.43089467)
decoder loss ratio: 26601.155670, decoder SINDy loss  ratio: 0.561737
--- 0.2664954662322998 seconds for one epoch ---
--- 0.32901859283447266 seconds for one epoch ---
--- 2.436105966567993 seconds for one epoch ---
--- 0.3200528621673584 seconds for one epoch ---
--- 2.44551944732666 seconds for one epoch ---
--- 0.31438446044921875 seconds for one epoch ---
--- 2.469849109649658 seconds for one epoch ---
--- 0.32622766494750977 seconds for one epoch ---
--- 2.493785858154297 seconds for one epoch ---
--- 0.322967529296875 seconds for one epoch ---
--- 2.4422061443328857 seconds for one epoch ---
--- 0.3183460235595703 seconds for one epoch ---
--- 2.4650535583496094 seconds for one epoch ---
--- 0.3196699619293213 seconds for one epoch ---
--- 2.4408342838287354 seconds for one epoch ---
--- 0.33817434310913086 seconds for one epoch ---
--- 2.4389419555664062 seconds for one epoch ---
--- 0.3186821937561035 seconds for one epoch ---
--- 2.478586435317993 seconds for one epoch ---
--- 0.3175222873687744 seconds for one epoch ---
--- 2.498833656311035 seconds for one epoch ---
--- 0.3298320770263672 seconds for one epoch ---
--- 2.5014808177948 seconds for one epoch ---
--- 0.327838659286499 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990505]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.622658]
 [ -0.      ]]
--- 0.24718952178955078 seconds for one epoch ---
Epoch 4875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3976.306884765625, (1650.4816, 1.2930256, 2324.1013, 0.4310258)
   validation loss 1087.7318115234375, (832.1477, 1.0469334, 254.1062, 0.4310258)
decoder loss ratio: 32238.846767, decoder SINDy loss  ratio: 0.548524
--- 0.30928468704223633 seconds for one epoch ---
--- 2.424980401992798 seconds for one epoch ---
--- 0.3184340000152588 seconds for one epoch ---
--- 2.449767827987671 seconds for one epoch ---
--- 0.2891693115234375 seconds for one epoch ---
--- 2.5047831535339355 seconds for one epoch ---
--- 0.3328855037689209 seconds for one epoch ---
--- 2.452425956726074 seconds for one epoch ---
--- 0.3186321258544922 seconds for one epoch ---
--- 2.4501590728759766 seconds for one epoch ---
--- 0.30297303199768066 seconds for one epoch ---
--- 2.427851915359497 seconds for one epoch ---
--- 0.3140754699707031 seconds for one epoch ---
--- 2.50671648979187 seconds for one epoch ---
--- 0.3160426616668701 seconds for one epoch ---
--- 2.4492948055267334 seconds for one epoch ---
--- 0.3220713138580322 seconds for one epoch ---
--- 2.5007476806640625 seconds for one epoch ---
--- 0.32767653465270996 seconds for one epoch ---
--- 2.4602701663970947 seconds for one epoch ---
--- 0.32146430015563965 seconds for one epoch ---
--- 2.470425844192505 seconds for one epoch ---
--- 0.3175516128540039 seconds for one epoch ---
--- 2.4751691818237305 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990548]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.636812]
 [  0.      ]]
--- 0.302778959274292 seconds for one epoch ---
Epoch 4900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2513.246337890625, (845.5908, 1.0803326, 1666.1439, 0.4313062)
   validation loss 783.3795166015625, (543.5706, 1.0530924, 238.32448, 0.4313062)
decoder loss ratio: 21058.869409, decoder SINDy loss  ratio: 0.514457
--- 0.26668572425842285 seconds for one epoch ---
--- 0.32558226585388184 seconds for one epoch ---
--- 2.4309492111206055 seconds for one epoch ---
--- 0.32514357566833496 seconds for one epoch ---
--- 2.464259386062622 seconds for one epoch ---
--- 0.32634973526000977 seconds for one epoch ---
--- 2.466939926147461 seconds for one epoch ---
--- 0.3306102752685547 seconds for one epoch ---
--- 2.4953207969665527 seconds for one epoch ---
--- 0.3242461681365967 seconds for one epoch ---
--- 2.445314645767212 seconds for one epoch ---
--- 0.3338642120361328 seconds for one epoch ---
--- 2.4607925415039062 seconds for one epoch ---
--- 0.31374073028564453 seconds for one epoch ---
--- 2.439812660217285 seconds for one epoch ---
--- 0.3193376064300537 seconds for one epoch ---
--- 2.4907238483428955 seconds for one epoch ---
--- 0.32173728942871094 seconds for one epoch ---
--- 2.4948649406433105 seconds for one epoch ---
--- 0.320847749710083 seconds for one epoch ---
--- 2.533336639404297 seconds for one epoch ---
--- 0.31961655616760254 seconds for one epoch ---
--- 2.5109434127807617 seconds for one epoch ---
--- 0.3191230297088623 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99905765]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.644365]
 [ -0.      ]]
--- 0.26702046394348145 seconds for one epoch ---
Epoch 4925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3097.432373046875, (1281.9236, 1.1249777, 1813.9523, 0.43150765)
   validation loss 765.5728149414062, (517.24524, 1.028588, 246.8675, 0.43150765)
decoder loss ratio: 20038.978546, decoder SINDy loss  ratio: 0.532898
--- 0.30645251274108887 seconds for one epoch ---
--- 2.481300115585327 seconds for one epoch ---
--- 0.32782888412475586 seconds for one epoch ---
--- 2.4884212017059326 seconds for one epoch ---
--- 0.31949543952941895 seconds for one epoch ---
--- 2.4731175899505615 seconds for one epoch ---
--- 0.31534671783447266 seconds for one epoch ---
--- 2.462435722351074 seconds for one epoch ---
--- 0.317486047744751 seconds for one epoch ---
--- 2.4673526287078857 seconds for one epoch ---
--- 0.32205772399902344 seconds for one epoch ---
--- 2.4804117679595947 seconds for one epoch ---
--- 0.31638479232788086 seconds for one epoch ---
--- 2.474490165710449 seconds for one epoch ---
--- 0.31357502937316895 seconds for one epoch ---
--- 2.4513726234436035 seconds for one epoch ---
--- 0.33958935737609863 seconds for one epoch ---
--- 2.4851410388946533 seconds for one epoch ---
--- 0.32131361961364746 seconds for one epoch ---
--- 2.521857738494873 seconds for one epoch ---
--- 0.3308401107788086 seconds for one epoch ---
--- 2.511282205581665 seconds for one epoch ---
--- 0.3241300582885742 seconds for one epoch ---
--- 2.482011556625366 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99905956]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.652876]
 [  0.      ]]
--- 0.31049108505249023 seconds for one epoch ---
Epoch 4950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2886.069091796875, (1321.225, 1.5452265, 1562.8673, 0.43169457)
   validation loss 862.4452514648438, (617.1588, 1.0039628, 243.8508, 0.43169457)
decoder loss ratio: 23909.803869, decoder SINDy loss  ratio: 0.526386
--- 0.2820165157318115 seconds for one epoch ---
--- 0.3208894729614258 seconds for one epoch ---
--- 2.472778797149658 seconds for one epoch ---
--- 0.3288249969482422 seconds for one epoch ---
--- 2.489366292953491 seconds for one epoch ---
--- 0.3105478286743164 seconds for one epoch ---
--- 2.5071706771850586 seconds for one epoch ---
--- 0.32294154167175293 seconds for one epoch ---
--- 2.506166934967041 seconds for one epoch ---
--- 0.32416248321533203 seconds for one epoch ---
--- 2.5221118927001953 seconds for one epoch ---
--- 0.31977272033691406 seconds for one epoch ---
--- 2.5399973392486572 seconds for one epoch ---
--- 0.7532503604888916 seconds for one epoch ---
--- 2.4767539501190186 seconds for one epoch ---
--- 0.31055426597595215 seconds for one epoch ---
--- 2.484874963760376 seconds for one epoch ---
--- 0.3380162715911865 seconds for one epoch ---
--- 2.5308547019958496 seconds for one epoch ---
--- 0.29387593269348145 seconds for one epoch ---
--- 2.4843719005584717 seconds for one epoch ---
--- 0.3284037113189697 seconds for one epoch ---
--- 2.5048043727874756 seconds for one epoch ---
--- 0.3185739517211914 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999061]
 [0.      ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.658583]
 [  0.      ]]
--- 0.2773768901824951 seconds for one epoch ---
Epoch 4975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4309.13525390625, (1707.5468, 1.7505257, 2599.4065, 0.431868)
   validation loss 733.771728515625, (494.75745, 1.005772, 237.57661, 0.431868)
decoder loss ratio: 19167.762406, decoder SINDy loss  ratio: 0.512843
--- 0.3023362159729004 seconds for one epoch ---
--- 2.500650405883789 seconds for one epoch ---
--- 0.33271336555480957 seconds for one epoch ---
--- 2.4880688190460205 seconds for one epoch ---
--- 0.3187873363494873 seconds for one epoch ---
--- 2.5558149814605713 seconds for one epoch ---
--- 0.3287029266357422 seconds for one epoch ---
--- 2.4901833534240723 seconds for one epoch ---
--- 0.3189539909362793 seconds for one epoch ---
--- 2.5378127098083496 seconds for one epoch ---
--- 0.3162038326263428 seconds for one epoch ---
--- 2.4717676639556885 seconds for one epoch ---
--- 0.3168008327484131 seconds for one epoch ---
--- 2.498046636581421 seconds for one epoch ---
--- 0.33347535133361816 seconds for one epoch ---
--- 2.5010933876037598 seconds for one epoch ---
--- 0.33226585388183594 seconds for one epoch ---
--- 2.5030221939086914 seconds for one epoch ---
--- 0.323911190032959 seconds for one epoch ---
--- 2.5185811519622803 seconds for one epoch ---
--- 0.3122994899749756 seconds for one epoch ---
--- 2.5573182106018066 seconds for one epoch ---
--- 0.3250541687011719 seconds for one epoch ---
--- 2.503044843673706 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990636]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.666965]
 [ -0.      ]]
--- 0.3111402988433838 seconds for one epoch ---
Epoch 5000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4431.41162109375, (1385.3549, 3.1019478, 3042.523, 0.43209276)
   validation loss 865.2719116210938, (614.8084, 0.98534316, 249.04611, 0.43209276)
decoder loss ratio: 23818.745183, decoder SINDy loss  ratio: 0.537601
THRESHOLDING: 1 active coefficients
--- 2.5043227672576904 seconds for one epoch ---
--- 0.3286902904510498 seconds for one epoch ---
--- 2.5020911693573 seconds for one epoch ---
--- 0.31426119804382324 seconds for one epoch ---
--- 2.494053602218628 seconds for one epoch ---
--- 0.32097458839416504 seconds for one epoch ---
--- 2.539330005645752 seconds for one epoch ---
--- 0.33841538429260254 seconds for one epoch ---
--- 2.5038044452667236 seconds for one epoch ---
--- 0.3240377902984619 seconds for one epoch ---
--- 2.509242057800293 seconds for one epoch ---
--- 0.315108060836792 seconds for one epoch ---
--- 2.5268642902374268 seconds for one epoch ---
--- 0.32456183433532715 seconds for one epoch ---
--- 2.5631959438323975 seconds for one epoch ---
--- 0.3189883232116699 seconds for one epoch ---
--- 2.4905855655670166 seconds for one epoch ---
--- 0.32303929328918457 seconds for one epoch ---
--- 2.5410714149475098 seconds for one epoch ---
--- 0.31294989585876465 seconds for one epoch ---
--- 2.5087249279022217 seconds for one epoch ---
--- 0.3222019672393799 seconds for one epoch ---
--- 2.5650100708007812 seconds for one epoch ---
--- 0.31502485275268555 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999067]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.674139]
 [  0.      ]]
--- 0.26474928855895996 seconds for one epoch ---
Epoch 5025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3548.983154296875, (1118.4647, 2.5977075, 2427.4883, 0.4322655)
   validation loss 889.7421875, (643.40686, 1.0405682, 244.86252, 0.4322655)
decoder loss ratio: 24926.698773, decoder SINDy loss  ratio: 0.528570
--- 0.294771671295166 seconds for one epoch ---
--- 2.49056339263916 seconds for one epoch ---
--- 0.3318955898284912 seconds for one epoch ---
--- 2.5410661697387695 seconds for one epoch ---
--- 0.3154025077819824 seconds for one epoch ---
--- 2.5447049140930176 seconds for one epoch ---
--- 0.32381463050842285 seconds for one epoch ---
--- 2.510101556777954 seconds for one epoch ---
--- 0.3061239719390869 seconds for one epoch ---
--- 2.555429220199585 seconds for one epoch ---
--- 0.33028197288513184 seconds for one epoch ---
--- 2.511787176132202 seconds for one epoch ---
--- 0.3179209232330322 seconds for one epoch ---
--- 2.569833517074585 seconds for one epoch ---
--- 0.32352638244628906 seconds for one epoch ---
--- 2.5705180168151855 seconds for one epoch ---
--- 0.31184935569763184 seconds for one epoch ---
--- 2.526686429977417 seconds for one epoch ---
--- 0.34058213233947754 seconds for one epoch ---
--- 2.546757459640503 seconds for one epoch ---
--- 0.32678794860839844 seconds for one epoch ---
--- 2.5993993282318115 seconds for one epoch ---
--- 0.3122897148132324 seconds for one epoch ---
--- 2.571126699447632 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990703]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.681688]
 [ -0.      ]]
--- 0.3120884895324707 seconds for one epoch ---
Epoch 5050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2315.74267578125, (1159.0519, 1.0116285, 1155.2468, 0.4324072)
   validation loss 766.77734375, (520.3628, 1.0376931, 244.9444, 0.4324072)
decoder loss ratio: 20159.757989, decoder SINDy loss  ratio: 0.528747
--- 0.28065061569213867 seconds for one epoch ---
--- 0.32673144340515137 seconds for one epoch ---
--- 2.5482828617095947 seconds for one epoch ---
--- 0.31556248664855957 seconds for one epoch ---
--- 2.5552704334259033 seconds for one epoch ---
--- 0.33521032333374023 seconds for one epoch ---
--- 2.582430839538574 seconds for one epoch ---
--- 0.330913782119751 seconds for one epoch ---
--- 2.5389862060546875 seconds for one epoch ---
--- 0.3259885311126709 seconds for one epoch ---
--- 2.5862743854522705 seconds for one epoch ---
--- 0.3379685878753662 seconds for one epoch ---
--- 2.5457816123962402 seconds for one epoch ---
--- 0.3318204879760742 seconds for one epoch ---
--- 2.573819160461426 seconds for one epoch ---
--- 0.3161005973815918 seconds for one epoch ---
--- 2.56843900680542 seconds for one epoch ---
--- 0.2934226989746094 seconds for one epoch ---
--- 2.551668643951416 seconds for one epoch ---
--- 0.32498645782470703 seconds for one epoch ---
--- 2.5758883953094482 seconds for one epoch ---
--- 0.33164286613464355 seconds for one epoch ---
--- 2.537195920944214 seconds for one epoch ---
--- 0.3147304058074951 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99907124]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.687616]
 [ -0.      ]]
--- 0.2698054313659668 seconds for one epoch ---
Epoch 5075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2557.600830078125, (1194.9397, 0.7402734, 1361.4883, 0.43259126)
   validation loss 713.6160888671875, (472.7002, 1.0493853, 239.43391, 0.43259126)
decoder loss ratio: 18313.226210, decoder SINDy loss  ratio: 0.516852
--- 0.29542016983032227 seconds for one epoch ---
--- 2.544344186782837 seconds for one epoch ---
--- 0.3362758159637451 seconds for one epoch ---
--- 2.574362277984619 seconds for one epoch ---
--- 0.3247792720794678 seconds for one epoch ---
--- 2.521214485168457 seconds for one epoch ---
--- 0.32005810737609863 seconds for one epoch ---
--- 2.6007871627807617 seconds for one epoch ---
--- 0.3255455493927002 seconds for one epoch ---
--- 2.5354976654052734 seconds for one epoch ---
--- 0.3115882873535156 seconds for one epoch ---
--- 2.601973056793213 seconds for one epoch ---
--- 0.31478452682495117 seconds for one epoch ---
--- 2.535966157913208 seconds for one epoch ---
--- 0.3066132068634033 seconds for one epoch ---
--- 2.537217378616333 seconds for one epoch ---
--- 0.3103756904602051 seconds for one epoch ---
--- 2.550074815750122 seconds for one epoch ---
--- 0.3294250965118408 seconds for one epoch ---
--- 2.556990623474121 seconds for one epoch ---
--- 0.32490015029907227 seconds for one epoch ---
--- 2.544902801513672 seconds for one epoch ---
--- 0.3206765651702881 seconds for one epoch ---
--- 2.6294443607330322 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990731]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.694557]
 [  0.      ]]
--- 0.29374027252197266 seconds for one epoch ---
Epoch 5100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4081.88525390625, (1570.1449, 0.48358464, 2510.8242, 0.43270922)
   validation loss 806.2125854492188, (544.6859, 1.0093375, 260.0846, 0.43270922)
decoder loss ratio: 21102.077889, decoder SINDy loss  ratio: 0.561429
--- 0.26859426498413086 seconds for one epoch ---
--- 0.3271920680999756 seconds for one epoch ---
--- 2.5408577919006348 seconds for one epoch ---
--- 0.3188467025756836 seconds for one epoch ---
--- 2.540123462677002 seconds for one epoch ---
--- 0.32063937187194824 seconds for one epoch ---
--- 2.5702879428863525 seconds for one epoch ---
--- 0.31629133224487305 seconds for one epoch ---
--- 2.554839611053467 seconds for one epoch ---
--- 0.32503414154052734 seconds for one epoch ---
--- 2.5452287197113037 seconds for one epoch ---
--- 0.32863759994506836 seconds for one epoch ---
--- 2.58347225189209 seconds for one epoch ---
--- 0.3201003074645996 seconds for one epoch ---
--- 2.5444514751434326 seconds for one epoch ---
--- 0.3225290775299072 seconds for one epoch ---
--- 2.5948824882507324 seconds for one epoch ---
--- 0.33715295791625977 seconds for one epoch ---
--- 2.54661226272583 seconds for one epoch ---
--- 0.33377838134765625 seconds for one epoch ---
--- 2.585169792175293 seconds for one epoch ---
--- 0.3231685161590576 seconds for one epoch ---
--- 2.5584616661071777 seconds for one epoch ---
--- 0.32479238510131836 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990749]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.700903]
 [  0.      ]]
--- 0.26691365242004395 seconds for one epoch ---
Epoch 5125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2574.945068359375, (888.0278, 1.0111464, 1685.4734, 0.4328741)
   validation loss 793.5545654296875, (545.9171, 1.0577558, 246.14685, 0.4328741)
decoder loss ratio: 21149.776760, decoder SINDy loss  ratio: 0.531343
--- 0.30039191246032715 seconds for one epoch ---
--- 2.6021432876586914 seconds for one epoch ---
--- 0.3228156566619873 seconds for one epoch ---
--- 2.5559258460998535 seconds for one epoch ---
--- 0.3198721408843994 seconds for one epoch ---
--- 2.5615479946136475 seconds for one epoch ---
--- 0.32332658767700195 seconds for one epoch ---
--- 2.543897867202759 seconds for one epoch ---
--- 0.32790184020996094 seconds for one epoch ---
--- 2.59277606010437 seconds for one epoch ---
--- 0.33500003814697266 seconds for one epoch ---
--- 2.538051128387451 seconds for one epoch ---
--- 0.29491424560546875 seconds for one epoch ---
--- 2.5600903034210205 seconds for one epoch ---
--- 0.3148765563964844 seconds for one epoch ---
--- 2.5882182121276855 seconds for one epoch ---
--- 0.3059101104736328 seconds for one epoch ---
--- 2.5807135105133057 seconds for one epoch ---
--- 0.3234274387359619 seconds for one epoch ---
--- 2.6232805252075195 seconds for one epoch ---
--- 0.33569979667663574 seconds for one epoch ---
--- 2.5708415508270264 seconds for one epoch ---
--- 0.317873477935791 seconds for one epoch ---
--- 2.5772719383239746 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990772]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.707075]
 [ -0.      ]]
--- 0.30804443359375 seconds for one epoch ---
Epoch 5150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3704.31201171875, (1192.4991, 5.7966175, 2505.583, 0.4330615)
   validation loss 881.069580078125, (625.46375, 1.0218837, 254.1509, 0.4330615)
decoder loss ratio: 24231.551339, decoder SINDy loss  ratio: 0.548620
--- 0.27236437797546387 seconds for one epoch ---
--- 0.3303663730621338 seconds for one epoch ---
--- 2.6139230728149414 seconds for one epoch ---
--- 0.318950891494751 seconds for one epoch ---
--- 2.5606675148010254 seconds for one epoch ---
--- 0.3433341979980469 seconds for one epoch ---
--- 2.570695638656616 seconds for one epoch ---
--- 0.3173086643218994 seconds for one epoch ---
--- 2.627073049545288 seconds for one epoch ---
--- 0.32703375816345215 seconds for one epoch ---
--- 2.5860538482666016 seconds for one epoch ---
--- 0.3160243034362793 seconds for one epoch ---
--- 2.5859718322753906 seconds for one epoch ---
--- 0.327472448348999 seconds for one epoch ---
--- 2.5656306743621826 seconds for one epoch ---
--- 0.326740026473999 seconds for one epoch ---
--- 2.6403250694274902 seconds for one epoch ---
--- 0.32646846771240234 seconds for one epoch ---
--- 2.5702250003814697 seconds for one epoch ---
--- 0.32131266593933105 seconds for one epoch ---
--- 2.588657855987549 seconds for one epoch ---
--- 0.32949304580688477 seconds for one epoch ---
--- 2.651797294616699 seconds for one epoch ---
--- 0.3201732635498047 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990833]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.722124]
 [ -0.      ]]
--- 0.2614254951477051 seconds for one epoch ---
Epoch 5175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3855.5185546875, (953.0742, 4.3332524, 2897.6777, 0.4334223)
   validation loss 708.0606689453125, (464.35022, 1.0887188, 242.18832, 0.4334223)
decoder loss ratio: 17989.733660, decoder SINDy loss  ratio: 0.522798
--- 0.3100292682647705 seconds for one epoch ---
--- 2.595933198928833 seconds for one epoch ---
--- 0.30800294876098633 seconds for one epoch ---
--- 2.611677646636963 seconds for one epoch ---
--- 0.3221168518066406 seconds for one epoch ---
--- 2.59924054145813 seconds for one epoch ---
--- 0.32943105697631836 seconds for one epoch ---
--- 2.5822689533233643 seconds for one epoch ---
--- 0.327409029006958 seconds for one epoch ---
--- 2.5922131538391113 seconds for one epoch ---
--- 0.32024240493774414 seconds for one epoch ---
--- 2.5802083015441895 seconds for one epoch ---
--- 0.3300964832305908 seconds for one epoch ---
--- 2.613802433013916 seconds for one epoch ---
--- 0.3105452060699463 seconds for one epoch ---
--- 2.626248598098755 seconds for one epoch ---
--- 0.3034181594848633 seconds for one epoch ---
--- 2.6359360218048096 seconds for one epoch ---
--- 0.3253343105316162 seconds for one epoch ---
--- 2.6139986515045166 seconds for one epoch ---
--- 0.3173811435699463 seconds for one epoch ---
--- 2.6077585220336914 seconds for one epoch ---
--- 0.3158688545227051 seconds for one epoch ---
--- 2.6490769386291504 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990858]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.729944]
 [  0.      ]]
--- 0.30979156494140625 seconds for one epoch ---
Epoch 5200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2979.22021484375, (1134.5586, 1.2918702, 1842.9363, 0.433609)
   validation loss 747.647216796875, (508.07364, 1.0618426, 238.07814, 0.433609)
decoder loss ratio: 19683.654826, decoder SINDy loss  ratio: 0.513925
--- 0.2597033977508545 seconds for one epoch ---
--- 0.3329291343688965 seconds for one epoch ---
--- 2.6150166988372803 seconds for one epoch ---
--- 0.31795668601989746 seconds for one epoch ---
--- 2.6313555240631104 seconds for one epoch ---
--- 0.32417917251586914 seconds for one epoch ---
--- 2.580812454223633 seconds for one epoch ---
--- 0.3237144947052002 seconds for one epoch ---
--- 2.6399130821228027 seconds for one epoch ---
--- 0.3246757984161377 seconds for one epoch ---
--- 2.629182815551758 seconds for one epoch ---
--- 0.31837940216064453 seconds for one epoch ---
--- 2.642862319946289 seconds for one epoch ---
--- 0.32297706604003906 seconds for one epoch ---
--- 2.643207550048828 seconds for one epoch ---
--- 0.32239317893981934 seconds for one epoch ---
--- 2.597809076309204 seconds for one epoch ---
--- 0.3302466869354248 seconds for one epoch ---
--- 2.6383473873138428 seconds for one epoch ---
--- 0.3249645233154297 seconds for one epoch ---
--- 2.6413402557373047 seconds for one epoch ---
--- 0.319110631942749 seconds for one epoch ---
--- 2.663788318634033 seconds for one epoch ---
--- 0.31908631324768066 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990875]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.739004]
 [ -0.      ]]
--- 0.2602348327636719 seconds for one epoch ---
Epoch 5225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2548.694580078125, (1071.4596, 2.0567036, 1474.7443, 0.43379173)
   validation loss 779.3876953125, (533.7242, 1.0964879, 244.13326, 0.43379173)
decoder loss ratio: 20677.401402, decoder SINDy loss  ratio: 0.526996
--- 0.3037149906158447 seconds for one epoch ---
--- 2.633859872817993 seconds for one epoch ---
--- 0.32355165481567383 seconds for one epoch ---
--- 2.588243007659912 seconds for one epoch ---
--- 0.3312976360321045 seconds for one epoch ---
--- 2.6695470809936523 seconds for one epoch ---
--- 0.32459545135498047 seconds for one epoch ---
--- 2.666354179382324 seconds for one epoch ---
--- 0.32642626762390137 seconds for one epoch ---
--- 2.668870210647583 seconds for one epoch ---
--- 0.33063626289367676 seconds for one epoch ---
--- 2.597266435623169 seconds for one epoch ---
--- 0.323167085647583 seconds for one epoch ---
--- 2.64278507232666 seconds for one epoch ---
--- 0.32148051261901855 seconds for one epoch ---
--- 2.621842861175537 seconds for one epoch ---
--- 0.3325643539428711 seconds for one epoch ---
--- 2.657142400741577 seconds for one epoch ---
--- 0.33281373977661133 seconds for one epoch ---
--- 2.6368279457092285 seconds for one epoch ---
--- 0.30682921409606934 seconds for one epoch ---
--- 2.659625768661499 seconds for one epoch ---
--- 0.3224599361419678 seconds for one epoch ---
--- 2.6551334857940674 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99908787]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.740042]
 [  0.      ]]
--- 0.3106536865234375 seconds for one epoch ---
Epoch 5250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3403.55029296875, (1210.2518, 1.9559672, 2190.9087, 0.43383542)
   validation loss 825.8836059570312, (584.2699, 1.0610228, 240.11882, 0.43383542)
decoder loss ratio: 22635.630165, decoder SINDy loss  ratio: 0.518330
--- 0.26140427589416504 seconds for one epoch ---
--- 0.32558584213256836 seconds for one epoch ---
--- 2.6685843467712402 seconds for one epoch ---
--- 0.32326412200927734 seconds for one epoch ---
--- 2.6186025142669678 seconds for one epoch ---
--- 0.3199155330657959 seconds for one epoch ---
--- 2.603431224822998 seconds for one epoch ---
--- 0.3431422710418701 seconds for one epoch ---
--- 2.6229236125946045 seconds for one epoch ---
--- 0.33188486099243164 seconds for one epoch ---
--- 2.6815202236175537 seconds for one epoch ---
--- 0.32221364974975586 seconds for one epoch ---
--- 2.6757652759552 seconds for one epoch ---
--- 0.33922815322875977 seconds for one epoch ---
--- 2.6299796104431152 seconds for one epoch ---
--- 0.3214993476867676 seconds for one epoch ---
--- 2.680159091949463 seconds for one epoch ---
--- 0.3352549076080322 seconds for one epoch ---
--- 2.663076162338257 seconds for one epoch ---
--- 0.3309664726257324 seconds for one epoch ---
--- 2.672025442123413 seconds for one epoch ---
--- 0.33294081687927246 seconds for one epoch ---
--- 2.6881678104400635 seconds for one epoch ---
--- 0.3225059509277344 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990905]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.746378]
 [ -0.      ]]
--- 0.2648332118988037 seconds for one epoch ---
Epoch 5275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5592.56982421875, (2197.2427, 1.1922069, 3393.7007, 0.434018)
   validation loss 889.1870727539062, (634.15515, 1.0985281, 253.49937, 0.434018)
decoder loss ratio: 24568.271506, decoder SINDy loss  ratio: 0.547214
--- 0.2880871295928955 seconds for one epoch ---
--- 2.6076302528381348 seconds for one epoch ---
--- 0.3303186893463135 seconds for one epoch ---
--- 2.690073251724243 seconds for one epoch ---
--- 0.3195617198944092 seconds for one epoch ---
--- 2.621173858642578 seconds for one epoch ---
--- 0.31990885734558105 seconds for one epoch ---
--- 2.6681721210479736 seconds for one epoch ---
--- 0.3182806968688965 seconds for one epoch ---
--- 2.6514058113098145 seconds for one epoch ---
--- 0.337658166885376 seconds for one epoch ---
--- 2.6809232234954834 seconds for one epoch ---
--- 0.33117032051086426 seconds for one epoch ---
--- 2.6438775062561035 seconds for one epoch ---
--- 0.32842469215393066 seconds for one epoch ---
--- 2.6535804271698 seconds for one epoch ---
--- 0.32015395164489746 seconds for one epoch ---
--- 2.680647850036621 seconds for one epoch ---
--- 0.31377625465393066 seconds for one epoch ---
--- 2.660078287124634 seconds for one epoch ---
--- 0.32622790336608887 seconds for one epoch ---
--- 2.6358423233032227 seconds for one epoch ---
--- 0.33708691596984863 seconds for one epoch ---
--- 2.6338233947753906 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990921]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.752914]
 [  0.      ]]
--- 0.3060002326965332 seconds for one epoch ---
Epoch 5300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2198.66259765625, (1253.9446, 0.14675349, 944.13715, 0.4341495)
   validation loss 728.3427124023438, (487.6467, 1.1332382, 239.1286, 0.4341495)
decoder loss ratio: 18892.279672, decoder SINDy loss  ratio: 0.516193
--- 0.2637326717376709 seconds for one epoch ---
--- 0.3149986267089844 seconds for one epoch ---
--- 2.6053943634033203 seconds for one epoch ---
--- 0.31987547874450684 seconds for one epoch ---
--- 2.631722927093506 seconds for one epoch ---
--- 0.3076486587524414 seconds for one epoch ---
--- 2.619722366333008 seconds for one epoch ---
--- 0.31306886672973633 seconds for one epoch ---
--- 2.6849074363708496 seconds for one epoch ---
--- 0.3281521797180176 seconds for one epoch ---
--- 2.6533119678497314 seconds for one epoch ---
--- 0.3275179862976074 seconds for one epoch ---
--- 2.6230287551879883 seconds for one epoch ---
--- 0.3293170928955078 seconds for one epoch ---
--- 2.6310312747955322 seconds for one epoch ---
--- 0.31972551345825195 seconds for one epoch ---
--- 2.685899496078491 seconds for one epoch ---
--- 0.33336639404296875 seconds for one epoch ---
--- 2.6439669132232666 seconds for one epoch ---
--- 0.3165709972381592 seconds for one epoch ---
--- 2.648935317993164 seconds for one epoch ---
--- 0.32853221893310547 seconds for one epoch ---
--- 2.6710455417633057 seconds for one epoch ---
--- 0.32086896896362305 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99909556]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.761728]
 [  0.      ]]
--- 0.2607576847076416 seconds for one epoch ---
Epoch 5325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1793.02001953125, (1040.1486, 0.7615701, 751.6755, 0.43435487)
   validation loss 715.211181640625, (475.7956, 1.0860655, 237.8952, 0.43435487)
decoder loss ratio: 18433.147300, decoder SINDy loss  ratio: 0.513530
--- 0.31082987785339355 seconds for one epoch ---
--- 2.666994571685791 seconds for one epoch ---
--- 0.3190732002258301 seconds for one epoch ---
--- 2.6457295417785645 seconds for one epoch ---
--- 0.3213791847229004 seconds for one epoch ---
--- 2.677669048309326 seconds for one epoch ---
--- 0.32025742530822754 seconds for one epoch ---
--- 2.6772642135620117 seconds for one epoch ---
--- 0.32051968574523926 seconds for one epoch ---
--- 2.693896532058716 seconds for one epoch ---
--- 0.3256978988647461 seconds for one epoch ---
--- 2.6833267211914062 seconds for one epoch ---
--- 0.3202054500579834 seconds for one epoch ---
--- 2.712024450302124 seconds for one epoch ---
--- 0.33865857124328613 seconds for one epoch ---
--- 2.655193328857422 seconds for one epoch ---
--- 0.32269835472106934 seconds for one epoch ---
--- 2.6778173446655273 seconds for one epoch ---
--- 0.3207995891571045 seconds for one epoch ---
--- 2.658275604248047 seconds for one epoch ---
--- 0.3217151165008545 seconds for one epoch ---
--- 2.714078903198242 seconds for one epoch ---
--- 0.32300472259521484 seconds for one epoch ---
--- 2.72304105758667 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990958]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.761984]
 [ -0.      ]]
--- 0.2968935966491699 seconds for one epoch ---
Epoch 5350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2634.820556640625, (1502.3306, 0.55783206, 1131.4977, 0.4343987)
   validation loss 786.774658203125, (544.7014, 1.1020195, 240.53688, 0.4343987)
decoder loss ratio: 21102.678500, decoder SINDy loss  ratio: 0.519233
--- 0.26813387870788574 seconds for one epoch ---
--- 0.32707929611206055 seconds for one epoch ---
--- 2.640561103820801 seconds for one epoch ---
--- 0.32897448539733887 seconds for one epoch ---
--- 2.6785173416137695 seconds for one epoch ---
--- 0.3146672248840332 seconds for one epoch ---
--- 2.7016408443450928 seconds for one epoch ---
--- 0.3303864002227783 seconds for one epoch ---
--- 2.7004072666168213 seconds for one epoch ---
--- 0.329378604888916 seconds for one epoch ---
--- 2.678365707397461 seconds for one epoch ---
--- 0.33509230613708496 seconds for one epoch ---
--- 2.6772396564483643 seconds for one epoch ---
--- 0.3216266632080078 seconds for one epoch ---
--- 2.7144861221313477 seconds for one epoch ---
--- 0.3247256278991699 seconds for one epoch ---
--- 2.6879196166992188 seconds for one epoch ---
--- 0.3281698226928711 seconds for one epoch ---
--- 2.718522787094116 seconds for one epoch ---
--- 0.3127474784851074 seconds for one epoch ---
--- 2.7257461547851562 seconds for one epoch ---
--- 0.32369375228881836 seconds for one epoch ---
--- 2.6854066848754883 seconds for one epoch ---
--- 0.3379030227661133 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990981]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.772287]
 [  0.      ]]
--- 0.2590162754058838 seconds for one epoch ---
Epoch 5375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3196.566162109375, (1732.2657, 3.522012, 1460.3439, 0.43463936)
   validation loss 845.1080932617188, (593.9633, 1.1046528, 249.6055, 0.43463936)
decoder loss ratio: 23011.170100, decoder SINDy loss  ratio: 0.538809
--- 0.309283971786499 seconds for one epoch ---
--- 2.716149091720581 seconds for one epoch ---
--- 0.32744932174682617 seconds for one epoch ---
--- 2.651822805404663 seconds for one epoch ---
--- 0.31784558296203613 seconds for one epoch ---
--- 2.7211859226226807 seconds for one epoch ---
--- 0.3280782699584961 seconds for one epoch ---
--- 2.7080774307250977 seconds for one epoch ---
--- 0.3267331123352051 seconds for one epoch ---
--- 2.6755874156951904 seconds for one epoch ---
--- 0.3304789066314697 seconds for one epoch ---
--- 2.6976475715637207 seconds for one epoch ---
--- 0.3185453414916992 seconds for one epoch ---
--- 2.736142873764038 seconds for one epoch ---
--- 0.3229970932006836 seconds for one epoch ---
--- 2.7219579219818115 seconds for one epoch ---
--- 0.32744479179382324 seconds for one epoch ---
--- 2.68611478805542 seconds for one epoch ---
--- 0.3252732753753662 seconds for one epoch ---
--- 2.668994426727295 seconds for one epoch ---
--- 0.33208584785461426 seconds for one epoch ---
--- 2.729469060897827 seconds for one epoch ---
--- 0.3269319534301758 seconds for one epoch ---
--- 2.6990554332733154 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990995]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.779543]
 [ -0.      ]]
--- 0.3077659606933594 seconds for one epoch ---
Epoch 5400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2887.533447265625, (1090.492, 2.6498544, 1793.9567, 0.43481895)
   validation loss 780.5444946289062, (536.6348, 1.1046501, 242.37016, 0.43481895)
decoder loss ratio: 20790.164824, decoder SINDy loss  ratio: 0.523190
--- 0.2713043689727783 seconds for one epoch ---
--- 0.316007137298584 seconds for one epoch ---
--- 2.670269250869751 seconds for one epoch ---
--- 0.30321264266967773 seconds for one epoch ---
--- 2.6732349395751953 seconds for one epoch ---
--- 0.32554030418395996 seconds for one epoch ---
--- 2.72951078414917 seconds for one epoch ---
--- 0.31318140029907227 seconds for one epoch ---
--- 2.6833813190460205 seconds for one epoch ---
--- 0.3270535469055176 seconds for one epoch ---
--- 2.730403184890747 seconds for one epoch ---
--- 0.3180704116821289 seconds for one epoch ---
--- 2.7244515419006348 seconds for one epoch ---
--- 0.3180227279663086 seconds for one epoch ---
--- 2.680480718612671 seconds for one epoch ---
--- 0.31005144119262695 seconds for one epoch ---
--- 2.7307488918304443 seconds for one epoch ---
--- 0.31900644302368164 seconds for one epoch ---
--- 2.6920409202575684 seconds for one epoch ---
--- 0.3288581371307373 seconds for one epoch ---
--- 2.675297737121582 seconds for one epoch ---
--- 0.31977295875549316 seconds for one epoch ---
--- 2.754757881164551 seconds for one epoch ---
--- 0.317166805267334 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991027]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.789112]
 [ -0.      ]]
--- 0.2679615020751953 seconds for one epoch ---
Epoch 5425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3581.479736328125, (1490.722, 1.7813439, 2088.5413, 0.43502304)
   validation loss 790.9093627929688, (546.4127, 1.1038852, 242.95776, 0.43502304)
decoder loss ratio: 21168.977376, decoder SINDy loss  ratio: 0.524459
--- 0.30669379234313965 seconds for one epoch ---
--- 2.682819366455078 seconds for one epoch ---
--- 0.3070831298828125 seconds for one epoch ---
--- 2.7491958141326904 seconds for one epoch ---
--- 0.30991697311401367 seconds for one epoch ---
--- 2.704556703567505 seconds for one epoch ---
--- 0.3025813102722168 seconds for one epoch ---
--- 2.6863789558410645 seconds for one epoch ---
--- 0.32462310791015625 seconds for one epoch ---
--- 2.7323849201202393 seconds for one epoch ---
--- 0.32631921768188477 seconds for one epoch ---
--- 2.7661023139953613 seconds for one epoch ---
--- 0.32686805725097656 seconds for one epoch ---
--- 2.7561981678009033 seconds for one epoch ---
--- 0.3224787712097168 seconds for one epoch ---
--- 2.7453651428222656 seconds for one epoch ---
--- 0.3204379081726074 seconds for one epoch ---
--- 2.723416566848755 seconds for one epoch ---
--- 0.33605527877807617 seconds for one epoch ---
--- 2.690764904022217 seconds for one epoch ---
--- 0.32099294662475586 seconds for one epoch ---
--- 2.7365260124206543 seconds for one epoch ---
--- 0.32412004470825195 seconds for one epoch ---
--- 2.721829891204834 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99910396]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.792934]
 [  0.      ]]
--- 0.30800867080688477 seconds for one epoch ---
Epoch 5450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2452.244140625, (1228.4094, 3.2599697, 1220.1395, 0.43514225)
   validation loss 952.2562866210938, (702.10376, 1.1763163, 248.54105, 0.43514225)
decoder loss ratio: 27200.718559, decoder SINDy loss  ratio: 0.536511
--- 0.2628309726715088 seconds for one epoch ---
--- 0.32194948196411133 seconds for one epoch ---
--- 2.761843204498291 seconds for one epoch ---
--- 0.32014894485473633 seconds for one epoch ---
--- 2.764026403427124 seconds for one epoch ---
--- 0.319016695022583 seconds for one epoch ---
--- 2.7398359775543213 seconds for one epoch ---
--- 0.32535505294799805 seconds for one epoch ---
--- 2.7418365478515625 seconds for one epoch ---
--- 0.31846022605895996 seconds for one epoch ---
--- 2.699171304702759 seconds for one epoch ---
--- 0.32222771644592285 seconds for one epoch ---
--- 2.715024948120117 seconds for one epoch ---
--- 0.32684326171875 seconds for one epoch ---
--- 2.761840343475342 seconds for one epoch ---
--- 0.3355233669281006 seconds for one epoch ---
--- 2.711561918258667 seconds for one epoch ---
--- 0.3144533634185791 seconds for one epoch ---
--- 2.7469162940979004 seconds for one epoch ---
--- 0.3339550495147705 seconds for one epoch ---
--- 2.7037200927734375 seconds for one epoch ---
--- 0.32225704193115234 seconds for one epoch ---
--- 2.7039334774017334 seconds for one epoch ---
--- 0.32373690605163574 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99910617]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.799683]
 [  0.      ]]
--- 0.26819729804992676 seconds for one epoch ---
Epoch 5475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4036.34130859375, (1257.6919, 3.6631167, 2774.551, 0.43529525)
   validation loss 1083.72314453125, (811.0895, 1.1207073, 271.0777, 0.43529525)
decoder loss ratio: 31423.014473, decoder SINDy loss  ratio: 0.585159
--- 0.31623029708862305 seconds for one epoch ---
--- 2.7186810970306396 seconds for one epoch ---
--- 0.3295738697052002 seconds for one epoch ---
--- 2.749635696411133 seconds for one epoch ---
--- 0.31311821937561035 seconds for one epoch ---
--- 2.7065351009368896 seconds for one epoch ---
--- 0.3203911781311035 seconds for one epoch ---
--- 2.7679412364959717 seconds for one epoch ---
--- 0.3258073329925537 seconds for one epoch ---
--- 2.745161294937134 seconds for one epoch ---
--- 0.32857751846313477 seconds for one epoch ---
--- 2.7431447505950928 seconds for one epoch ---
--- 0.33115267753601074 seconds for one epoch ---
--- 2.7624948024749756 seconds for one epoch ---
--- 0.325272798538208 seconds for one epoch ---
--- 2.7257206439971924 seconds for one epoch ---
--- 0.3332381248474121 seconds for one epoch ---
--- 2.7883713245391846 seconds for one epoch ---
--- 0.3180115222930908 seconds for one epoch ---
--- 2.7050845623016357 seconds for one epoch ---
--- 0.3278203010559082 seconds for one epoch ---
--- 2.7719578742980957 seconds for one epoch ---
--- 0.3220052719116211 seconds for one epoch ---
--- 2.723604917526245 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99910724]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.80105]
 [ -0.     ]]
--- 0.2961585521697998 seconds for one epoch ---
Epoch 5500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2305.377197265625, (1053.1041, 2.7015047, 1249.1364, 0.43534413)
   validation loss 841.79541015625, (602.8339, 1.1529477, 237.37318, 0.43534413)
decoder loss ratio: 23354.832756, decoder SINDy loss  ratio: 0.512403
THRESHOLDING: 1 active coefficients
--- 2.751857280731201 seconds for one epoch ---
--- 0.3347289562225342 seconds for one epoch ---
--- 2.7354202270507812 seconds for one epoch ---
--- 0.3358590602874756 seconds for one epoch ---
--- 2.730276346206665 seconds for one epoch ---
--- 0.313626766204834 seconds for one epoch ---
--- 2.770108461380005 seconds for one epoch ---
--- 0.3094809055328369 seconds for one epoch ---
--- 2.7735159397125244 seconds for one epoch ---
--- 0.32533955574035645 seconds for one epoch ---
--- 2.7494258880615234 seconds for one epoch ---
--- 0.3237612247467041 seconds for one epoch ---
--- 2.795764684677124 seconds for one epoch ---
--- 0.3018362522125244 seconds for one epoch ---
--- 2.779082775115967 seconds for one epoch ---
--- 0.3338761329650879 seconds for one epoch ---
--- 2.7189533710479736 seconds for one epoch ---
--- 0.28782224655151367 seconds for one epoch ---
--- 2.739994764328003 seconds for one epoch ---
--- 0.30998754501342773 seconds for one epoch ---
--- 2.731389284133911 seconds for one epoch ---
--- 0.3170511722564697 seconds for one epoch ---
--- 2.7872262001037598 seconds for one epoch ---
--- 0.33404040336608887 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99910814]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.80378]
 [ -0.     ]]
--- 0.26402711868286133 seconds for one epoch ---
Epoch 5525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2479.677490234375, (1025.6055, 1.4520421, 1452.1846, 0.43537068)
   validation loss 793.0993041992188, (553.5713, 1.1482853, 237.9443, 0.43537068)
decoder loss ratio: 21446.312780, decoder SINDy loss  ratio: 0.513636
--- 0.3122091293334961 seconds for one epoch ---
--- 2.749642848968506 seconds for one epoch ---
--- 0.3292717933654785 seconds for one epoch ---
--- 2.79093599319458 seconds for one epoch ---
--- 0.3279459476470947 seconds for one epoch ---
--- 2.781191110610962 seconds for one epoch ---
--- 0.3272674083709717 seconds for one epoch ---
--- 2.7852835655212402 seconds for one epoch ---
--- 0.3268439769744873 seconds for one epoch ---
--- 2.7290210723876953 seconds for one epoch ---
--- 0.3278195858001709 seconds for one epoch ---
--- 2.788712739944458 seconds for one epoch ---
--- 0.31368374824523926 seconds for one epoch ---
--- 2.7396202087402344 seconds for one epoch ---
--- 0.3177027702331543 seconds for one epoch ---
--- 2.794964075088501 seconds for one epoch ---
--- 0.32233190536499023 seconds for one epoch ---
--- 2.792067527770996 seconds for one epoch ---
--- 0.3314394950866699 seconds for one epoch ---
--- 2.7566604614257812 seconds for one epoch ---
--- 0.329744815826416 seconds for one epoch ---
--- 2.8055131435394287 seconds for one epoch ---
--- 0.3256657123565674 seconds for one epoch ---
--- 2.801074743270874 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99910915]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.809904]
 [  0.      ]]
--- 0.30311012268066406 seconds for one epoch ---
Epoch 5550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3340.2734375, (1459.506, 0.78051364, 1879.5515, 0.43556592)
   validation loss 812.9263305664062, (556.55585, 1.111621, 254.82329, 0.43556592)
decoder loss ratio: 21561.939743, decoder SINDy loss  ratio: 0.550072
--- 0.2771179676055908 seconds for one epoch ---
--- 0.3235628604888916 seconds for one epoch ---
--- 2.8197779655456543 seconds for one epoch ---
--- 0.3379840850830078 seconds for one epoch ---
--- 2.7431652545928955 seconds for one epoch ---
--- 0.32230615615844727 seconds for one epoch ---
--- 2.753688097000122 seconds for one epoch ---
--- 0.32146143913269043 seconds for one epoch ---
--- 2.8116683959960938 seconds for one epoch ---
--- 0.3126640319824219 seconds for one epoch ---
--- 2.7915353775024414 seconds for one epoch ---
--- 0.31548404693603516 seconds for one epoch ---
--- 2.8033535480499268 seconds for one epoch ---
--- 0.31695985794067383 seconds for one epoch ---
--- 2.7883658409118652 seconds for one epoch ---
--- 0.3215973377227783 seconds for one epoch ---
--- 2.752939462661743 seconds for one epoch ---
--- 0.3253800868988037 seconds for one epoch ---
--- 2.813760280609131 seconds for one epoch ---
--- 0.3224947452545166 seconds for one epoch ---
--- 2.793440580368042 seconds for one epoch ---
--- 0.33176612854003906 seconds for one epoch ---
--- 2.8177871704101562 seconds for one epoch ---
--- 0.32177138328552246 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991102]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.81346]
 [ -0.     ]]
--- 0.27248430252075195 seconds for one epoch ---
Epoch 5575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2433.83251953125, (751.9537, 1.2230322, 1680.2203, 0.43555775)
   validation loss 1245.4775390625, (992.93695, 1.1333301, 250.9718, 0.43555775)
decoder loss ratio: 38468.101284, decoder SINDy loss  ratio: 0.541758
--- 0.2972893714904785 seconds for one epoch ---
--- 2.74977707862854 seconds for one epoch ---
--- 0.3112053871154785 seconds for one epoch ---
--- 2.7660534381866455 seconds for one epoch ---
--- 0.3197669982910156 seconds for one epoch ---
--- 2.7498557567596436 seconds for one epoch ---
--- 0.32721757888793945 seconds for one epoch ---
--- 2.8029279708862305 seconds for one epoch ---
--- 0.3249673843383789 seconds for one epoch ---
--- 2.805826187133789 seconds for one epoch ---
--- 0.3226478099822998 seconds for one epoch ---
--- 2.819143295288086 seconds for one epoch ---
--- 0.31574058532714844 seconds for one epoch ---
--- 2.809098243713379 seconds for one epoch ---
--- 0.3205759525299072 seconds for one epoch ---
--- 2.7745728492736816 seconds for one epoch ---
--- 0.3276641368865967 seconds for one epoch ---
--- 2.766373872756958 seconds for one epoch ---
--- 0.31555628776550293 seconds for one epoch ---
--- 2.779355764389038 seconds for one epoch ---
--- 0.3086726665496826 seconds for one epoch ---
--- 2.834035873413086 seconds for one epoch ---
--- 0.3181471824645996 seconds for one epoch ---
--- 2.814467191696167 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99911124]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.817314]
 [  0.      ]]
--- 0.29501771926879883 seconds for one epoch ---
Epoch 5600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3942.140869140625, (1985.0184, 0.8979024, 1955.7888, 0.43572244)
   validation loss 908.9763793945312, (663.2802, 1.0628803, 244.1976, 0.43572244)
decoder loss ratio: 25696.626934, decoder SINDy loss  ratio: 0.527135
--- 0.28176355361938477 seconds for one epoch ---
--- 0.313190221786499 seconds for one epoch ---
--- 2.7564151287078857 seconds for one epoch ---
--- 0.32207250595092773 seconds for one epoch ---
--- 2.8385210037231445 seconds for one epoch ---
--- 0.3116788864135742 seconds for one epoch ---
--- 2.770963668823242 seconds for one epoch ---
--- 0.31598329544067383 seconds for one epoch ---
--- 2.844348192214966 seconds for one epoch ---
--- 0.33068323135375977 seconds for one epoch ---
--- 2.7690513134002686 seconds for one epoch ---
--- 0.3218393325805664 seconds for one epoch ---
--- 2.8382363319396973 seconds for one epoch ---
--- 0.32865118980407715 seconds for one epoch ---
--- 2.8425278663635254 seconds for one epoch ---
--- 0.32033276557922363 seconds for one epoch ---
--- 2.84513521194458 seconds for one epoch ---
--- 0.32465672492980957 seconds for one epoch ---
--- 2.7963826656341553 seconds for one epoch ---
--- 0.32145023345947266 seconds for one epoch ---
--- 2.844773292541504 seconds for one epoch ---
--- 0.33155298233032227 seconds for one epoch ---
--- 2.8239927291870117 seconds for one epoch ---
--- 0.32951879501342773 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991119]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.821299]
 [ -0.      ]]
--- 0.27284979820251465 seconds for one epoch ---
Epoch 5625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2318.020751953125, (957.5857, 1.0821402, 1358.9171, 0.43586406)
   validation loss 772.4408569335938, (531.3972, 1.0850047, 239.52278, 0.43586406)
decoder loss ratio: 20587.250725, decoder SINDy loss  ratio: 0.517044
--- 0.3038644790649414 seconds for one epoch ---
--- 2.8016598224639893 seconds for one epoch ---
--- 0.3316798210144043 seconds for one epoch ---
--- 2.856769323348999 seconds for one epoch ---
--- 0.33466529846191406 seconds for one epoch ---
--- 2.8627395629882812 seconds for one epoch ---
--- 0.33824849128723145 seconds for one epoch ---
--- 2.823338270187378 seconds for one epoch ---
--- 0.3280608654022217 seconds for one epoch ---
--- 2.807464122772217 seconds for one epoch ---
--- 0.3196280002593994 seconds for one epoch ---
--- 2.84922194480896 seconds for one epoch ---
--- 0.3235154151916504 seconds for one epoch ---
--- 2.798151731491089 seconds for one epoch ---
--- 0.3259012699127197 seconds for one epoch ---
--- 2.842299461364746 seconds for one epoch ---
--- 0.32062840461730957 seconds for one epoch ---
--- 2.8366611003875732 seconds for one epoch ---
--- 0.3244616985321045 seconds for one epoch ---
--- 2.784672498703003 seconds for one epoch ---
--- 0.3268764019012451 seconds for one epoch ---
--- 2.843280792236328 seconds for one epoch ---
--- 0.31302404403686523 seconds for one epoch ---
--- 2.810120105743408 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99911344]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.826626]
 [  0.      ]]
--- 0.3009529113769531 seconds for one epoch ---
Epoch 5650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2367.18212890625, (938.9741, 4.31566, 1423.4563, 0.43594986)
   validation loss 755.70166015625, (513.7811, 1.1143179, 240.37025, 0.43594986)
decoder loss ratio: 19904.772859, decoder SINDy loss  ratio: 0.518873
--- 0.271773099899292 seconds for one epoch ---
--- 0.32947301864624023 seconds for one epoch ---
--- 2.843040943145752 seconds for one epoch ---
--- 0.3258821964263916 seconds for one epoch ---
--- 2.8323581218719482 seconds for one epoch ---
--- 0.33290553092956543 seconds for one epoch ---
--- 2.849269151687622 seconds for one epoch ---
--- 0.32564711570739746 seconds for one epoch ---
--- 2.790968894958496 seconds for one epoch ---
--- 0.3297090530395508 seconds for one epoch ---
--- 2.8304598331451416 seconds for one epoch ---
--- 0.327070951461792 seconds for one epoch ---
--- 2.864435911178589 seconds for one epoch ---
--- 0.33319664001464844 seconds for one epoch ---
--- 2.8336939811706543 seconds for one epoch ---
--- 0.32352232933044434 seconds for one epoch ---
--- 2.795137643814087 seconds for one epoch ---
--- 0.3217437267303467 seconds for one epoch ---
--- 2.874281644821167 seconds for one epoch ---
--- 0.32260894775390625 seconds for one epoch ---
--- 2.8122973442077637 seconds for one epoch ---
--- 0.3203909397125244 seconds for one epoch ---
--- 2.8682472705841064 seconds for one epoch ---
--- 0.3286619186401367 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99911505]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.830235]
 [  0.      ]]
--- 0.2597160339355469 seconds for one epoch ---
Epoch 5675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3058.69677734375, (1156.7223, 1.4506062, 1900.088, 0.4360405)
   validation loss 782.6050415039062, (544.5284, 1.1123252, 236.52834, 0.4360405)
decoder loss ratio: 21095.974836, decoder SINDy loss  ratio: 0.510580
--- 0.3132352828979492 seconds for one epoch ---
--- 2.815920829772949 seconds for one epoch ---
--- 0.3321659564971924 seconds for one epoch ---
--- 2.8671133518218994 seconds for one epoch ---
--- 0.3211064338684082 seconds for one epoch ---
--- 2.86460280418396 seconds for one epoch ---
--- 0.33055853843688965 seconds for one epoch ---
--- 2.837456464767456 seconds for one epoch ---
--- 0.31917357444763184 seconds for one epoch ---
--- 2.884875535964966 seconds for one epoch ---
--- 0.3226139545440674 seconds for one epoch ---
--- 2.8246235847473145 seconds for one epoch ---
--- 0.3268871307373047 seconds for one epoch ---
--- 2.883211135864258 seconds for one epoch ---
--- 0.3207271099090576 seconds for one epoch ---
--- 2.8532185554504395 seconds for one epoch ---
--- 0.3188812732696533 seconds for one epoch ---
--- 2.864877700805664 seconds for one epoch ---
--- 0.32761716842651367 seconds for one epoch ---
--- 2.8051908016204834 seconds for one epoch ---
--- 0.32363009452819824 seconds for one epoch ---
--- 2.8684091567993164 seconds for one epoch ---
--- 0.3271310329437256 seconds for one epoch ---
--- 2.833552598953247 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991168]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.835321]
 [ -0.      ]]
--- 0.30284643173217773 seconds for one epoch ---
Epoch 5700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2366.378662109375, (880.32043, 1.2286081, 1484.3933, 0.43618122)
   validation loss 807.0460205078125, (562.89246, 1.0900084, 242.62741, 0.43618122)
decoder loss ratio: 21807.430972, decoder SINDy loss  ratio: 0.523745
--- 0.2774040699005127 seconds for one epoch ---
--- 0.3253054618835449 seconds for one epoch ---
--- 2.8851609230041504 seconds for one epoch ---
--- 0.312091588973999 seconds for one epoch ---
--- 2.868225336074829 seconds for one epoch ---
--- 0.3234999179840088 seconds for one epoch ---
--- 2.813549518585205 seconds for one epoch ---
--- 0.3283252716064453 seconds for one epoch ---
--- 2.8393003940582275 seconds for one epoch ---
--- 0.32610440254211426 seconds for one epoch ---
--- 2.8502535820007324 seconds for one epoch ---
--- 0.32216858863830566 seconds for one epoch ---
--- 2.831427574157715 seconds for one epoch ---
--- 0.3143315315246582 seconds for one epoch ---
--- 2.8216171264648438 seconds for one epoch ---
--- 0.3130640983581543 seconds for one epoch ---
--- 2.8149733543395996 seconds for one epoch ---
--- 0.30762720108032227 seconds for one epoch ---
--- 2.887316942214966 seconds for one epoch ---
--- 0.32865381240844727 seconds for one epoch ---
--- 2.8335487842559814 seconds for one epoch ---
--- 0.3197746276855469 seconds for one epoch ---
--- 2.8793914318084717 seconds for one epoch ---
--- 0.3281123638153076 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991181]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.838179]
 [  0.      ]]
--- 0.2701287269592285 seconds for one epoch ---
Epoch 5725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2214.27001953125, (733.9116, 4.040793, 1475.8813, 0.43621427)
   validation loss 792.1529541015625, (553.7131, 1.1254317, 236.87822, 0.43621427)
decoder loss ratio: 21451.805764, decoder SINDy loss  ratio: 0.511335
--- 0.31407737731933594 seconds for one epoch ---
--- 2.838223695755005 seconds for one epoch ---
--- 0.3086833953857422 seconds for one epoch ---
--- 2.8953027725219727 seconds for one epoch ---
--- 0.31551432609558105 seconds for one epoch ---
--- 2.819044351577759 seconds for one epoch ---
--- 0.32851433753967285 seconds for one epoch ---
--- 2.82940673828125 seconds for one epoch ---
--- 0.31778883934020996 seconds for one epoch ---
--- 2.836400270462036 seconds for one epoch ---
--- 0.33094000816345215 seconds for one epoch ---
--- 2.830404758453369 seconds for one epoch ---
--- 0.3242313861846924 seconds for one epoch ---
--- 2.84133243560791 seconds for one epoch ---
--- 0.3048436641693115 seconds for one epoch ---
--- 2.901033878326416 seconds for one epoch ---
--- 0.33254551887512207 seconds for one epoch ---
--- 2.8894293308258057 seconds for one epoch ---
--- 0.31436681747436523 seconds for one epoch ---
--- 2.824549436569214 seconds for one epoch ---
--- 0.32248926162719727 seconds for one epoch ---
--- 2.8870747089385986 seconds for one epoch ---
--- 0.3234570026397705 seconds for one epoch ---
--- 2.818662643432617 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991181]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.840551]
 [ -0.      ]]
--- 0.30869626998901367 seconds for one epoch ---
Epoch 5750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2674.344970703125, (1087.7598, 0.5128026, 1585.6361, 0.4362936)
   validation loss 800.2308349609375, (557.37494, 1.111147, 241.30846, 0.4362936)
decoder loss ratio: 21593.672781, decoder SINDy loss  ratio: 0.520898
--- 0.27942585945129395 seconds for one epoch ---
--- 0.3175389766693115 seconds for one epoch ---
--- 2.805603504180908 seconds for one epoch ---
--- 0.3096616268157959 seconds for one epoch ---
--- 2.8551278114318848 seconds for one epoch ---
--- 0.3211393356323242 seconds for one epoch ---
--- 2.9048752784729004 seconds for one epoch ---
--- 0.31422924995422363 seconds for one epoch ---
--- 2.8416309356689453 seconds for one epoch ---
--- 0.31977200508117676 seconds for one epoch ---
--- 2.863868236541748 seconds for one epoch ---
--- 0.325761079788208 seconds for one epoch ---
--- 2.877547264099121 seconds for one epoch ---
--- 0.30583906173706055 seconds for one epoch ---
--- 2.845979928970337 seconds for one epoch ---
--- 0.31828904151916504 seconds for one epoch ---
--- 2.8425369262695312 seconds for one epoch ---
--- 0.331470251083374 seconds for one epoch ---
--- 2.889493465423584 seconds for one epoch ---
--- 0.31593847274780273 seconds for one epoch ---
--- 2.8696224689483643 seconds for one epoch ---
--- 0.3167414665222168 seconds for one epoch ---
--- 2.9185032844543457 seconds for one epoch ---
--- 0.31659674644470215 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991196]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.84831]
 [ -0.     ]]
--- 0.26558709144592285 seconds for one epoch ---
Epoch 5775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1950.031005859375, (779.9709, 3.0872936, 1166.5363, 0.43648598)
   validation loss 752.0861206054688, (514.51196, 1.1125, 236.02518, 0.43648598)
decoder loss ratio: 19933.086674, decoder SINDy loss  ratio: 0.509494
--- 0.30391931533813477 seconds for one epoch ---
--- 2.8779101371765137 seconds for one epoch ---
--- 0.3307182788848877 seconds for one epoch ---
--- 2.821166515350342 seconds for one epoch ---
--- 0.32002806663513184 seconds for one epoch ---
--- 2.9292585849761963 seconds for one epoch ---
--- 0.3301689624786377 seconds for one epoch ---
--- 2.845069408416748 seconds for one epoch ---
--- 0.3183298110961914 seconds for one epoch ---
--- 2.908123016357422 seconds for one epoch ---
--- 0.3241691589355469 seconds for one epoch ---
--- 2.8905751705169678 seconds for one epoch ---
--- 0.3172945976257324 seconds for one epoch ---
--- 2.853135108947754 seconds for one epoch ---
--- 0.32811832427978516 seconds for one epoch ---
--- 2.9322893619537354 seconds for one epoch ---
--- 0.3242502212524414 seconds for one epoch ---
--- 2.873317003250122 seconds for one epoch ---
--- 0.32680678367614746 seconds for one epoch ---
--- 2.916935920715332 seconds for one epoch ---
--- 0.325420618057251 seconds for one epoch ---
--- 2.9263529777526855 seconds for one epoch ---
--- 0.3108334541320801 seconds for one epoch ---
--- 2.9099364280700684 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991204]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.851702]
 [  0.      ]]
--- 0.30347108840942383 seconds for one epoch ---
Epoch 5800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2995.64501953125, (1224.9711, 0.97904956, 1769.2585, 0.43656245)
   validation loss 784.824951171875, (547.0824, 1.1370548, 236.16888, 0.43656245)
decoder loss ratio: 21194.921854, decoder SINDy loss  ratio: 0.509804
--- 0.26431822776794434 seconds for one epoch ---
--- 0.3279705047607422 seconds for one epoch ---
--- 2.8692593574523926 seconds for one epoch ---
--- 0.3187899589538574 seconds for one epoch ---
--- 2.835082769393921 seconds for one epoch ---
--- 0.3276963233947754 seconds for one epoch ---
--- 2.8734354972839355 seconds for one epoch ---
--- 0.31244826316833496 seconds for one epoch ---
--- 2.9261622428894043 seconds for one epoch ---
--- 0.3274047374725342 seconds for one epoch ---
--- 2.8775360584259033 seconds for one epoch ---
--- 0.31471729278564453 seconds for one epoch ---
--- 2.8555305004119873 seconds for one epoch ---
--- 0.3183777332305908 seconds for one epoch ---
--- 2.926988124847412 seconds for one epoch ---
--- 0.31353259086608887 seconds for one epoch ---
--- 2.8914804458618164 seconds for one epoch ---
--- 0.3174440860748291 seconds for one epoch ---
--- 2.87607741355896 seconds for one epoch ---
--- 0.3197612762451172 seconds for one epoch ---
--- 2.8995518684387207 seconds for one epoch ---
--- 0.3219614028930664 seconds for one epoch ---
--- 2.939227819442749 seconds for one epoch ---
--- 0.32117700576782227 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991212]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.854605]
 [  0.      ]]
--- 0.26404595375061035 seconds for one epoch ---
Epoch 5825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2699.77880859375, (1436.8562, 0.6593839, 1261.8268, 0.4366231)
   validation loss 808.65576171875, (566.2632, 1.098364, 240.85757, 0.4366231)
decoder loss ratio: 21938.018809, decoder SINDy loss  ratio: 0.519925
--- 0.31966567039489746 seconds for one epoch ---
--- 2.9311108589172363 seconds for one epoch ---
--- 0.32340240478515625 seconds for one epoch ---
--- 2.899014949798584 seconds for one epoch ---
--- 0.3038971424102783 seconds for one epoch ---
--- 2.864363670349121 seconds for one epoch ---
--- 0.3257279396057129 seconds for one epoch ---
--- 2.9512293338775635 seconds for one epoch ---
--- 0.3190739154815674 seconds for one epoch ---
--- 2.939166307449341 seconds for one epoch ---
--- 0.32089877128601074 seconds for one epoch ---
--- 2.8929026126861572 seconds for one epoch ---
--- 0.324446439743042 seconds for one epoch ---
--- 2.928398370742798 seconds for one epoch ---
--- 0.33034682273864746 seconds for one epoch ---
--- 2.940225839614868 seconds for one epoch ---
--- 0.3178713321685791 seconds for one epoch ---
--- 2.9440653324127197 seconds for one epoch ---
--- 0.31751298904418945 seconds for one epoch ---
--- 2.9070959091186523 seconds for one epoch ---
--- 0.32184457778930664 seconds for one epoch ---
--- 2.9006619453430176 seconds for one epoch ---
--- 0.31511521339416504 seconds for one epoch ---
--- 2.8857462406158447 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99912304]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.860683]
 [ -0.      ]]
--- 0.2955343723297119 seconds for one epoch ---
Epoch 5850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3206.355712890625, (1472.2645, 0.7477293, 1732.9066, 0.43676263)
   validation loss 737.759765625, (488.89764, 1.0727692, 247.3526, 0.43676263)
decoder loss ratio: 18940.743494, decoder SINDy loss  ratio: 0.533945
--- 0.26203131675720215 seconds for one epoch ---
--- 0.3231954574584961 seconds for one epoch ---
--- 2.893096446990967 seconds for one epoch ---
--- 0.3147459030151367 seconds for one epoch ---
--- 2.9485976696014404 seconds for one epoch ---
--- 0.3258242607116699 seconds for one epoch ---
--- 2.910989999771118 seconds for one epoch ---
--- 0.31986141204833984 seconds for one epoch ---
--- 2.8722245693206787 seconds for one epoch ---
--- 0.3300919532775879 seconds for one epoch ---
--- 2.9279603958129883 seconds for one epoch ---
--- 0.2907702922821045 seconds for one epoch ---
--- 2.941763162612915 seconds for one epoch ---
--- 0.3215968608856201 seconds for one epoch ---
--- 2.926793336868286 seconds for one epoch ---
--- 0.31594324111938477 seconds for one epoch ---
--- 2.928205966949463 seconds for one epoch ---
--- 0.32330775260925293 seconds for one epoch ---
--- 2.918048858642578 seconds for one epoch ---
--- 0.31371045112609863 seconds for one epoch ---
--- 2.8892626762390137 seconds for one epoch ---
--- 0.31743955612182617 seconds for one epoch ---
--- 2.941260814666748 seconds for one epoch ---
--- 0.31282949447631836 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99912333]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.862658]
 [ -0.      ]]
--- 0.26949214935302734 seconds for one epoch ---
Epoch 5875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2558.419677734375, (1342.6843, 1.785864, 1213.5127, 0.4368518)
   validation loss 827.6066284179688, (585.0933, 1.1382093, 240.9383, 0.4368518)
decoder loss ratio: 22667.531090, decoder SINDy loss  ratio: 0.520099
--- 0.3133673667907715 seconds for one epoch ---
--- 2.924083709716797 seconds for one epoch ---
--- 0.3116614818572998 seconds for one epoch ---
--- 2.9408345222473145 seconds for one epoch ---
--- 0.32285547256469727 seconds for one epoch ---
--- 2.88128662109375 seconds for one epoch ---
--- 0.31336307525634766 seconds for one epoch ---
--- 2.9546196460723877 seconds for one epoch ---
--- 0.33101820945739746 seconds for one epoch ---
--- 2.9076173305511475 seconds for one epoch ---
--- 0.2917203903198242 seconds for one epoch ---
--- 2.943410873413086 seconds for one epoch ---
--- 0.33224940299987793 seconds for one epoch ---
--- 2.893986701965332 seconds for one epoch ---
--- 0.32500505447387695 seconds for one epoch ---
--- 2.8744730949401855 seconds for one epoch ---
--- 0.31069111824035645 seconds for one epoch ---
--- 2.9448866844177246 seconds for one epoch ---
--- 0.3101537227630615 seconds for one epoch ---
--- 2.963669776916504 seconds for one epoch ---
--- 0.39397120475769043 seconds for one epoch ---
--- 2.911726951599121 seconds for one epoch ---
--- 0.3221452236175537 seconds for one epoch ---
--- 2.941265106201172 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99912554]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.869627]
 [  0.      ]]
--- 0.2997920513153076 seconds for one epoch ---
Epoch 5900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2192.05419921875, (1003.60846, 1.2174478, 1186.7913, 0.43699765)
   validation loss 766.5880126953125, (528.041, 1.1574156, 236.9526, 0.43699765)
decoder loss ratio: 20457.225665, decoder SINDy loss  ratio: 0.511496
--- 0.27559638023376465 seconds for one epoch ---
--- 0.3286118507385254 seconds for one epoch ---
--- 2.9464950561523438 seconds for one epoch ---
--- 0.32662391662597656 seconds for one epoch ---
--- 2.9782629013061523 seconds for one epoch ---
--- 0.31510114669799805 seconds for one epoch ---
--- 2.991811513900757 seconds for one epoch ---
--- 0.3323938846588135 seconds for one epoch ---
--- 2.9298288822174072 seconds for one epoch ---
--- 0.3105196952819824 seconds for one epoch ---
--- 2.931861400604248 seconds for one epoch ---
--- 0.32159852981567383 seconds for one epoch ---
--- 2.98399019241333 seconds for one epoch ---
--- 0.31841468811035156 seconds for one epoch ---
--- 2.9685182571411133 seconds for one epoch ---
--- 0.32941293716430664 seconds for one epoch ---
--- 2.981126070022583 seconds for one epoch ---
--- 0.31795525550842285 seconds for one epoch ---
--- 2.9595067501068115 seconds for one epoch ---
--- 0.3280913829803467 seconds for one epoch ---
--- 2.9900081157684326 seconds for one epoch ---
--- 0.31104397773742676 seconds for one epoch ---
--- 3.0161876678466797 seconds for one epoch ---
--- 0.3125114440917969 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991267]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.872421]
 [ -0.      ]]
--- 0.2631707191467285 seconds for one epoch ---
Epoch 5925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5265.57275390625, (863.7241, 1.2109079, 4400.2007, 0.4370862)
   validation loss 907.9091186523438, (654.84393, 1.1654286, 251.46269, 0.4370862)
decoder loss ratio: 25369.790828, decoder SINDy loss  ratio: 0.542818
--- 0.31617307662963867 seconds for one epoch ---
--- 2.99967098236084 seconds for one epoch ---
--- 0.32753705978393555 seconds for one epoch ---
--- 2.915844678878784 seconds for one epoch ---
--- 0.3188779354095459 seconds for one epoch ---
--- 2.949596405029297 seconds for one epoch ---
--- 0.325620174407959 seconds for one epoch ---
--- 2.9343159198760986 seconds for one epoch ---
--- 0.32002830505371094 seconds for one epoch ---
--- 3.0029520988464355 seconds for one epoch ---
--- 0.3156876564025879 seconds for one epoch ---
--- 2.981189727783203 seconds for one epoch ---
--- 0.3088085651397705 seconds for one epoch ---
--- 2.9528183937072754 seconds for one epoch ---
--- 0.3312041759490967 seconds for one epoch ---
--- 2.955577850341797 seconds for one epoch ---
--- 0.33063554763793945 seconds for one epoch ---
--- 2.92718243598938 seconds for one epoch ---
--- 0.3272535800933838 seconds for one epoch ---
--- 2.9992918968200684 seconds for one epoch ---
--- 0.33104681968688965 seconds for one epoch ---
--- 3.0111265182495117 seconds for one epoch ---
--- 0.32380223274230957 seconds for one epoch ---
--- 2.9744691848754883 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99912703]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.871593]
 [  0.      ]]
--- 0.31699204444885254 seconds for one epoch ---
Epoch 5950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5105.95458984375, (1738.9799, 3.0867906, 3363.451, 0.43708393)
   validation loss 760.8890991210938, (516.3303, 1.1837616, 242.93791, 0.43708393)
decoder loss ratio: 20003.533073, decoder SINDy loss  ratio: 0.524416
--- 0.26818346977233887 seconds for one epoch ---
--- 0.3250100612640381 seconds for one epoch ---
--- 2.990647792816162 seconds for one epoch ---
--- 0.320420503616333 seconds for one epoch ---
--- 2.9944863319396973 seconds for one epoch ---
--- 0.3170762062072754 seconds for one epoch ---
--- 2.919167995452881 seconds for one epoch ---
--- 0.32010340690612793 seconds for one epoch ---
--- 2.9594833850860596 seconds for one epoch ---
--- 0.32821202278137207 seconds for one epoch ---
--- 2.960310935974121 seconds for one epoch ---
--- 0.3311653137207031 seconds for one epoch ---
--- 2.991056203842163 seconds for one epoch ---
--- 0.31957292556762695 seconds for one epoch ---
--- 2.954773426055908 seconds for one epoch ---
--- 0.3220865726470947 seconds for one epoch ---
--- 3.0149874687194824 seconds for one epoch ---
--- 0.3323204517364502 seconds for one epoch ---
--- 3.005484104156494 seconds for one epoch ---
--- 0.31002378463745117 seconds for one epoch ---
--- 2.998420476913452 seconds for one epoch ---
--- 0.32903504371643066 seconds for one epoch ---
--- 2.992487668991089 seconds for one epoch ---
--- 0.31934428215026855 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991274]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.87722]
 [ -0.     ]]
--- 0.2612271308898926 seconds for one epoch ---
Epoch 5975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3315.66064453125, (1921.3461, 0.41523182, 1393.462, 0.43719187)
   validation loss 744.4226684570312, (507.2134, 1.1529808, 235.61906, 0.43719187)
decoder loss ratio: 19650.328042, decoder SINDy loss  ratio: 0.508617
--- 0.3035166263580322 seconds for one epoch ---
--- 3.0176591873168945 seconds for one epoch ---
--- 0.3263068199157715 seconds for one epoch ---
--- 3.006077527999878 seconds for one epoch ---
--- 0.325580358505249 seconds for one epoch ---
--- 3.0187575817108154 seconds for one epoch ---
--- 0.3175332546234131 seconds for one epoch ---
--- 2.9492604732513428 seconds for one epoch ---
--- 0.32204413414001465 seconds for one epoch ---
--- 2.960543632507324 seconds for one epoch ---
--- 0.33170557022094727 seconds for one epoch ---
--- 3.024531841278076 seconds for one epoch ---
--- 0.3269772529602051 seconds for one epoch ---
--- 3.0097193717956543 seconds for one epoch ---
--- 0.3290534019470215 seconds for one epoch ---
--- 3.0186383724212646 seconds for one epoch ---
--- 0.31229209899902344 seconds for one epoch ---
--- 2.9971048831939697 seconds for one epoch ---
--- 0.3272590637207031 seconds for one epoch ---
--- 3.0419154167175293 seconds for one epoch ---
--- 0.30718135833740234 seconds for one epoch ---
--- 3.002504348754883 seconds for one epoch ---
--- 0.3144562244415283 seconds for one epoch ---
--- 2.9687206745147705 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999128]
 [0.      ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.882778]
 [  0.      ]]
--- 0.3102693557739258 seconds for one epoch ---
Epoch 6000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3159.782958984375, (1229.7762, 1.1463741, 1928.4232, 0.43734416)
   validation loss 778.7675170898438, (527.2502, 1.1855925, 249.8944, 0.43734416)
decoder loss ratio: 20426.587440, decoder SINDy loss  ratio: 0.539432
THRESHOLDING: 1 active coefficients
--- 0.25610947608947754 seconds for one epoch ---
--- 0.3321342468261719 seconds for one epoch ---
--- 2.9730727672576904 seconds for one epoch ---
--- 0.30017852783203125 seconds for one epoch ---
--- 3.0216898918151855 seconds for one epoch ---
--- 0.32229065895080566 seconds for one epoch ---
--- 3.0218560695648193 seconds for one epoch ---
--- 0.3082008361816406 seconds for one epoch ---
--- 2.9782605171203613 seconds for one epoch ---
--- 0.31679630279541016 seconds for one epoch ---
--- 3.0284605026245117 seconds for one epoch ---
--- 0.3160250186920166 seconds for one epoch ---
--- 3.020986557006836 seconds for one epoch ---
--- 0.32744741439819336 seconds for one epoch ---
--- 2.979029655456543 seconds for one epoch ---
--- 0.31874656677246094 seconds for one epoch ---
--- 2.9707748889923096 seconds for one epoch ---
--- 0.3260767459869385 seconds for one epoch ---
--- 3.0478298664093018 seconds for one epoch ---
--- 0.32811880111694336 seconds for one epoch ---
--- 3.0404770374298096 seconds for one epoch ---
--- 0.33855772018432617 seconds for one epoch ---
--- 2.979201316833496 seconds for one epoch ---
--- 0.3224985599517822 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99912786]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.884457]
 [  0.      ]]
--- 0.2687819004058838 seconds for one epoch ---
Epoch 6025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3670.205322265625, (1466.821, 0.7137538, 2202.2332, 0.43737337)
   validation loss 727.9262084960938, (485.10455, 1.1112634, 241.27301, 0.43737337)
decoder loss ratio: 18793.792570, decoder SINDy loss  ratio: 0.520822
--- 0.3148767948150635 seconds for one epoch ---
--- 3.007030963897705 seconds for one epoch ---
--- 0.3255014419555664 seconds for one epoch ---
--- 2.965695858001709 seconds for one epoch ---
--- 0.31793880462646484 seconds for one epoch ---
--- 3.0314929485321045 seconds for one epoch ---
--- 0.3154170513153076 seconds for one epoch ---
--- 2.9900286197662354 seconds for one epoch ---
--- 0.3284423351287842 seconds for one epoch ---
--- 3.048889398574829 seconds for one epoch ---
--- 0.3255140781402588 seconds for one epoch ---
--- 2.9797959327697754 seconds for one epoch ---
--- 0.32846975326538086 seconds for one epoch ---
--- 3.061234712600708 seconds for one epoch ---
--- 0.3273355960845947 seconds for one epoch ---
--- 2.98089599609375 seconds for one epoch ---
--- 0.3244915008544922 seconds for one epoch ---
--- 3.0579099655151367 seconds for one epoch ---
--- 0.31042051315307617 seconds for one epoch ---
--- 3.0535948276519775 seconds for one epoch ---
--- 0.3196878433227539 seconds for one epoch ---
--- 3.0701568126678467 seconds for one epoch ---
--- 0.32432126998901367 seconds for one epoch ---
--- 3.0489280223846436 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991281]
 [0.       ]]
[[ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.88642]
 [ -0.     ]]
--- 0.3017921447753906 seconds for one epoch ---
Epoch 6050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1634.80322265625, (673.1616, 1.0306059, 960.17365, 0.43743116)
   validation loss 743.7330932617188, (502.87372, 1.1497496, 239.27217, 0.43743116)
decoder loss ratio: 19482.200873, decoder SINDy loss  ratio: 0.516503
--- 0.2706596851348877 seconds for one epoch ---
--- 0.31140780448913574 seconds for one epoch ---
--- 3.0354456901550293 seconds for one epoch ---
--- 0.3290729522705078 seconds for one epoch ---
--- 3.0071792602539062 seconds for one epoch ---
--- 0.32880115509033203 seconds for one epoch ---
--- 3.060572624206543 seconds for one epoch ---
--- 0.33377504348754883 seconds for one epoch ---
--- 3.0584218502044678 seconds for one epoch ---
--- 0.32120442390441895 seconds for one epoch ---
--- 3.0641138553619385 seconds for one epoch ---
--- 0.3302435874938965 seconds for one epoch ---
--- 3.0520479679107666 seconds for one epoch ---
--- 0.33119964599609375 seconds for one epoch ---
--- 3.0275092124938965 seconds for one epoch ---
--- 0.3122110366821289 seconds for one epoch ---
--- 3.0690770149230957 seconds for one epoch ---
--- 0.30632472038269043 seconds for one epoch ---
--- 3.0612967014312744 seconds for one epoch ---
--- 0.3189225196838379 seconds for one epoch ---
--- 3.0589566230773926 seconds for one epoch ---
--- 0.329087495803833 seconds for one epoch ---
--- 3.082458019256592 seconds for one epoch ---
--- 0.3332092761993408 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99912906]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.889805]
 [  0.      ]]
--- 0.2710709571838379 seconds for one epoch ---
Epoch 6075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1916.619873046875, (1031.9171, 0.6762799, 883.5889, 0.43751404)
   validation loss 759.1338500976562, (521.95636, 1.127792, 235.61217, 0.43751404)
decoder loss ratio: 20221.495537, decoder SINDy loss  ratio: 0.508602
--- 0.2936375141143799 seconds for one epoch ---
--- 3.0741193294525146 seconds for one epoch ---
--- 0.3370497226715088 seconds for one epoch ---
--- 3.000767946243286 seconds for one epoch ---
--- 0.33136868476867676 seconds for one epoch ---
--- 3.024010181427002 seconds for one epoch ---
--- 0.32379674911499023 seconds for one epoch ---
--- 3.0823862552642822 seconds for one epoch ---
--- 0.32976508140563965 seconds for one epoch ---
--- 3.091524600982666 seconds for one epoch ---
--- 0.32134580612182617 seconds for one epoch ---
--- 3.0286097526550293 seconds for one epoch ---
--- 0.33078908920288086 seconds for one epoch ---
--- 3.0696728229522705 seconds for one epoch ---
--- 0.3341944217681885 seconds for one epoch ---
--- 3.0316975116729736 seconds for one epoch ---
--- 0.3345823287963867 seconds for one epoch ---
--- 3.06136417388916 seconds for one epoch ---
--- 0.32367801666259766 seconds for one epoch ---
--- 3.030723810195923 seconds for one epoch ---
--- 0.316148042678833 seconds for one epoch ---
--- 3.042262077331543 seconds for one epoch ---
--- 0.31495118141174316 seconds for one epoch ---
--- 3.1008596420288086 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991311]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.894594]
 [ -0.      ]]
--- 0.3011493682861328 seconds for one epoch ---
Epoch 6100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2140.79541015625, (1070.3988, 0.64505726, 1069.3141, 0.43760815)
   validation loss 710.3331298828125, (469.9104, 1.1297449, 238.8554, 0.43760815)
decoder loss ratio: 18205.144711, decoder SINDy loss  ratio: 0.515603
--- 0.27458834648132324 seconds for one epoch ---
--- 0.3238387107849121 seconds for one epoch ---
--- 3.075295925140381 seconds for one epoch ---
--- 0.311734676361084 seconds for one epoch ---
--- 3.02207088470459 seconds for one epoch ---
--- 0.31353211402893066 seconds for one epoch ---
--- 3.0145649909973145 seconds for one epoch ---
--- 0.31957411766052246 seconds for one epoch ---
--- 3.066091775894165 seconds for one epoch ---
--- 0.3214907646179199 seconds for one epoch ---
--- 3.0872724056243896 seconds for one epoch ---
--- 0.32009124755859375 seconds for one epoch ---
--- 3.04886794090271 seconds for one epoch ---
--- 0.32546281814575195 seconds for one epoch ---
--- 3.082858085632324 seconds for one epoch ---
--- 0.3234543800354004 seconds for one epoch ---
--- 3.037761926651001 seconds for one epoch ---
--- 0.331279993057251 seconds for one epoch ---
--- 3.0898895263671875 seconds for one epoch ---
--- 0.32616400718688965 seconds for one epoch ---
--- 3.0730509757995605 seconds for one epoch ---
--- 0.325603723526001 seconds for one epoch ---
--- 3.098905086517334 seconds for one epoch ---
--- 0.31671929359436035 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991332]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.898806]
 [ -0.      ]]
--- 0.26587367057800293 seconds for one epoch ---
Epoch 6125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2264.156005859375, (1064.1525, 0.7483088, 1198.8175, 0.43774715)
   validation loss 951.7908935546875, (689.15295, 1.0832143, 261.117, 0.43774715)
decoder loss ratio: 26698.981864, decoder SINDy loss  ratio: 0.563658
--- 0.3160383701324463 seconds for one epoch ---
--- 3.1200778484344482 seconds for one epoch ---
--- 0.3325819969177246 seconds for one epoch ---
--- 3.0927062034606934 seconds for one epoch ---
--- 0.32753992080688477 seconds for one epoch ---
--- 3.0741961002349854 seconds for one epoch ---
--- 0.33325672149658203 seconds for one epoch ---
--- 3.025582790374756 seconds for one epoch ---
--- 0.3237636089324951 seconds for one epoch ---
--- 3.0711193084716797 seconds for one epoch ---
--- 0.3203902244567871 seconds for one epoch ---
--- 3.0204577445983887 seconds for one epoch ---
--- 0.3211519718170166 seconds for one epoch ---
--- 3.089547634124756 seconds for one epoch ---
--- 0.3218271732330322 seconds for one epoch ---
--- 3.104625701904297 seconds for one epoch ---
--- 0.33107733726501465 seconds for one epoch ---
--- 3.087595224380493 seconds for one epoch ---
--- 0.3276636600494385 seconds for one epoch ---
--- 3.045464515686035 seconds for one epoch ---
--- 0.29888343811035156 seconds for one epoch ---
--- 3.1014912128448486 seconds for one epoch ---
--- 0.3163583278656006 seconds for one epoch ---
--- 3.0697295665740967 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991338]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.900295]
 [  0.      ]]
--- 0.31544065475463867 seconds for one epoch ---
Epoch 6150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2496.29833984375, (986.2477, 0.5821203, 1509.0308, 0.4377512)
   validation loss 739.4779052734375, (498.9605, 1.1019202, 238.97774, 0.4377512)
decoder loss ratio: 19330.596401, decoder SINDy loss  ratio: 0.515867
--- 0.2702009677886963 seconds for one epoch ---
--- 0.32248973846435547 seconds for one epoch ---
--- 3.109375476837158 seconds for one epoch ---
--- 0.3291187286376953 seconds for one epoch ---
--- 3.0763230323791504 seconds for one epoch ---
--- 0.32183003425598145 seconds for one epoch ---
--- 3.0976338386535645 seconds for one epoch ---
--- 0.3224985599517822 seconds for one epoch ---
--- 3.050438404083252 seconds for one epoch ---
--- 0.3166816234588623 seconds for one epoch ---
--- 3.100029230117798 seconds for one epoch ---
--- 0.3133096694946289 seconds for one epoch ---
--- 3.1277456283569336 seconds for one epoch ---
--- 0.32342958450317383 seconds for one epoch ---
--- 3.061598300933838 seconds for one epoch ---
--- 0.3246316909790039 seconds for one epoch ---
--- 3.1294538974761963 seconds for one epoch ---
--- 0.33008456230163574 seconds for one epoch ---
--- 3.1148324012756348 seconds for one epoch ---
--- 0.3307633399963379 seconds for one epoch ---
--- 3.107520341873169 seconds for one epoch ---
--- 0.3080897331237793 seconds for one epoch ---
--- 3.0902199745178223 seconds for one epoch ---
--- 0.32416820526123047 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991367]
 [0.       ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [-16.90665]
 [  0.     ]]
--- 0.2646048069000244 seconds for one epoch ---
Epoch 6175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2616.0537109375, (884.68176, 7.190691, 1723.7434, 0.43792358)
   validation loss 910.8307495117188, (658.2006, 1.1246015, 251.06764, 0.43792358)
decoder loss ratio: 25499.834804, decoder SINDy loss  ratio: 0.541965
--- 0.2872939109802246 seconds for one epoch ---
--- 3.0529062747955322 seconds for one epoch ---
--- 0.31057095527648926 seconds for one epoch ---
--- 3.0975472927093506 seconds for one epoch ---
--- 0.31869053840637207 seconds for one epoch ---
--- 3.078521728515625 seconds for one epoch ---
--- 0.32441163063049316 seconds for one epoch ---
--- 3.0546460151672363 seconds for one epoch ---
--- 0.31255149841308594 seconds for one epoch ---
--- 3.0526702404022217 seconds for one epoch ---
--- 0.32808589935302734 seconds for one epoch ---
--- 3.0314533710479736 seconds for one epoch ---
--- 0.31302571296691895 seconds for one epoch ---
--- 3.1096413135528564 seconds for one epoch ---
--- 0.32625389099121094 seconds for one epoch ---
--- 3.137455940246582 seconds for one epoch ---
--- 0.3101530075073242 seconds for one epoch ---
--- 3.0657284259796143 seconds for one epoch ---
--- 0.32425785064697266 seconds for one epoch ---
--- 3.1243302822113037 seconds for one epoch ---
--- 0.31473278999328613 seconds for one epoch ---
--- 3.114542245864868 seconds for one epoch ---
--- 0.33358216285705566 seconds for one epoch ---
--- 3.110079050064087 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99913794]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.908457]
 [ -0.      ]]
--- 0.30872273445129395 seconds for one epoch ---
Epoch 6200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2493.550537109375, (969.16235, 0.45287782, 1523.4973, 0.4379859)
   validation loss 732.7029418945312, (495.4391, 1.14807, 235.67781, 0.4379859)
decoder loss ratio: 19194.170347, decoder SINDy loss  ratio: 0.508744
--- 0.26064062118530273 seconds for one epoch ---
--- 0.3363363742828369 seconds for one epoch ---
--- 3.060347318649292 seconds for one epoch ---
--- 0.3207376003265381 seconds for one epoch ---
--- 3.080200433731079 seconds for one epoch ---
--- 0.3140292167663574 seconds for one epoch ---
--- 3.1237738132476807 seconds for one epoch ---
--- 0.309800386428833 seconds for one epoch ---
--- 3.065864086151123 seconds for one epoch ---
--- 0.3221125602722168 seconds for one epoch ---
--- 3.072909116744995 seconds for one epoch ---
--- 0.33220767974853516 seconds for one epoch ---
--- 3.0950748920440674 seconds for one epoch ---
--- 0.3286595344543457 seconds for one epoch ---
--- 3.0715909004211426 seconds for one epoch ---
--- 0.323775053024292 seconds for one epoch ---
--- 3.057558536529541 seconds for one epoch ---
--- 0.31941795349121094 seconds for one epoch ---
--- 3.0474188327789307 seconds for one epoch ---
--- 0.3116569519042969 seconds for one epoch ---
--- 3.100277900695801 seconds for one epoch ---
--- 0.3206770420074463 seconds for one epoch ---
--- 3.0610930919647217 seconds for one epoch ---
--- 0.3061342239379883 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991384]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.911089]
 [ -0.      ]]
--- 0.2668793201446533 seconds for one epoch ---
Epoch 6225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2937.301513671875, (969.33093, 1.5629556, 1965.9696, 0.43802834)
   validation loss 928.396484375, (691.2529, 1.136007, 235.56953, 0.43802834)
decoder loss ratio: 26780.338564, decoder SINDy loss  ratio: 0.508510
--- 0.31620192527770996 seconds for one epoch ---
--- 3.0669214725494385 seconds for one epoch ---
--- 0.33663034439086914 seconds for one epoch ---
--- 3.065157413482666 seconds for one epoch ---
--- 0.3262166976928711 seconds for one epoch ---
--- 3.0746357440948486 seconds for one epoch ---
--- 0.31700611114501953 seconds for one epoch ---
--- 3.125267267227173 seconds for one epoch ---
--- 0.3196859359741211 seconds for one epoch ---
--- 3.0530245304107666 seconds for one epoch ---
--- 0.33138012886047363 seconds for one epoch ---
--- 3.0688798427581787 seconds for one epoch ---
--- 0.32264137268066406 seconds for one epoch ---
--- 3.0989015102386475 seconds for one epoch ---
--- 0.31573939323425293 seconds for one epoch ---
--- 3.153700351715088 seconds for one epoch ---
--- 0.3192439079284668 seconds for one epoch ---
--- 3.1411569118499756 seconds for one epoch ---
--- 0.32705235481262207 seconds for one epoch ---
--- 3.10048508644104 seconds for one epoch ---
--- 0.3108220100402832 seconds for one epoch ---
--- 3.081733465194702 seconds for one epoch ---
--- 0.3203155994415283 seconds for one epoch ---
--- 3.0601096153259277 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99914014]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.91821]
 [  0.     ]]
--- 0.2895786762237549 seconds for one epoch ---
Epoch 6250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1536.2813720703125, (667.14166, 0.27935618, 868.4221, 0.43820795)
   validation loss 768.2471923828125, (526.6305, 1.1214395, 240.05698, 0.43820795)
decoder loss ratio: 20402.579576, decoder SINDy loss  ratio: 0.518197
--- 0.2756824493408203 seconds for one epoch ---
--- 0.32561159133911133 seconds for one epoch ---
--- 3.059851884841919 seconds for one epoch ---
--- 0.32775163650512695 seconds for one epoch ---
--- 3.1157066822052 seconds for one epoch ---
--- 0.32343626022338867 seconds for one epoch ---
--- 3.1352760791778564 seconds for one epoch ---
--- 0.32528018951416016 seconds for one epoch ---
--- 3.146044969558716 seconds for one epoch ---
--- 0.3139984607696533 seconds for one epoch ---
--- 3.138237714767456 seconds for one epoch ---
--- 0.3124661445617676 seconds for one epoch ---
--- 3.102519989013672 seconds for one epoch ---
--- 0.31950831413269043 seconds for one epoch ---
--- 3.105525016784668 seconds for one epoch ---
--- 0.32071399688720703 seconds for one epoch ---
--- 3.1563570499420166 seconds for one epoch ---
--- 0.3262293338775635 seconds for one epoch ---
--- 3.0933825969696045 seconds for one epoch ---
--- 0.32536888122558594 seconds for one epoch ---
--- 3.149359941482544 seconds for one epoch ---
--- 0.3197159767150879 seconds for one epoch ---
--- 3.162391424179077 seconds for one epoch ---
--- 0.3149693012237549 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991401]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.920269]
 [ -0.      ]]
--- 0.26648521423339844 seconds for one epoch ---
Epoch 6275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3224.500244140625, (1078.263, 0.93459177, 2144.8645, 0.43826628)
   validation loss 762.8177490234375, (516.63916, 1.1015326, 244.63875, 0.43826628)
decoder loss ratio: 20015.497989, decoder SINDy loss  ratio: 0.528087
--- 0.2989847660064697 seconds for one epoch ---
--- 3.0780320167541504 seconds for one epoch ---
--- 0.32978177070617676 seconds for one epoch ---
--- 3.092061758041382 seconds for one epoch ---
--- 0.3158841133117676 seconds for one epoch ---
--- 3.1231844425201416 seconds for one epoch ---
--- 0.3274984359741211 seconds for one epoch ---
--- 3.1530606746673584 seconds for one epoch ---
--- 0.32676124572753906 seconds for one epoch ---
--- 3.1056668758392334 seconds for one epoch ---
--- 0.3270258903503418 seconds for one epoch ---
--- 3.0812864303588867 seconds for one epoch ---
--- 0.30653977394104004 seconds for one epoch ---
--- 3.1126861572265625 seconds for one epoch ---
--- 0.32446742057800293 seconds for one epoch ---
--- 3.0956270694732666 seconds for one epoch ---
--- 0.3170928955078125 seconds for one epoch ---
--- 3.122549533843994 seconds for one epoch ---
--- 0.33528900146484375 seconds for one epoch ---
--- 3.0929057598114014 seconds for one epoch ---
--- 0.32067227363586426 seconds for one epoch ---
--- 3.126370429992676 seconds for one epoch ---
--- 0.31366515159606934 seconds for one epoch ---
--- 3.0695364475250244 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991413]
 [0.       ]]
[[ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [  0.    ]
 [  0.    ]
 [  0.    ]
 [-16.9252]
 [  0.    ]]
--- 0.2996070384979248 seconds for one epoch ---
Epoch 6300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5672.8779296875, (1660.9323, 4.82534, 4006.682, 0.4383981)
   validation loss 773.8059692382812, (529.7574, 1.1045933, 242.50557, 0.4383981)
decoder loss ratio: 20523.720804, decoder SINDy loss  ratio: 0.523482
--- 0.27161288261413574 seconds for one epoch ---
--- 0.3175835609436035 seconds for one epoch ---
--- 3.151423931121826 seconds for one epoch ---
--- 0.33838582038879395 seconds for one epoch ---
--- 3.097482204437256 seconds for one epoch ---
--- 0.3246726989746094 seconds for one epoch ---
--- 3.1504552364349365 seconds for one epoch ---
--- 0.8700363636016846 seconds for one epoch ---
--- 3.136261463165283 seconds for one epoch ---
--- 0.32856082916259766 seconds for one epoch ---
--- 3.150930166244507 seconds for one epoch ---
--- 0.32547712326049805 seconds for one epoch ---
--- 3.108759880065918 seconds for one epoch ---
--- 0.31705188751220703 seconds for one epoch ---
--- 3.1667277812957764 seconds for one epoch ---
--- 0.3195061683654785 seconds for one epoch ---
--- 3.1063108444213867 seconds for one epoch ---
--- 0.31560230255126953 seconds for one epoch ---
--- 3.1515347957611084 seconds for one epoch ---
--- 0.3256237506866455 seconds for one epoch ---
--- 3.111387252807617 seconds for one epoch ---
--- 0.3211343288421631 seconds for one epoch ---
--- 3.1807522773742676 seconds for one epoch ---
--- 0.3258376121520996 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991417]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.929235]
 [ -0.      ]]
--- 0.2756767272949219 seconds for one epoch ---
Epoch 6325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2614.03466796875, (1119.1912, 3.6488729, 1490.7561, 0.4384695)
   validation loss 717.9566650390625, (479.9661, 1.0916189, 236.46045, 0.4384695)
decoder loss ratio: 18594.719777, decoder SINDy loss  ratio: 0.510433
--- 0.2972538471221924 seconds for one epoch ---
--- 3.10807728767395 seconds for one epoch ---
--- 0.30184412002563477 seconds for one epoch ---
--- 3.14609432220459 seconds for one epoch ---
--- 0.3191821575164795 seconds for one epoch ---
--- 3.111299753189087 seconds for one epoch ---
--- 0.32273030281066895 seconds for one epoch ---
--- 3.13380765914917 seconds for one epoch ---
--- 0.3182375431060791 seconds for one epoch ---
--- 3.167128324508667 seconds for one epoch ---
--- 0.3271157741546631 seconds for one epoch ---
--- 3.1605489253997803 seconds for one epoch ---
--- 0.32637977600097656 seconds for one epoch ---
--- 3.1070804595947266 seconds for one epoch ---
--- 0.31705760955810547 seconds for one epoch ---
--- 3.1222445964813232 seconds for one epoch ---
--- 0.31700992584228516 seconds for one epoch ---
--- 3.115062713623047 seconds for one epoch ---
--- 0.30984926223754883 seconds for one epoch ---
--- 3.170175790786743 seconds for one epoch ---
--- 0.32605743408203125 seconds for one epoch ---
--- 3.147339344024658 seconds for one epoch ---
--- 0.3273799419403076 seconds for one epoch ---
--- 3.1159441471099854 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99914193]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.930157]
 [  0.      ]]
--- 0.3053405284881592 seconds for one epoch ---
Epoch 6350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2248.760009765625, (1336.5828, 0.5242959, 911.2144, 0.4385046)
   validation loss 778.2562866210938, (533.5242, 1.1100007, 243.18364, 0.4385046)
decoder loss ratio: 20669.652581, decoder SINDy loss  ratio: 0.524946
--- 0.2673153877258301 seconds for one epoch ---
--- 0.3230464458465576 seconds for one epoch ---
--- 3.1219067573547363 seconds for one epoch ---
--- 0.3264303207397461 seconds for one epoch ---
--- 3.120776891708374 seconds for one epoch ---
--- 0.31475019454956055 seconds for one epoch ---
--- 3.126190662384033 seconds for one epoch ---
--- 0.32628631591796875 seconds for one epoch ---
--- 3.1333320140838623 seconds for one epoch ---
--- 0.3246147632598877 seconds for one epoch ---
--- 3.197279691696167 seconds for one epoch ---
--- 0.30004405975341797 seconds for one epoch ---
--- 3.1955766677856445 seconds for one epoch ---
--- 0.31458282470703125 seconds for one epoch ---
--- 3.19040584564209 seconds for one epoch ---
--- 0.3265092372894287 seconds for one epoch ---
--- 3.122051239013672 seconds for one epoch ---
--- 0.32403087615966797 seconds for one epoch ---
--- 3.1990790367126465 seconds for one epoch ---
--- 0.32578206062316895 seconds for one epoch ---
--- 3.1413979530334473 seconds for one epoch ---
--- 0.32761430740356445 seconds for one epoch ---
--- 3.1434874534606934 seconds for one epoch ---
--- 0.32332372665405273 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991429]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.934044]
 [  0.      ]]
--- 0.2663614749908447 seconds for one epoch ---
Epoch 6375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2451.218994140625, (1278.2565, 0.87857974, 1171.6453, 0.43862286)
   validation loss 710.4237670898438, (474.0646, 1.1387049, 234.78186, 0.43862286)
decoder loss ratio: 18366.085838, decoder SINDy loss  ratio: 0.506810
--- 0.30292654037475586 seconds for one epoch ---
--- 3.1149039268493652 seconds for one epoch ---
--- 0.3305540084838867 seconds for one epoch ---
--- 3.1844136714935303 seconds for one epoch ---
--- 0.3224642276763916 seconds for one epoch ---
--- 3.205314874649048 seconds for one epoch ---
--- 0.3278064727783203 seconds for one epoch ---
--- 3.121814250946045 seconds for one epoch ---
--- 0.31703615188598633 seconds for one epoch ---
--- 3.171322822570801 seconds for one epoch ---
--- 0.3218996524810791 seconds for one epoch ---
--- 3.165006160736084 seconds for one epoch ---
--- 0.3267531394958496 seconds for one epoch ---
--- 3.218231678009033 seconds for one epoch ---
--- 0.31653428077697754 seconds for one epoch ---
--- 3.1345181465148926 seconds for one epoch ---
--- 0.3192112445831299 seconds for one epoch ---
--- 3.2121920585632324 seconds for one epoch ---
--- 0.3268139362335205 seconds for one epoch ---
--- 3.205756425857544 seconds for one epoch ---
--- 0.3218514919281006 seconds for one epoch ---
--- 3.14026141166687 seconds for one epoch ---
--- 0.32663655281066895 seconds for one epoch ---
--- 3.1551568508148193 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99914455]
 [0.        ]]
[[  0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-16.9384]
 [ -0.    ]]
--- 0.31592369079589844 seconds for one epoch ---
Epoch 6400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4222.5595703125, (2059.2666, 1.4514384, 2161.403, 0.43869707)
   validation loss 804.8707885742188, (558.5831, 1.1187291, 244.73022, 0.43869707)
decoder loss ratio: 21640.480195, decoder SINDy loss  ratio: 0.528285
--- 0.2647535800933838 seconds for one epoch ---
--- 0.31682276725769043 seconds for one epoch ---
--- 3.1405701637268066 seconds for one epoch ---
--- 0.32477831840515137 seconds for one epoch ---
--- 3.214155673980713 seconds for one epoch ---
--- 0.33015894889831543 seconds for one epoch ---
--- 3.1396968364715576 seconds for one epoch ---
--- 0.3229029178619385 seconds for one epoch ---
--- 3.2037479877471924 seconds for one epoch ---
--- 0.3197183609008789 seconds for one epoch ---
--- 3.14823317527771 seconds for one epoch ---
--- 0.32928466796875 seconds for one epoch ---
--- 3.1964962482452393 seconds for one epoch ---
--- 0.32461071014404297 seconds for one epoch ---
--- 3.1896679401397705 seconds for one epoch ---
--- 0.33437275886535645 seconds for one epoch ---
--- 3.1591005325317383 seconds for one epoch ---
--- 0.3286294937133789 seconds for one epoch ---
--- 3.2203433513641357 seconds for one epoch ---
--- 0.3224761486053467 seconds for one epoch ---
--- 3.210808753967285 seconds for one epoch ---
--- 0.3144540786743164 seconds for one epoch ---
--- 3.20579195022583 seconds for one epoch ---
--- 0.3114817142486572 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99914527]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.940615]
 [  0.      ]]
--- 0.256227970123291 seconds for one epoch ---
Epoch 6425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3816.117919921875, (1486.732, 3.2144713, 2325.7327, 0.43876415)
   validation loss 763.8882446289062, (528.0169, 1.1185509, 234.31401, 0.43876415)
decoder loss ratio: 20456.291645, decoder SINDy loss  ratio: 0.505800
--- 0.31058645248413086 seconds for one epoch ---
--- 3.1799654960632324 seconds for one epoch ---
--- 0.3269767761230469 seconds for one epoch ---
--- 3.1802613735198975 seconds for one epoch ---
--- 0.3212001323699951 seconds for one epoch ---
--- 3.240618944168091 seconds for one epoch ---
--- 0.31125903129577637 seconds for one epoch ---
--- 3.201775312423706 seconds for one epoch ---
--- 0.31906795501708984 seconds for one epoch ---
--- 3.169423818588257 seconds for one epoch ---
--- 0.3254866600036621 seconds for one epoch ---
--- 3.2137062549591064 seconds for one epoch ---
--- 0.32727980613708496 seconds for one epoch ---
--- 3.1720781326293945 seconds for one epoch ---
--- 0.3319203853607178 seconds for one epoch ---
--- 3.1763923168182373 seconds for one epoch ---
--- 0.3213951587677002 seconds for one epoch ---
--- 3.147677421569824 seconds for one epoch ---
--- 0.32079434394836426 seconds for one epoch ---
--- 3.233821153640747 seconds for one epoch ---
--- 0.2955935001373291 seconds for one epoch ---
--- 3.1808550357818604 seconds for one epoch ---
--- 0.334930419921875 seconds for one epoch ---
--- 3.2279622554779053 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991483]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.947348]
 [ -0.      ]]
--- 0.2983570098876953 seconds for one epoch ---
Epoch 6450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1702.1630859375, (914.3212, 0.86883485, 786.5342, 0.43889713)
   validation loss 767.4329833984375, (528.6271, 1.1511661, 237.21584, 0.43889713)
decoder loss ratio: 20479.930630, decoder SINDy loss  ratio: 0.512064
--- 0.26535511016845703 seconds for one epoch ---
--- 0.32670021057128906 seconds for one epoch ---
--- 3.1892497539520264 seconds for one epoch ---
--- 0.31806349754333496 seconds for one epoch ---
--- 3.1805410385131836 seconds for one epoch ---
--- 0.32012033462524414 seconds for one epoch ---
--- 3.2329635620117188 seconds for one epoch ---
--- 0.32591795921325684 seconds for one epoch ---
--- 3.176393508911133 seconds for one epoch ---
--- 0.3205740451812744 seconds for one epoch ---
--- 3.23104190826416 seconds for one epoch ---
--- 0.31587934494018555 seconds for one epoch ---
--- 3.1863014698028564 seconds for one epoch ---
--- 0.3320000171661377 seconds for one epoch ---
--- 3.217566728591919 seconds for one epoch ---
--- 0.34111976623535156 seconds for one epoch ---
--- 3.252102851867676 seconds for one epoch ---
--- 0.32766151428222656 seconds for one epoch ---
--- 3.193652629852295 seconds for one epoch ---
--- 0.3248612880706787 seconds for one epoch ---
--- 3.2089715003967285 seconds for one epoch ---
--- 0.3230602741241455 seconds for one epoch ---
--- 3.24499249458313 seconds for one epoch ---
--- 0.3276336193084717 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991493]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.950241]
 [ -0.      ]]
--- 0.24885344505310059 seconds for one epoch ---
Epoch 6475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2381.40087890625, (938.08594, 2.4244905, 1440.4515, 0.4389895)
   validation loss 781.4602661132812, (527.9111, 1.0971357, 252.01314, 0.4389895)
decoder loss ratio: 20452.191415, decoder SINDy loss  ratio: 0.544006
--- 0.30830883979797363 seconds for one epoch ---
--- 3.185088872909546 seconds for one epoch ---
--- 0.3256363868713379 seconds for one epoch ---
--- 3.16813325881958 seconds for one epoch ---
--- 0.3289000988006592 seconds for one epoch ---
--- 3.2443997859954834 seconds for one epoch ---
--- 0.3146390914916992 seconds for one epoch ---
--- 3.2429800033569336 seconds for one epoch ---
--- 0.31789374351501465 seconds for one epoch ---
--- 3.239678382873535 seconds for one epoch ---
--- 0.31783008575439453 seconds for one epoch ---
--- 3.187389612197876 seconds for one epoch ---
--- 0.3126087188720703 seconds for one epoch ---
--- 3.2031362056732178 seconds for one epoch ---
--- 0.32425856590270996 seconds for one epoch ---
--- 3.22853422164917 seconds for one epoch ---
--- 0.31757593154907227 seconds for one epoch ---
--- 3.191098690032959 seconds for one epoch ---
--- 0.3273584842681885 seconds for one epoch ---
--- 3.184260368347168 seconds for one epoch ---
--- 0.3136718273162842 seconds for one epoch ---
--- 3.247572898864746 seconds for one epoch ---
--- 0.3217630386352539 seconds for one epoch ---
--- 3.2553093433380127 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99915075]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.953415]
 [  0.      ]]
--- 0.29619503021240234 seconds for one epoch ---
Epoch 6500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4832.26416015625, (3044.156, 1.1188036, 1786.5505, 0.43906078)
   validation loss 919.8102416992188, (669.9287, 1.1122646, 248.3302, 0.43906078)
decoder loss ratio: 25954.201309, decoder SINDy loss  ratio: 0.536056
THRESHOLDING: 1 active coefficients
--- 3.1487152576446533 seconds for one epoch ---
--- 0.3266878128051758 seconds for one epoch ---
--- 3.1904711723327637 seconds for one epoch ---
--- 0.32073330879211426 seconds for one epoch ---
--- 3.255059003829956 seconds for one epoch ---
--- 0.3259580135345459 seconds for one epoch ---
--- 3.204395055770874 seconds for one epoch ---
--- 0.31684064865112305 seconds for one epoch ---
--- 3.24357533454895 seconds for one epoch ---
--- 0.31690001487731934 seconds for one epoch ---
--- 3.1751644611358643 seconds for one epoch ---
--- 0.3287625312805176 seconds for one epoch ---
--- 3.262704849243164 seconds for one epoch ---
--- 0.32517457008361816 seconds for one epoch ---
--- 3.2615017890930176 seconds for one epoch ---
--- 0.31443047523498535 seconds for one epoch ---
--- 3.235257148742676 seconds for one epoch ---
--- 0.3218672275543213 seconds for one epoch ---
--- 3.2714977264404297 seconds for one epoch ---
--- 0.33802103996276855 seconds for one epoch ---
--- 3.2523140907287598 seconds for one epoch ---
--- 0.3289947509765625 seconds for one epoch ---
--- 3.277890682220459 seconds for one epoch ---
--- 0.3336200714111328 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991513]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.956343]
 [  0.      ]]
--- 0.2743675708770752 seconds for one epoch ---
Epoch 6525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2202.546875, (1135.0436, 2.324735, 1064.7394, 0.4391391)
   validation loss 688.0350952148438, (449.37408, 1.1168575, 237.10498, 0.4391391)
decoder loss ratio: 17409.532180, decoder SINDy loss  ratio: 0.511824
--- 0.29514360427856445 seconds for one epoch ---
--- 3.2070441246032715 seconds for one epoch ---
--- 0.318209171295166 seconds for one epoch ---
--- 3.2624387741088867 seconds for one epoch ---
--- 0.33579182624816895 seconds for one epoch ---
--- 3.224372625350952 seconds for one epoch ---
--- 0.3281440734863281 seconds for one epoch ---
--- 3.194894552230835 seconds for one epoch ---
--- 0.3333930969238281 seconds for one epoch ---
--- 3.246960163116455 seconds for one epoch ---
--- 0.3191845417022705 seconds for one epoch ---
--- 3.2446322441101074 seconds for one epoch ---
--- 0.3256113529205322 seconds for one epoch ---
--- 3.2255406379699707 seconds for one epoch ---
--- 0.3229947090148926 seconds for one epoch ---
--- 3.2792654037475586 seconds for one epoch ---
--- 0.33001184463500977 seconds for one epoch ---
--- 3.288189172744751 seconds for one epoch ---
--- 0.32239794731140137 seconds for one epoch ---
--- 3.235588550567627 seconds for one epoch ---
--- 0.32152700424194336 seconds for one epoch ---
--- 3.2218143939971924 seconds for one epoch ---
--- 0.30322813987731934 seconds for one epoch ---
--- 3.278618574142456 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991509]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.957218]
 [ -0.      ]]
--- 0.3007020950317383 seconds for one epoch ---
Epoch 6550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5031.74755859375, (2162.237, 1.5319597, 2867.5396, 0.43917662)
   validation loss 1069.8878173828125, (785.0637, 0.99602675, 283.38885, 0.43917662)
decoder loss ratio: 30414.731471, decoder SINDy loss  ratio: 0.611735
--- 0.2620279788970947 seconds for one epoch ---
--- 0.3276395797729492 seconds for one epoch ---
--- 3.2127561569213867 seconds for one epoch ---
--- 0.3145790100097656 seconds for one epoch ---
--- 3.2766103744506836 seconds for one epoch ---
--- 0.31772708892822266 seconds for one epoch ---
--- 3.230997085571289 seconds for one epoch ---
--- 0.318936824798584 seconds for one epoch ---
--- 3.2239677906036377 seconds for one epoch ---
--- 0.32396626472473145 seconds for one epoch ---
--- 3.3054511547088623 seconds for one epoch ---
--- 0.3248903751373291 seconds for one epoch ---
--- 3.227522134780884 seconds for one epoch ---
--- 0.31874847412109375 seconds for one epoch ---
--- 3.302968740463257 seconds for one epoch ---
--- 0.33148622512817383 seconds for one epoch ---
--- 3.242431879043579 seconds for one epoch ---
--- 0.33036255836486816 seconds for one epoch ---
--- 3.325594186782837 seconds for one epoch ---
--- 0.33112359046936035 seconds for one epoch ---
--- 3.243068218231201 seconds for one epoch ---
--- 0.32901978492736816 seconds for one epoch ---
--- 3.2573397159576416 seconds for one epoch ---
--- 0.32861828804016113 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99915075]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [-16.95948]
 [ -0.     ]]
--- 0.2655465602874756 seconds for one epoch ---
Epoch 6575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1244.7252197265625, (571.3879, 1.0223142, 671.8758, 0.4392171)
   validation loss 748.5555419921875, (504.40204, 1.0717226, 242.64255, 0.4392171)
decoder loss ratio: 19541.410655, decoder SINDy loss  ratio: 0.523778
--- 0.2867863178253174 seconds for one epoch ---
--- 3.246150493621826 seconds for one epoch ---
--- 0.3259868621826172 seconds for one epoch ---
--- 3.2416908740997314 seconds for one epoch ---
--- 0.32665252685546875 seconds for one epoch ---
--- 3.2805943489074707 seconds for one epoch ---
--- 0.3220198154449463 seconds for one epoch ---
--- 3.2528936862945557 seconds for one epoch ---
--- 0.32056736946105957 seconds for one epoch ---
--- 3.274993419647217 seconds for one epoch ---
--- 0.32355642318725586 seconds for one epoch ---
--- 3.235530138015747 seconds for one epoch ---
--- 0.3366222381591797 seconds for one epoch ---
--- 3.3064815998077393 seconds for one epoch ---
--- 0.3208153247833252 seconds for one epoch ---
--- 3.2493093013763428 seconds for one epoch ---
--- 0.32363176345825195 seconds for one epoch ---
--- 3.2539522647857666 seconds for one epoch ---
--- 0.32505178451538086 seconds for one epoch ---
--- 3.312134265899658 seconds for one epoch ---
--- 0.3265976905822754 seconds for one epoch ---
--- 3.269561529159546 seconds for one epoch ---
--- 0.3235902786254883 seconds for one epoch ---
--- 3.239950656890869 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999151]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.961233]
 [  0.      ]]
--- 0.3159511089324951 seconds for one epoch ---
Epoch 6600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3420.838134765625, (1444.5566, 0.79992616, 1975.0424, 0.4392395)
   validation loss 759.204833984375, (520.53424, 1.1375781, 237.09383, 0.4392395)
decoder loss ratio: 20166.400173, decoder SINDy loss  ratio: 0.511800
--- 0.2764616012573242 seconds for one epoch ---
--- 0.3295469284057617 seconds for one epoch ---
--- 3.2567861080169678 seconds for one epoch ---
--- 0.3196220397949219 seconds for one epoch ---
--- 3.2529125213623047 seconds for one epoch ---
--- 0.3143463134765625 seconds for one epoch ---
--- 3.216331720352173 seconds for one epoch ---
--- 0.3151581287384033 seconds for one epoch ---
--- 3.307812213897705 seconds for one epoch ---
--- 0.32569336891174316 seconds for one epoch ---
--- 3.3033714294433594 seconds for one epoch ---
--- 0.31158900260925293 seconds for one epoch ---
--- 3.265522003173828 seconds for one epoch ---
--- 0.3202817440032959 seconds for one epoch ---
--- 3.271479845046997 seconds for one epoch ---
--- 0.3245248794555664 seconds for one epoch ---
--- 3.2782554626464844 seconds for one epoch ---
--- 0.3244900703430176 seconds for one epoch ---
--- 3.2515273094177246 seconds for one epoch ---
--- 0.31148505210876465 seconds for one epoch ---
--- 3.267273426055908 seconds for one epoch ---
--- 0.3255805969238281 seconds for one epoch ---
--- 3.262315034866333 seconds for one epoch ---
--- 0.3226156234741211 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99915135]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.965174]
 [ -0.      ]]
--- 0.26558446884155273 seconds for one epoch ---
Epoch 6625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1284.5335693359375, (597.00146, 1.0075382, 686.08514, 0.43936092)
   validation loss 722.1930541992188, (485.65656, 1.1294906, 234.96767, 0.43936092)
decoder loss ratio: 18815.178084, decoder SINDy loss  ratio: 0.507211
--- 0.322920560836792 seconds for one epoch ---
--- 3.317592144012451 seconds for one epoch ---
--- 0.33686113357543945 seconds for one epoch ---
--- 3.2867050170898438 seconds for one epoch ---
--- 0.3135683536529541 seconds for one epoch ---
--- 3.264104127883911 seconds for one epoch ---
--- 0.30892229080200195 seconds for one epoch ---
--- 3.2582366466522217 seconds for one epoch ---
--- 0.32137346267700195 seconds for one epoch ---
--- 3.302292823791504 seconds for one epoch ---
--- 0.3112306594848633 seconds for one epoch ---
--- 3.3330037593841553 seconds for one epoch ---
--- 0.33426380157470703 seconds for one epoch ---
--- 3.316063642501831 seconds for one epoch ---
--- 0.31580400466918945 seconds for one epoch ---
--- 3.2805769443511963 seconds for one epoch ---
--- 0.3152289390563965 seconds for one epoch ---
--- 3.256725311279297 seconds for one epoch ---
--- 0.29543256759643555 seconds for one epoch ---
--- 3.342991352081299 seconds for one epoch ---
--- 0.32897305488586426 seconds for one epoch ---
--- 3.2620975971221924 seconds for one epoch ---
--- 0.33232808113098145 seconds for one epoch ---
--- 3.2684226036071777 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991517]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.967928]
 [  0.      ]]
--- 0.304119348526001 seconds for one epoch ---
Epoch 6650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2389.54736328125, (1072.7074, 1.8068392, 1314.5935, 0.43943402)
   validation loss 743.9334716796875, (507.23975, 1.1381649, 235.1161, 0.43943402)
decoder loss ratio: 19651.348371, decoder SINDy loss  ratio: 0.507531
--- 0.27127885818481445 seconds for one epoch ---
--- 0.3287343978881836 seconds for one epoch ---
--- 3.3348426818847656 seconds for one epoch ---
--- 0.3233163356781006 seconds for one epoch ---
--- 3.3463361263275146 seconds for one epoch ---
--- 0.3226149082183838 seconds for one epoch ---
--- 3.3129236698150635 seconds for one epoch ---
--- 0.33660268783569336 seconds for one epoch ---
--- 3.3392422199249268 seconds for one epoch ---
--- 0.3345482349395752 seconds for one epoch ---
--- 3.299232244491577 seconds for one epoch ---
--- 0.31714606285095215 seconds for one epoch ---
--- 3.2959821224212646 seconds for one epoch ---
--- 0.3307805061340332 seconds for one epoch ---
--- 3.3523104190826416 seconds for one epoch ---
--- 0.33501529693603516 seconds for one epoch ---
--- 3.2618894577026367 seconds for one epoch ---
--- 0.3245534896850586 seconds for one epoch ---
--- 3.278491735458374 seconds for one epoch ---
--- 0.3129427433013916 seconds for one epoch ---
--- 3.283658504486084 seconds for one epoch ---
--- 0.31130385398864746 seconds for one epoch ---
--- 3.31091046333313 seconds for one epoch ---
--- 0.31069040298461914 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991523]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.970158]
 [ -0.      ]]
--- 0.26047587394714355 seconds for one epoch ---
Epoch 6675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2269.6845703125, (1213.0166, 1.4223042, 1054.8063, 0.439478)
   validation loss 734.8635864257812, (497.8228, 1.1572884, 235.44405, 0.439478)
decoder loss ratio: 19286.520109, decoder SINDy loss  ratio: 0.508239
--- 0.30532360076904297 seconds for one epoch ---
--- 3.2763514518737793 seconds for one epoch ---
--- 0.3201324939727783 seconds for one epoch ---
--- 3.323887586593628 seconds for one epoch ---
--- 0.3246755599975586 seconds for one epoch ---
--- 3.2832515239715576 seconds for one epoch ---
--- 0.32286810874938965 seconds for one epoch ---
--- 3.2637078762054443 seconds for one epoch ---
--- 0.31763243675231934 seconds for one epoch ---
--- 3.354058265686035 seconds for one epoch ---
--- 0.31981444358825684 seconds for one epoch ---
--- 3.3563475608825684 seconds for one epoch ---
--- 0.3398590087890625 seconds for one epoch ---
--- 3.2812860012054443 seconds for one epoch ---
--- 0.3166630268096924 seconds for one epoch ---
--- 3.33149790763855 seconds for one epoch ---
--- 0.30675435066223145 seconds for one epoch ---
--- 3.288649797439575 seconds for one epoch ---
--- 0.31919121742248535 seconds for one epoch ---
--- 3.283869981765747 seconds for one epoch ---
--- 0.3164091110229492 seconds for one epoch ---
--- 3.2885420322418213 seconds for one epoch ---
--- 0.3306708335876465 seconds for one epoch ---
--- 3.2449474334716797 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991527]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.973461]
 [  0.      ]]
--- 0.31771087646484375 seconds for one epoch ---
Epoch 6700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2502.644775390625, (1522.228, 0.783127, 979.19415, 0.43955395)
   validation loss 741.2140502929688, (503.10593, 1.1356658, 236.5329, 0.43955395)
decoder loss ratio: 19491.197023, decoder SINDy loss  ratio: 0.510590
--- 0.2637505531311035 seconds for one epoch ---
--- 0.3236265182495117 seconds for one epoch ---
--- 3.2780022621154785 seconds for one epoch ---
--- 0.33006978034973145 seconds for one epoch ---
--- 3.282724380493164 seconds for one epoch ---
--- 0.31455039978027344 seconds for one epoch ---
--- 3.2915396690368652 seconds for one epoch ---
--- 0.3177328109741211 seconds for one epoch ---
--- 3.289520740509033 seconds for one epoch ---
--- 0.32035207748413086 seconds for one epoch ---
--- 3.307438850402832 seconds for one epoch ---
--- 0.32543134689331055 seconds for one epoch ---
--- 3.322115659713745 seconds for one epoch ---
--- 0.3280041217803955 seconds for one epoch ---
--- 3.37695574760437 seconds for one epoch ---
--- 0.313230037689209 seconds for one epoch ---
--- 3.3540778160095215 seconds for one epoch ---
--- 0.31459999084472656 seconds for one epoch ---
--- 3.30644154548645 seconds for one epoch ---
--- 0.3164994716644287 seconds for one epoch ---
--- 3.298264503479004 seconds for one epoch ---
--- 0.32439184188842773 seconds for one epoch ---
--- 3.3760507106781006 seconds for one epoch ---
--- 0.31444859504699707 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999153]
 [0.      ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-16.97612]
 [  0.     ]]
--- 0.26798224449157715 seconds for one epoch ---
Epoch 6725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3390.632080078125, (1585.9003, 0.27228272, 1804.0198, 0.43962964)
   validation loss 736.1251831054688, (497.80856, 1.1544964, 236.7225, 0.43962964)
decoder loss ratio: 19285.967973, decoder SINDy loss  ratio: 0.510999
--- 0.2979903221130371 seconds for one epoch ---
--- 3.295156955718994 seconds for one epoch ---
--- 0.33456897735595703 seconds for one epoch ---
--- 3.3747475147247314 seconds for one epoch ---
--- 0.3268120288848877 seconds for one epoch ---
--- 3.3052570819854736 seconds for one epoch ---
--- 0.31249570846557617 seconds for one epoch ---
--- 3.2933738231658936 seconds for one epoch ---
--- 0.32169508934020996 seconds for one epoch ---
--- 3.358215093612671 seconds for one epoch ---
--- 0.33035850524902344 seconds for one epoch ---
--- 3.3115622997283936 seconds for one epoch ---
--- 0.31213974952697754 seconds for one epoch ---
--- 3.3081231117248535 seconds for one epoch ---
--- 0.30875444412231445 seconds for one epoch ---
--- 3.278822660446167 seconds for one epoch ---
--- 0.3076324462890625 seconds for one epoch ---
--- 3.3021950721740723 seconds for one epoch ---
--- 0.30951523780822754 seconds for one epoch ---
--- 3.2933080196380615 seconds for one epoch ---
--- 0.31975817680358887 seconds for one epoch ---
--- 3.375330924987793 seconds for one epoch ---
--- 0.322826623916626 seconds for one epoch ---
--- 3.403784990310669 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991536]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.978144]
 [ -0.      ]]
--- 0.31940627098083496 seconds for one epoch ---
Epoch 6750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4617.31787109375, (1631.5912, 7.240038, 2978.0474, 0.43967915)
   validation loss 731.0091552734375, (492.626, 1.1439849, 236.79944, 0.43967915)
decoder loss ratio: 19085.186751, decoder SINDy loss  ratio: 0.511165
--- 0.2750124931335449 seconds for one epoch ---
--- 0.3307685852050781 seconds for one epoch ---
--- 3.356839895248413 seconds for one epoch ---
--- 0.31877589225769043 seconds for one epoch ---
--- 3.3692357540130615 seconds for one epoch ---
--- 0.32673025131225586 seconds for one epoch ---
--- 3.3737237453460693 seconds for one epoch ---
--- 0.32251811027526855 seconds for one epoch ---
--- 3.3031387329101562 seconds for one epoch ---
--- 0.3134117126464844 seconds for one epoch ---
--- 3.314953565597534 seconds for one epoch ---
--- 0.3289492130279541 seconds for one epoch ---
--- 3.3333792686462402 seconds for one epoch ---
--- 0.32394981384277344 seconds for one epoch ---
--- 3.383479118347168 seconds for one epoch ---
--- 0.3364851474761963 seconds for one epoch ---
--- 3.321288585662842 seconds for one epoch ---
--- 0.3163490295410156 seconds for one epoch ---
--- 3.401517629623413 seconds for one epoch ---
--- 0.3271796703338623 seconds for one epoch ---
--- 3.3929009437561035 seconds for one epoch ---
--- 0.33263134956359863 seconds for one epoch ---
--- 3.3103628158569336 seconds for one epoch ---
--- 0.3429090976715088 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991543]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.981138]
 [  0.      ]]
--- 0.27248287200927734 seconds for one epoch ---
Epoch 6775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2214.323974609375, (1234.6492, 0.20994711, 979.025, 0.43976107)
   validation loss 711.3380737304688, (475.62076, 1.1569307, 234.12067, 0.43976107)
decoder loss ratio: 18426.373881, decoder SINDy loss  ratio: 0.505382
--- 0.2989199161529541 seconds for one epoch ---
--- 3.3516101837158203 seconds for one epoch ---
--- 0.31907200813293457 seconds for one epoch ---
--- 3.370976448059082 seconds for one epoch ---
--- 0.3046236038208008 seconds for one epoch ---
--- 3.318406105041504 seconds for one epoch ---
--- 0.32344746589660645 seconds for one epoch ---
--- 3.3677709102630615 seconds for one epoch ---
--- 0.3201253414154053 seconds for one epoch ---
--- 3.4016101360321045 seconds for one epoch ---
--- 0.3285379409790039 seconds for one epoch ---
--- 3.3810598850250244 seconds for one epoch ---
--- 0.3249039649963379 seconds for one epoch ---
--- 3.4023754596710205 seconds for one epoch ---
--- 0.32400965690612793 seconds for one epoch ---
--- 3.3250694274902344 seconds for one epoch ---
--- 0.3179779052734375 seconds for one epoch ---
--- 3.395949363708496 seconds for one epoch ---
--- 0.3264944553375244 seconds for one epoch ---
--- 3.3453869819641113 seconds for one epoch ---
--- 0.32858920097351074 seconds for one epoch ---
--- 3.3913724422454834 seconds for one epoch ---
--- 0.32610321044921875 seconds for one epoch ---
--- 3.368457078933716 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99915576]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-16.984106]
 [ -0.      ]]
--- 0.2960643768310547 seconds for one epoch ---
Epoch 6800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2363.3154296875, (818.5019, 0.6949633, 1543.6787, 0.4398515)
   validation loss 788.0535888671875, (548.102, 1.1695606, 238.34216, 0.4398515)
decoder loss ratio: 21234.422630, decoder SINDy loss  ratio: 0.514495
--- 0.2679564952850342 seconds for one epoch ---
--- 0.3334980010986328 seconds for one epoch ---
--- 3.3748013973236084 seconds for one epoch ---
--- 0.32466840744018555 seconds for one epoch ---
--- 3.3206138610839844 seconds for one epoch ---
--- 0.31844425201416016 seconds for one epoch ---
--- 3.4168219566345215 seconds for one epoch ---
--- 0.3199496269226074 seconds for one epoch ---
--- 3.3655877113342285 seconds for one epoch ---
--- 0.33389782905578613 seconds for one epoch ---
--- 3.403803825378418 seconds for one epoch ---
--- 0.318495512008667 seconds for one epoch ---
--- 3.3698372840881348 seconds for one epoch ---
--- 0.32999396324157715 seconds for one epoch ---
--- 3.3948967456817627 seconds for one epoch ---
--- 0.32364606857299805 seconds for one epoch ---
--- 3.418147325515747 seconds for one epoch ---
--- 0.3177154064178467 seconds for one epoch ---
--- 3.3937761783599854 seconds for one epoch ---
--- 0.3290374279022217 seconds for one epoch ---
--- 3.4189341068267822 seconds for one epoch ---
--- 0.3167283535003662 seconds for one epoch ---
--- 3.3987555503845215 seconds for one epoch ---
--- 0.3154277801513672 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991578]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.989838]
 [ -0.      ]]
--- 0.2722923755645752 seconds for one epoch ---
Epoch 6825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3301.689208984375, (1334.5966, 0.8670366, 1965.7856, 0.43995792)
   validation loss 710.156982421875, (471.35056, 1.1281916, 237.23827, 0.43995792)
decoder loss ratio: 18260.938818, decoder SINDy loss  ratio: 0.512112
--- 0.3041841983795166 seconds for one epoch ---
--- 3.4012515544891357 seconds for one epoch ---
--- 0.31711387634277344 seconds for one epoch ---
--- 3.40846848487854 seconds for one epoch ---
--- 0.317211389541626 seconds for one epoch ---
--- 3.3973655700683594 seconds for one epoch ---
--- 0.3241136074066162 seconds for one epoch ---
--- 3.4084908962249756 seconds for one epoch ---
--- 0.32616734504699707 seconds for one epoch ---
--- 3.409433603286743 seconds for one epoch ---
--- 0.3269624710083008 seconds for one epoch ---
--- 3.3258793354034424 seconds for one epoch ---
--- 0.32544898986816406 seconds for one epoch ---
--- 3.402397394180298 seconds for one epoch ---
--- 0.32234644889831543 seconds for one epoch ---
--- 3.389448642730713 seconds for one epoch ---
--- 0.3115842342376709 seconds for one epoch ---
--- 3.333266019821167 seconds for one epoch ---
--- 0.3286428451538086 seconds for one epoch ---
--- 3.413181781768799 seconds for one epoch ---
--- 0.3262910842895508 seconds for one epoch ---
--- 3.333798885345459 seconds for one epoch ---
--- 0.32732367515563965 seconds for one epoch ---
--- 3.363706350326538 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991591]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.992533]
 [  0.      ]]
--- 0.29828453063964844 seconds for one epoch ---
Epoch 6850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3383.037109375, (1828.1053, 1.0488183, 1553.4429, 0.44001037)
   validation loss 717.98388671875, (473.50375, 1.0975134, 242.94261, 0.44001037)
decoder loss ratio: 18344.357456, decoder SINDy loss  ratio: 0.524426
--- 0.2411494255065918 seconds for one epoch ---
--- 0.32089853286743164 seconds for one epoch ---
--- 3.4227490425109863 seconds for one epoch ---
--- 0.3216390609741211 seconds for one epoch ---
--- 3.4129440784454346 seconds for one epoch ---
--- 0.3263566493988037 seconds for one epoch ---
--- 3.416929006576538 seconds for one epoch ---
--- 0.322786808013916 seconds for one epoch ---
--- 3.36966872215271 seconds for one epoch ---
--- 0.3115718364715576 seconds for one epoch ---
--- 3.3424203395843506 seconds for one epoch ---
--- 0.3179945945739746 seconds for one epoch ---
--- 3.4033727645874023 seconds for one epoch ---
--- 0.32440972328186035 seconds for one epoch ---
--- 3.3751015663146973 seconds for one epoch ---
--- 0.3325047492980957 seconds for one epoch ---
--- 3.4021081924438477 seconds for one epoch ---
--- 0.3299076557159424 seconds for one epoch ---
--- 3.432188034057617 seconds for one epoch ---
--- 0.3188202381134033 seconds for one epoch ---
--- 3.4421255588531494 seconds for one epoch ---
--- 0.3260049819946289 seconds for one epoch ---
--- 3.45377254486084 seconds for one epoch ---
--- 0.3265688419342041 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99915993]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.992973]
 [  0.      ]]
--- 0.25414538383483887 seconds for one epoch ---
Epoch 6875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3981.027099609375, (870.4069, 1.340632, 3108.8396, 0.44005623)
   validation loss 704.1278686523438, (463.58926, 1.1438392, 238.95473, 0.44005623)
decoder loss ratio: 17960.252910, decoder SINDy loss  ratio: 0.515817
--- 0.298159122467041 seconds for one epoch ---
--- 3.346740245819092 seconds for one epoch ---
--- 0.3287050724029541 seconds for one epoch ---
--- 3.423377513885498 seconds for one epoch ---
--- 0.32559633255004883 seconds for one epoch ---
--- 3.366150140762329 seconds for one epoch ---
--- 0.3194606304168701 seconds for one epoch ---
--- 3.446718454360962 seconds for one epoch ---
--- 0.3223114013671875 seconds for one epoch ---
--- 3.3803441524505615 seconds for one epoch ---
--- 0.32595300674438477 seconds for one epoch ---
--- 3.432431697845459 seconds for one epoch ---
--- 0.32570457458496094 seconds for one epoch ---
--- 3.380505084991455 seconds for one epoch ---
--- 0.31793880462646484 seconds for one epoch ---
--- 3.4129490852355957 seconds for one epoch ---
--- 0.32413601875305176 seconds for one epoch ---
--- 3.4002647399902344 seconds for one epoch ---
--- 0.32878565788269043 seconds for one epoch ---
--- 3.4514501094818115 seconds for one epoch ---
--- 0.32190656661987305 seconds for one epoch ---
--- 3.4112308025360107 seconds for one epoch ---
--- 0.33037900924682617 seconds for one epoch ---
--- 3.4305880069732666 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991617]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.998034]
 [ -0.      ]]
--- 0.30187439918518066 seconds for one epoch ---
Epoch 6900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4283.50634765625, (2113.6729, 0.92488164, 2168.4685, 0.44015208)
   validation loss 738.5883178710938, (494.88998, 1.0946646, 242.16356, 0.44015208)
decoder loss ratio: 19172.897152, decoder SINDy loss  ratio: 0.522744
--- 0.2745029926300049 seconds for one epoch ---
--- 0.3192150592803955 seconds for one epoch ---
--- 3.422449827194214 seconds for one epoch ---
--- 0.32866525650024414 seconds for one epoch ---
--- 3.376643419265747 seconds for one epoch ---
--- 0.32102417945861816 seconds for one epoch ---
--- 3.4340970516204834 seconds for one epoch ---
--- 0.3207435607910156 seconds for one epoch ---
--- 3.3791186809539795 seconds for one epoch ---
--- 0.3245558738708496 seconds for one epoch ---
--- 3.427504301071167 seconds for one epoch ---
--- 0.3424103260040283 seconds for one epoch ---
--- 3.3878769874572754 seconds for one epoch ---
--- 0.32098984718322754 seconds for one epoch ---
--- 3.3804333209991455 seconds for one epoch ---
--- 0.32976508140563965 seconds for one epoch ---
--- 3.3991777896881104 seconds for one epoch ---
--- 0.32967138290405273 seconds for one epoch ---
--- 3.3625173568725586 seconds for one epoch ---
--- 0.3291161060333252 seconds for one epoch ---
--- 3.458204746246338 seconds for one epoch ---
--- 0.3254270553588867 seconds for one epoch ---
--- 3.4090843200683594 seconds for one epoch ---
--- 0.3206765651702881 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916136]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-16.999289]
 [ -0.      ]]
--- 0.27196478843688965 seconds for one epoch ---
Epoch 6925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2290.02294921875, (997.6733, 0.8998632, 1291.0096, 0.44019905)
   validation loss 722.9837036132812, (485.5402, 1.1290364, 235.8743, 0.44019905)
decoder loss ratio: 18810.669959, decoder SINDy loss  ratio: 0.509168
--- 0.31033778190612793 seconds for one epoch ---
--- 3.457597494125366 seconds for one epoch ---
--- 0.3250727653503418 seconds for one epoch ---
--- 3.369950294494629 seconds for one epoch ---
--- 0.3297841548919678 seconds for one epoch ---
--- 3.4671242237091064 seconds for one epoch ---
--- 0.3317840099334717 seconds for one epoch ---
--- 3.396193265914917 seconds for one epoch ---
--- 0.32176709175109863 seconds for one epoch ---
--- 3.442365884780884 seconds for one epoch ---
--- 0.32461071014404297 seconds for one epoch ---
--- 3.3854236602783203 seconds for one epoch ---
--- 0.31859254837036133 seconds for one epoch ---
--- 3.469007730484009 seconds for one epoch ---
--- 0.32291531562805176 seconds for one epoch ---
--- 3.4589993953704834 seconds for one epoch ---
--- 0.32376933097839355 seconds for one epoch ---
--- 3.3818297386169434 seconds for one epoch ---
--- 0.32771921157836914 seconds for one epoch ---
--- 3.3799874782562256 seconds for one epoch ---
--- 0.32781410217285156 seconds for one epoch ---
--- 3.5134105682373047 seconds for one epoch ---
--- 0.3253457546234131 seconds for one epoch ---
--- 3.4096693992614746 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991611]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.000975]
 [  0.      ]]
--- 0.3176250457763672 seconds for one epoch ---
Epoch 6950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3169.789794921875, (1211.9246, 5.418856, 1952.0062, 0.4402468)
   validation loss 696.1784057617188, (456.36575, 1.1163747, 238.25601, 0.4402468)
decoder loss ratio: 17680.401564, decoder SINDy loss  ratio: 0.514309
--- 0.2714838981628418 seconds for one epoch ---
--- 0.3317751884460449 seconds for one epoch ---
--- 3.3802669048309326 seconds for one epoch ---
--- 0.3370389938354492 seconds for one epoch ---
--- 3.391521453857422 seconds for one epoch ---
--- 0.3239774703979492 seconds for one epoch ---
--- 3.4475791454315186 seconds for one epoch ---
--- 0.31554388999938965 seconds for one epoch ---
--- 3.45318865776062 seconds for one epoch ---
--- 0.325711727142334 seconds for one epoch ---
--- 3.395686149597168 seconds for one epoch ---
--- 0.3187825679779053 seconds for one epoch ---
--- 3.4041264057159424 seconds for one epoch ---
--- 0.3282136917114258 seconds for one epoch ---
--- 3.4960906505584717 seconds for one epoch ---
--- 0.32887768745422363 seconds for one epoch ---
--- 3.432774305343628 seconds for one epoch ---
--- 0.3289530277252197 seconds for one epoch ---
--- 3.495589017868042 seconds for one epoch ---
--- 0.3265495300292969 seconds for one epoch ---
--- 3.4310388565063477 seconds for one epoch ---
--- 0.3116645812988281 seconds for one epoch ---
--- 3.4315803050994873 seconds for one epoch ---
--- 0.33286142349243164 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916124]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.003473]
 [ -0.      ]]
--- 0.2616872787475586 seconds for one epoch ---
Epoch 6975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3813.220458984375, (1437.3479, 2.5202413, 2372.912, 0.44030437)
   validation loss 722.0096435546875, (482.26334, 1.1142921, 238.19174, 0.44030437)
decoder loss ratio: 18683.718890, decoder SINDy loss  ratio: 0.514170
--- 0.3030407428741455 seconds for one epoch ---
--- 3.4078574180603027 seconds for one epoch ---
--- 0.3014688491821289 seconds for one epoch ---
--- 3.4501781463623047 seconds for one epoch ---
--- 0.30634284019470215 seconds for one epoch ---
--- 3.458066701889038 seconds for one epoch ---
--- 0.3211028575897217 seconds for one epoch ---
--- 3.4153809547424316 seconds for one epoch ---
--- 0.30913496017456055 seconds for one epoch ---
--- 3.425178289413452 seconds for one epoch ---
--- 0.32123851776123047 seconds for one epoch ---
--- 3.414936065673828 seconds for one epoch ---
--- 0.3204030990600586 seconds for one epoch ---
--- 3.4976603984832764 seconds for one epoch ---
--- 0.3255577087402344 seconds for one epoch ---
--- 3.4643144607543945 seconds for one epoch ---
--- 0.31203508377075195 seconds for one epoch ---
--- 3.4642581939697266 seconds for one epoch ---
--- 0.3244500160217285 seconds for one epoch ---
--- 3.4835383892059326 seconds for one epoch ---
--- 0.32515811920166016 seconds for one epoch ---
--- 3.423738479614258 seconds for one epoch ---
--- 0.31571125984191895 seconds for one epoch ---
--- 3.434526205062866 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999161]
 [0.      ]]
[[  0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [ -0.    ]
 [  0.    ]
 [ -0.    ]
 [-17.0037]
 [  0.    ]]
--- 0.2988300323486328 seconds for one epoch ---
Epoch 7000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1785.575439453125, (872.57367, 1.1367635, 911.4247, 0.4403003)
   validation loss 787.1868286132812, (546.6999, 1.1004392, 238.94618, 0.4403003)
decoder loss ratio: 21180.102857, decoder SINDy loss  ratio: 0.515799
THRESHOLDING: 1 active coefficients
--- 3.4195730686187744 seconds for one epoch ---
--- 0.31565141677856445 seconds for one epoch ---
--- 3.4853031635284424 seconds for one epoch ---
--- 0.3206934928894043 seconds for one epoch ---
--- 3.457974433898926 seconds for one epoch ---
--- 0.32575249671936035 seconds for one epoch ---
--- 3.4089503288269043 seconds for one epoch ---
--- 0.3246793746948242 seconds for one epoch ---
--- 3.4432625770568848 seconds for one epoch ---
--- 0.32689809799194336 seconds for one epoch ---
--- 3.4791007041931152 seconds for one epoch ---
--- 0.31501197814941406 seconds for one epoch ---
--- 3.427583932876587 seconds for one epoch ---
--- 0.31030726432800293 seconds for one epoch ---
--- 3.4214043617248535 seconds for one epoch ---
--- 0.32260727882385254 seconds for one epoch ---
--- 3.429034471511841 seconds for one epoch ---
--- 0.32373785972595215 seconds for one epoch ---
--- 3.4944088459014893 seconds for one epoch ---
--- 0.32053685188293457 seconds for one epoch ---
--- 3.438626289367676 seconds for one epoch ---
--- 0.31983351707458496 seconds for one epoch ---
--- 3.4423017501831055 seconds for one epoch ---
--- 0.3056776523590088 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991609]
 [0.       ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [  0.     ]
 [  0.     ]
 [ -0.     ]
 [-17.00695]
 [ -0.     ]]
--- 0.26923632621765137 seconds for one epoch ---
Epoch 7025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2898.62451171875, (1360.9186, 0.56465465, 1536.7008, 0.44038287)
   validation loss 712.1849975585938, (473.0024, 1.1320112, 237.6102, 0.44038287)
decoder loss ratio: 18324.934566, decoder SINDy loss  ratio: 0.512915
--- 0.292696475982666 seconds for one epoch ---
--- 3.3644204139709473 seconds for one epoch ---
--- 0.32276368141174316 seconds for one epoch ---
--- 3.4736194610595703 seconds for one epoch ---
--- 0.33065247535705566 seconds for one epoch ---
--- 3.4549996852874756 seconds for one epoch ---
--- 0.322462797164917 seconds for one epoch ---
--- 3.4871826171875 seconds for one epoch ---
--- 0.33167362213134766 seconds for one epoch ---
--- 3.4265236854553223 seconds for one epoch ---
--- 0.32942962646484375 seconds for one epoch ---
--- 3.4201478958129883 seconds for one epoch ---
--- 0.32057762145996094 seconds for one epoch ---
--- 3.5207555294036865 seconds for one epoch ---
--- 0.3180582523345947 seconds for one epoch ---
--- 3.459578275680542 seconds for one epoch ---
--- 0.3218212127685547 seconds for one epoch ---
--- 3.446138381958008 seconds for one epoch ---
--- 0.2975449562072754 seconds for one epoch ---
--- 3.4956908226013184 seconds for one epoch ---
--- 0.3316822052001953 seconds for one epoch ---
--- 3.451460123062134 seconds for one epoch ---
--- 0.3349618911743164 seconds for one epoch ---
--- 3.458621025085449 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991602]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.006878]
 [  0.      ]]
--- 0.3018460273742676 seconds for one epoch ---
Epoch 7050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 4242.9951171875, (1336.2758, 0.6627444, 2905.6165, 0.44039604)
   validation loss 736.9524536132812, (499.1012, 1.163846, 236.24707, 0.44039604)
decoder loss ratio: 19336.046822, decoder SINDy loss  ratio: 0.509973
--- 0.2734646797180176 seconds for one epoch ---
--- 0.3319523334503174 seconds for one epoch ---
--- 3.4442861080169678 seconds for one epoch ---
--- 0.32938480377197266 seconds for one epoch ---
--- 3.4359474182128906 seconds for one epoch ---
--- 0.31451964378356934 seconds for one epoch ---
--- 3.521834135055542 seconds for one epoch ---
--- 0.3199124336242676 seconds for one epoch ---
--- 3.532382011413574 seconds for one epoch ---
--- 0.3177323341369629 seconds for one epoch ---
--- 3.5314841270446777 seconds for one epoch ---
--- 0.327747106552124 seconds for one epoch ---
--- 3.5210378170013428 seconds for one epoch ---
--- 0.3286759853363037 seconds for one epoch ---
--- 3.5209269523620605 seconds for one epoch ---
--- 0.3303980827331543 seconds for one epoch ---
--- 3.476738214492798 seconds for one epoch ---
--- 0.32065272331237793 seconds for one epoch ---
--- 3.4690353870391846 seconds for one epoch ---
--- 0.32472991943359375 seconds for one epoch ---
--- 3.4761574268341064 seconds for one epoch ---
--- 0.3364686965942383 seconds for one epoch ---
--- 3.4662418365478516 seconds for one epoch ---
--- 0.3342781066894531 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991615]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.012426]
 [  0.      ]]
--- 0.27045178413391113 seconds for one epoch ---
Epoch 7075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1980.6903076171875, (915.98096, 1.9248792, 1062.344, 0.4405267)
   validation loss 775.0684204101562, (529.27325, 1.1251812, 244.22942, 0.4405267)
decoder loss ratio: 20504.964734, decoder SINDy loss  ratio: 0.527204
--- 0.2993028163909912 seconds for one epoch ---
--- 3.4678971767425537 seconds for one epoch ---
--- 0.32394933700561523 seconds for one epoch ---
--- 3.525010347366333 seconds for one epoch ---
--- 0.3250737190246582 seconds for one epoch ---
--- 3.512471914291382 seconds for one epoch ---
--- 0.3332202434539795 seconds for one epoch ---
--- 3.4530417919158936 seconds for one epoch ---
--- 0.32773590087890625 seconds for one epoch ---
--- 3.5215766429901123 seconds for one epoch ---
--- 0.32352542877197266 seconds for one epoch ---
--- 3.518113851547241 seconds for one epoch ---
--- 0.32993197441101074 seconds for one epoch ---
--- 3.4986658096313477 seconds for one epoch ---
--- 0.3315238952636719 seconds for one epoch ---
--- 3.475748300552368 seconds for one epoch ---
--- 0.3186371326446533 seconds for one epoch ---
--- 3.466505765914917 seconds for one epoch ---
--- 0.30685853958129883 seconds for one epoch ---
--- 3.492436170578003 seconds for one epoch ---
--- 0.3203151226043701 seconds for one epoch ---
--- 3.5355803966522217 seconds for one epoch ---
--- 0.3296821117401123 seconds for one epoch ---
--- 3.53712797164917 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991621]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.014664]
 [ -0.      ]]
--- 0.30098533630371094 seconds for one epoch ---
Epoch 7100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3315.105712890625, (1628.9075, 1.2610555, 1684.4963, 0.4405798)
   validation loss 767.7601318359375, (528.0266, 1.152158, 238.1408, 0.4405798)
decoder loss ratio: 20456.667617, decoder SINDy loss  ratio: 0.514060
--- 0.27767038345336914 seconds for one epoch ---
--- 0.3297693729400635 seconds for one epoch ---
--- 3.5508008003234863 seconds for one epoch ---
--- 0.33105993270874023 seconds for one epoch ---
--- 3.468770742416382 seconds for one epoch ---
--- 0.32759618759155273 seconds for one epoch ---
--- 3.5306191444396973 seconds for one epoch ---
--- 0.33365297317504883 seconds for one epoch ---
--- 3.466289520263672 seconds for one epoch ---
--- 0.3184792995452881 seconds for one epoch ---
--- 3.5587732791900635 seconds for one epoch ---
--- 0.320697546005249 seconds for one epoch ---
--- 3.5455620288848877 seconds for one epoch ---
--- 0.3171257972717285 seconds for one epoch ---
--- 3.5543930530548096 seconds for one epoch ---
--- 0.3053147792816162 seconds for one epoch ---
--- 3.5373120307922363 seconds for one epoch ---
--- 0.3134646415710449 seconds for one epoch ---
--- 3.4841604232788086 seconds for one epoch ---
--- 0.32354140281677246 seconds for one epoch ---
--- 3.5458459854125977 seconds for one epoch ---
--- 0.32312440872192383 seconds for one epoch ---
--- 3.537868022918701 seconds for one epoch ---
--- 0.32125043869018555 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991626]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.017025]
 [  0.      ]]
--- 0.27320075035095215 seconds for one epoch ---
Epoch 7125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2781.3359375, (1221.7661, 0.4000063, 1558.7291, 0.44063887)
   validation loss 812.2006225585938, (568.23773, 1.1682183, 242.35405, 0.44063887)
decoder loss ratio: 22014.516239, decoder SINDy loss  ratio: 0.523155
--- 0.29264163970947266 seconds for one epoch ---
--- 3.4868521690368652 seconds for one epoch ---
--- 0.32877254486083984 seconds for one epoch ---
--- 3.4820713996887207 seconds for one epoch ---
--- 0.33095359802246094 seconds for one epoch ---
--- 3.536858558654785 seconds for one epoch ---
--- 0.32118868827819824 seconds for one epoch ---
--- 3.5445621013641357 seconds for one epoch ---
--- 0.30288028717041016 seconds for one epoch ---
--- 3.5171377658843994 seconds for one epoch ---
--- 0.3181149959564209 seconds for one epoch ---
--- 3.5407371520996094 seconds for one epoch ---
--- 0.32887911796569824 seconds for one epoch ---
--- 3.496079683303833 seconds for one epoch ---
--- 0.3396754264831543 seconds for one epoch ---
--- 3.5435304641723633 seconds for one epoch ---
--- 0.32331252098083496 seconds for one epoch ---
--- 3.5598373413085938 seconds for one epoch ---
--- 0.31937098503112793 seconds for one epoch ---
--- 3.5701327323913574 seconds for one epoch ---
--- 0.3259406089782715 seconds for one epoch ---
--- 3.543505907058716 seconds for one epoch ---
--- 0.33366894721984863 seconds for one epoch ---
--- 3.545159101486206 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916303]
 [0.        ]]
[[  0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.01765]
 [ -0.     ]]
--- 0.3092067241668701 seconds for one epoch ---
Epoch 7150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3727.171630859375, (1514.5546, 2.1660688, 2210.0105, 0.44064543)
   validation loss 707.2512817382812, (468.2978, 1.1887249, 237.32411, 0.44064543)
decoder loss ratio: 18142.669406, decoder SINDy loss  ratio: 0.512297
--- 0.264345645904541 seconds for one epoch ---
--- 0.3205718994140625 seconds for one epoch ---
--- 3.542469024658203 seconds for one epoch ---
--- 0.3304870128631592 seconds for one epoch ---
--- 3.5099685192108154 seconds for one epoch ---
--- 0.3223912715911865 seconds for one epoch ---
--- 3.5542120933532715 seconds for one epoch ---
--- 0.3275320529937744 seconds for one epoch ---
--- 3.502285957336426 seconds for one epoch ---
--- 0.31969642639160156 seconds for one epoch ---
--- 3.56646466255188 seconds for one epoch ---
--- 0.30936551094055176 seconds for one epoch ---
--- 3.568638563156128 seconds for one epoch ---
--- 0.31983137130737305 seconds for one epoch ---
--- 3.4930758476257324 seconds for one epoch ---
--- 0.3449282646179199 seconds for one epoch ---
--- 3.5178322792053223 seconds for one epoch ---
--- 0.32430458068847656 seconds for one epoch ---
--- 3.505401372909546 seconds for one epoch ---
--- 0.33391237258911133 seconds for one epoch ---
--- 3.509657621383667 seconds for one epoch ---
--- 0.3137016296386719 seconds for one epoch ---
--- 3.564765214920044 seconds for one epoch ---
--- 0.3094806671142578 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916387]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.020071]
 [ -0.      ]]
--- 0.2745213508605957 seconds for one epoch ---
Epoch 7175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 6747.8369140625, (2041.1287, 0.66817796, 4705.599, 0.44071946)
   validation loss 724.3937377929688, (485.66168, 1.1863469, 237.10501, 0.44071946)
decoder loss ratio: 18815.376711, decoder SINDy loss  ratio: 0.511825
--- 0.31226396560668945 seconds for one epoch ---
--- 3.5743114948272705 seconds for one epoch ---
--- 0.3275790214538574 seconds for one epoch ---
--- 3.6211633682250977 seconds for one epoch ---
--- 0.33454084396362305 seconds for one epoch ---
--- 3.6643354892730713 seconds for one epoch ---
--- 0.34027862548828125 seconds for one epoch ---
--- 3.5569515228271484 seconds for one epoch ---
--- 0.33651041984558105 seconds for one epoch ---
--- 3.5757641792297363 seconds for one epoch ---
--- 0.32296037673950195 seconds for one epoch ---
--- 3.642514705657959 seconds for one epoch ---
--- 0.3234686851501465 seconds for one epoch ---
--- 3.6233203411102295 seconds for one epoch ---
--- 0.3233027458190918 seconds for one epoch ---
--- 3.589045763015747 seconds for one epoch ---
--- 0.3199937343597412 seconds for one epoch ---
--- 3.620182991027832 seconds for one epoch ---
--- 0.32750415802001953 seconds for one epoch ---
--- 3.577580213546753 seconds for one epoch ---
--- 0.32798075675964355 seconds for one epoch ---
--- 3.6201682090759277 seconds for one epoch ---
--- 0.31807875633239746 seconds for one epoch ---
--- 3.6361546516418457 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991651]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.023241]
 [  0.      ]]
--- 0.2913072109222412 seconds for one epoch ---
Epoch 7200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2278.21923828125, (1116.6421, 1.4753089, 1159.6608, 0.44079667)
   validation loss 714.690673828125, (474.17947, 1.1651367, 238.90526, 0.44079667)
decoder loss ratio: 18370.536030, decoder SINDy loss  ratio: 0.515711
--- 0.26975131034851074 seconds for one epoch ---
--- 0.3219614028930664 seconds for one epoch ---
--- 3.546374559402466 seconds for one epoch ---
--- 0.3223729133605957 seconds for one epoch ---
--- 3.565131187438965 seconds for one epoch ---
--- 0.3139314651489258 seconds for one epoch ---
--- 3.5463106632232666 seconds for one epoch ---
--- 0.30932092666625977 seconds for one epoch ---
--- 3.6204357147216797 seconds for one epoch ---
--- 0.3260014057159424 seconds for one epoch ---
--- 3.636620283126831 seconds for one epoch ---
--- 0.32126593589782715 seconds for one epoch ---
--- 3.5599236488342285 seconds for one epoch ---
--- 0.30918455123901367 seconds for one epoch ---
--- 3.5511341094970703 seconds for one epoch ---
--- 0.32659006118774414 seconds for one epoch ---
--- 3.622396230697632 seconds for one epoch ---
--- 0.33194494247436523 seconds for one epoch ---
--- 3.628676414489746 seconds for one epoch ---
--- 0.32777929306030273 seconds for one epoch ---
--- 3.5797815322875977 seconds for one epoch ---
--- 0.3263731002807617 seconds for one epoch ---
--- 3.5657567977905273 seconds for one epoch ---
--- 0.31584668159484863 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916506]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.022692]
 [  0.      ]]
--- 0.2658536434173584 seconds for one epoch ---
Epoch 7225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2252.057373046875, (827.4919, 0.33161625, 1423.7933, 0.44079477)
   validation loss 723.697998046875, (483.4879, 1.1387589, 238.63051, 0.44079477)
decoder loss ratio: 18731.161201, decoder SINDy loss  ratio: 0.515118
--- 0.29771852493286133 seconds for one epoch ---
--- 3.583493947982788 seconds for one epoch ---
--- 0.3179457187652588 seconds for one epoch ---
--- 3.551132917404175 seconds for one epoch ---
--- 0.32328128814697266 seconds for one epoch ---
--- 3.5697953701019287 seconds for one epoch ---
--- 0.32995128631591797 seconds for one epoch ---
--- 3.5684008598327637 seconds for one epoch ---
--- 0.32084012031555176 seconds for one epoch ---
--- 3.572789430618286 seconds for one epoch ---
--- 0.32704639434814453 seconds for one epoch ---
--- 3.586913824081421 seconds for one epoch ---
--- 0.32198143005371094 seconds for one epoch ---
--- 3.605844020843506 seconds for one epoch ---
--- 0.32346081733703613 seconds for one epoch ---
--- 3.6475703716278076 seconds for one epoch ---
--- 0.32655906677246094 seconds for one epoch ---
--- 3.567457437515259 seconds for one epoch ---
--- 0.32437872886657715 seconds for one epoch ---
--- 3.662414312362671 seconds for one epoch ---
--- 0.31360650062561035 seconds for one epoch ---
--- 3.5587658882141113 seconds for one epoch ---
--- 0.3081531524658203 seconds for one epoch ---
--- 3.5623905658721924 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991655]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.023228]
 [ -0.      ]]
--- 0.3036797046661377 seconds for one epoch ---
Epoch 7250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3214.43603515625, (988.7594, 0.666491, 2224.5693, 0.44079772)
   validation loss 773.4641723632812, (532.9118, 1.1342161, 238.97734, 0.44079772)
decoder loss ratio: 20645.928470, decoder SINDy loss  ratio: 0.515866
--- 0.2612626552581787 seconds for one epoch ---
--- 0.31721949577331543 seconds for one epoch ---
--- 3.660909652709961 seconds for one epoch ---
--- 0.3245832920074463 seconds for one epoch ---
--- 3.6099822521209717 seconds for one epoch ---
--- 0.3194434642791748 seconds for one epoch ---
--- 3.6737399101257324 seconds for one epoch ---
--- 0.3279435634613037 seconds for one epoch ---
--- 3.5711910724639893 seconds for one epoch ---
--- 0.32228565216064453 seconds for one epoch ---
--- 3.6624672412872314 seconds for one epoch ---
--- 0.3270711898803711 seconds for one epoch ---
--- 3.574742555618286 seconds for one epoch ---
--- 0.3154475688934326 seconds for one epoch ---
--- 3.625074863433838 seconds for one epoch ---
--- 0.32460522651672363 seconds for one epoch ---
--- 3.662879705429077 seconds for one epoch ---
--- 0.313554048538208 seconds for one epoch ---
--- 3.58481764793396 seconds for one epoch ---
--- 0.33173322677612305 seconds for one epoch ---
--- 3.647423505783081 seconds for one epoch ---
--- 0.3239138126373291 seconds for one epoch ---
--- 3.6832752227783203 seconds for one epoch ---
--- 0.31912732124328613 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916637]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.025297]
 [ -0.      ]]
--- 0.2722969055175781 seconds for one epoch ---
Epoch 7275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3141.805419921875, (1357.8389, 0.2923782, 1783.2333, 0.44085178)
   validation loss 757.2743530273438, (516.199, 1.1512549, 239.48329, 0.44085178)
decoder loss ratio: 19998.444437, decoder SINDy loss  ratio: 0.516958
--- 0.313277006149292 seconds for one epoch ---
--- 3.58320689201355 seconds for one epoch ---
--- 0.32340455055236816 seconds for one epoch ---
--- 3.5855417251586914 seconds for one epoch ---
--- 0.3173947334289551 seconds for one epoch ---
--- 3.5922722816467285 seconds for one epoch ---
--- 0.32111287117004395 seconds for one epoch ---
--- 3.6465563774108887 seconds for one epoch ---
--- 0.3259918689727783 seconds for one epoch ---
--- 3.6615095138549805 seconds for one epoch ---
--- 0.3163948059082031 seconds for one epoch ---
--- 3.5915396213531494 seconds for one epoch ---
--- 0.3226768970489502 seconds for one epoch ---
--- 3.646526575088501 seconds for one epoch ---
--- 0.3263273239135742 seconds for one epoch ---
--- 3.6058781147003174 seconds for one epoch ---
--- 0.31556129455566406 seconds for one epoch ---
--- 3.661914110183716 seconds for one epoch ---
--- 0.3078608512878418 seconds for one epoch ---
--- 3.593189001083374 seconds for one epoch ---
--- 0.32187986373901367 seconds for one epoch ---
--- 3.599914073944092 seconds for one epoch ---
--- 0.31239748001098633 seconds for one epoch ---
--- 3.6674509048461914 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916804]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.027802]
 [  0.      ]]
--- 0.313518762588501 seconds for one epoch ---
Epoch 7300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2929.05517578125, (1385.268, 1.6015431, 1541.7449, 0.44090638)
   validation loss 718.754150390625, (478.54453, 1.1560403, 238.61269, 0.44090638)
decoder loss ratio: 18539.645694, decoder SINDy loss  ratio: 0.515079
--- 0.2680056095123291 seconds for one epoch ---
--- 0.32047200202941895 seconds for one epoch ---
--- 3.693423271179199 seconds for one epoch ---
--- 0.32910847663879395 seconds for one epoch ---
--- 3.6247425079345703 seconds for one epoch ---
--- 0.32732129096984863 seconds for one epoch ---
--- 3.598280906677246 seconds for one epoch ---
--- 0.3154876232147217 seconds for one epoch ---
--- 3.6167259216308594 seconds for one epoch ---
--- 0.3203773498535156 seconds for one epoch ---
--- 3.678006649017334 seconds for one epoch ---
--- 0.33872365951538086 seconds for one epoch ---
--- 3.6179041862487793 seconds for one epoch ---
--- 0.3184340000152588 seconds for one epoch ---
--- 3.6143739223480225 seconds for one epoch ---
--- 0.3215610980987549 seconds for one epoch ---
--- 3.6110215187072754 seconds for one epoch ---
--- 0.3208754062652588 seconds for one epoch ---
--- 3.6319496631622314 seconds for one epoch ---
--- 0.32199907302856445 seconds for one epoch ---
--- 3.6391489505767822 seconds for one epoch ---
--- 0.32819175720214844 seconds for one epoch ---
--- 3.6283934116363525 seconds for one epoch ---
--- 0.329986572265625 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991689]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.027767]
 [ -0.      ]]
--- 0.2643778324127197 seconds for one epoch ---
Epoch 7325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 5190.4580078125, (1390.4541, 1.2523291, 3798.3108, 0.44092116)
   validation loss 707.1146240234375, (468.88507, 1.1673716, 236.62126, 0.44092116)
decoder loss ratio: 18165.421663, decoder SINDy loss  ratio: 0.510780
--- 0.2979166507720947 seconds for one epoch ---
--- 3.639754056930542 seconds for one epoch ---
--- 0.32035326957702637 seconds for one epoch ---
--- 3.6957225799560547 seconds for one epoch ---
--- 0.32034921646118164 seconds for one epoch ---
--- 3.695215940475464 seconds for one epoch ---
--- 0.3301856517791748 seconds for one epoch ---
--- 3.621793508529663 seconds for one epoch ---
--- 0.32384347915649414 seconds for one epoch ---
--- 3.7067348957061768 seconds for one epoch ---
--- 0.3139824867248535 seconds for one epoch ---
--- 3.625836133956909 seconds for one epoch ---
--- 0.33081865310668945 seconds for one epoch ---
--- 3.642953634262085 seconds for one epoch ---
--- 0.32185816764831543 seconds for one epoch ---
--- 3.6990745067596436 seconds for one epoch ---
--- 0.32277917861938477 seconds for one epoch ---
--- 3.6825578212738037 seconds for one epoch ---
--- 0.32527613639831543 seconds for one epoch ---
--- 3.6232714653015137 seconds for one epoch ---
--- 0.32889699935913086 seconds for one epoch ---
--- 3.7054736614227295 seconds for one epoch ---
--- 0.3145933151245117 seconds for one epoch ---
--- 3.6168642044067383 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916995]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.030619]
 [  0.      ]]
--- 0.29405832290649414 seconds for one epoch ---
Epoch 7350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 3309.455322265625, (1598.9982, 0.3025509, 1709.7137, 0.44096804)
   validation loss 695.5994262695312, (455.64468, 1.1539286, 238.35982, 0.44096804)
decoder loss ratio: 17652.466086, decoder SINDy loss  ratio: 0.514533
--- 0.2624976634979248 seconds for one epoch ---
--- 0.3298921585083008 seconds for one epoch ---
--- 3.6482529640197754 seconds for one epoch ---
--- 0.32407402992248535 seconds for one epoch ---
--- 3.627657890319824 seconds for one epoch ---
--- 0.32874083518981934 seconds for one epoch ---
--- 3.652590274810791 seconds for one epoch ---
--- 0.33061885833740234 seconds for one epoch ---
--- 3.675271987915039 seconds for one epoch ---
--- 0.3221561908721924 seconds for one epoch ---
--- 3.6750729084014893 seconds for one epoch ---
--- 0.3236253261566162 seconds for one epoch ---
--- 3.6362688541412354 seconds for one epoch ---
--- 0.3190617561340332 seconds for one epoch ---
--- 3.7153220176696777 seconds for one epoch ---
--- 0.32914018630981445 seconds for one epoch ---
--- 3.6590678691864014 seconds for one epoch ---
--- 0.3241615295410156 seconds for one epoch ---
--- 3.7251136302948 seconds for one epoch ---
--- 0.3207974433898926 seconds for one epoch ---
--- 3.697922706604004 seconds for one epoch ---
--- 0.3365187644958496 seconds for one epoch ---
--- 3.712010383605957 seconds for one epoch ---
--- 0.32540440559387207 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99917114]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-17.033783]
 [ -0.      ]]
--- 0.2753732204437256 seconds for one epoch ---
Epoch 7375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2740.1298828125, (1057.3044, 0.21047738, 1682.1741, 0.4410374)
   validation loss 719.184326171875, (481.21954, 1.165603, 236.35815, 0.4410374)
decoder loss ratio: 18643.280547, decoder SINDy loss  ratio: 0.510212
--- 0.29758262634277344 seconds for one epoch ---
--- 3.692309617996216 seconds for one epoch ---
--- 0.332125186920166 seconds for one epoch ---
--- 3.6794989109039307 seconds for one epoch ---
--- 0.319138765335083 seconds for one epoch ---
--- 3.7040419578552246 seconds for one epoch ---
--- 0.3184635639190674 seconds for one epoch ---
--- 3.716857433319092 seconds for one epoch ---
--- 0.3143908977508545 seconds for one epoch ---
--- 3.678903579711914 seconds for one epoch ---
--- 0.31828999519348145 seconds for one epoch ---
--- 3.6975386142730713 seconds for one epoch ---
--- 0.319685697555542 seconds for one epoch ---
--- 3.720383405685425 seconds for one epoch ---
--- 0.32880067825317383 seconds for one epoch ---
--- 3.6443140506744385 seconds for one epoch ---
--- 0.32620811462402344 seconds for one epoch ---
--- 3.730443239212036 seconds for one epoch ---
--- 0.3403446674346924 seconds for one epoch ---
--- 3.703394651412964 seconds for one epoch ---
--- 0.3207435607910156 seconds for one epoch ---
--- 3.655142068862915 seconds for one epoch ---
--- 0.3049755096435547 seconds for one epoch ---
--- 3.70552921295166 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991703]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-17.033802]
 [  0.      ]]
--- 0.3082609176635742 seconds for one epoch ---
Epoch 7400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2006.3187255859375, (1107.5762, 0.51400805, 897.78754, 0.44105306)
   validation loss 772.342529296875, (533.20917, 1.1427373, 237.54958, 0.44105306)
decoder loss ratio: 20657.448840, decoder SINDy loss  ratio: 0.512784
--- 1.5447137355804443 seconds for one epoch ---
--- 0.3125941753387451 seconds for one epoch ---
--- 3.657999038696289 seconds for one epoch ---
--- 0.32236409187316895 seconds for one epoch ---
--- 3.661496877670288 seconds for one epoch ---
--- 0.3118629455566406 seconds for one epoch ---
--- 3.6398351192474365 seconds for one epoch ---
--- 0.3264739513397217 seconds for one epoch ---
--- 3.7102530002593994 seconds for one epoch ---
--- 0.32560157775878906 seconds for one epoch ---
--- 3.733186960220337 seconds for one epoch ---
--- 0.32335519790649414 seconds for one epoch ---
--- 3.6670339107513428 seconds for one epoch ---
--- 0.31081342697143555 seconds for one epoch ---
--- 3.670278310775757 seconds for one epoch ---
--- 0.3401310443878174 seconds for one epoch ---
--- 3.7511470317840576 seconds for one epoch ---
--- 0.32683467864990234 seconds for one epoch ---
--- 3.6736884117126465 seconds for one epoch ---
--- 0.3191874027252197 seconds for one epoch ---
--- 3.6713509559631348 seconds for one epoch ---
--- 0.3266477584838867 seconds for one epoch ---
--- 3.743530035018921 seconds for one epoch ---
--- 0.3351552486419678 seconds for one epoch ---
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991704]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-17.035583]
 [  0.      ]]
--- 0.25914812088012695 seconds for one epoch ---
Epoch 7425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2098.0966796875, (872.9606, 0.555333, 1224.1396, 0.4411091)
   validation loss 811.3106079101562, (569.78467, 1.1900283, 239.8948, 0.4411091)
decoder loss ratio: 22074.447227, decoder SINDy loss  ratio: 0.517847
--- 0.3165597915649414 seconds for one epoch ---
--- 3.7317259311676025 seconds for one epoch ---
--- 0.33014512062072754 seconds for one epoch ---
--- 3.7212488651275635 seconds for one epoch ---
--- 0.31551623344421387 seconds for one epoch ---
--- 3.6627237796783447 seconds for one epoch ---
--- 0.31856679916381836 seconds for one epoch ---
--- 3.6769633293151855 seconds for one epoch ---
--- 0.3033928871154785 seconds for one epoch ---
--- 3.6715762615203857 seconds for one epoch ---
--- 0.32422518730163574 seconds for one epoch ---
--- 3.734971046447754 seconds for one epoch ---
--- 0.3253030776977539 seconds for one epoch ---
--- 3.737459182739258 seconds for one epoch ---
--- 0.3067207336425781 seconds for one epoch ---
--- 3.7225539684295654 seconds for one epoch ---
--- 0.33624744415283203 seconds for one epoch ---
--- 3.627013921737671 seconds for one epoch ---
--- 0.32276272773742676 seconds for one epoch ---
--- 3.733170986175537 seconds for one epoch ---
--- 0.3269522190093994 seconds for one epoch ---
--- 3.6682310104370117 seconds for one epoch ---
--- 0.31822824478149414 seconds for one epoch ---
--- 3.661439895629883 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99917006]
 [0.        ]]
[[  0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [-17.03771]
 [ -0.     ]]
--- 0.3032526969909668 seconds for one epoch ---
Epoch 7450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2710.877685546875, (1297.3386, 1.0195835, 1412.0785, 0.44114605)
   validation loss 784.2279663085938, (545.8487, 1.135114, 236.80296, 0.44114605)
decoder loss ratio: 21147.126035, decoder SINDy loss  ratio: 0.511173
--- 0.27547216415405273 seconds for one epoch ---
--- 0.32625865936279297 seconds for one epoch ---
--- 3.7415058612823486 seconds for one epoch ---
--- 0.32028675079345703 seconds for one epoch ---
--- 3.7387077808380127 seconds for one epoch ---
--- 0.31993961334228516 seconds for one epoch ---
--- 3.6955699920654297 seconds for one epoch ---
--- 0.3305637836456299 seconds for one epoch ---
--- 3.7465388774871826 seconds for one epoch ---
--- 0.3280313014984131 seconds for one epoch ---
--- 3.729118585586548 seconds for one epoch ---
--- 0.3240175247192383 seconds for one epoch ---
--- 3.6817331314086914 seconds for one epoch ---
--- 0.3303642272949219 seconds for one epoch ---
--- 3.679053783416748 seconds for one epoch ---
--- 0.3248867988586426 seconds for one epoch ---
--- 3.697143793106079 seconds for one epoch ---
--- 0.3315756320953369 seconds for one epoch ---
--- 3.7082958221435547 seconds for one epoch ---
--- 0.32633042335510254 seconds for one epoch ---
--- 3.6712379455566406 seconds for one epoch ---
--- 0.33355164527893066 seconds for one epoch ---
--- 3.704449415206909 seconds for one epoch ---
--- 0.3229498863220215 seconds for one epoch ---
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916965]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-17.039389]
 [  0.      ]]
--- 0.26785898208618164 seconds for one epoch ---
Epoch 7475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2288.942138671875, (1052.2506, 2.7564125, 1233.4938, 0.44117737)
   validation loss 793.39111328125, (552.7608, 1.1232058, 239.06593, 0.44117737)
decoder loss ratio: 21414.913152, decoder SINDy loss  ratio: 0.516057
--- 0.2952284812927246 seconds for one epoch ---
--- 3.6840121746063232 seconds for one epoch ---
--- 0.32462000846862793 seconds for one epoch ---
--- 3.733812093734741 seconds for one epoch ---
--- 0.3257558345794678 seconds for one epoch ---
--- 3.7361438274383545 seconds for one epoch ---
--- 0.31608080863952637 seconds for one epoch ---
--- 3.758277177810669 seconds for one epoch ---
--- 0.3000071048736572 seconds for one epoch ---
--- 3.7749009132385254 seconds for one epoch ---
--- 0.3217947483062744 seconds for one epoch ---
--- 3.6697778701782227 seconds for one epoch ---
--- 0.31658506393432617 seconds for one epoch ---
--- 3.6816182136535645 seconds for one epoch ---
--- 0.3114171028137207 seconds for one epoch ---
--- 3.7079238891601562 seconds for one epoch ---
--- 0.33054399490356445 seconds for one epoch ---
--- 3.7554638385772705 seconds for one epoch ---
--- 0.31879091262817383 seconds for one epoch ---
--- 3.764907121658325 seconds for one epoch ---
--- 0.3313264846801758 seconds for one epoch ---
--- 3.7765660285949707 seconds for one epoch ---
--- 0.3166074752807617 seconds for one epoch ---
--- 3.7704856395721436 seconds for one epoch ---
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.999169]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.040993]
 [ -0.      ]]
--- 0.30281543731689453 seconds for one epoch ---
Epoch 7500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 2214.801513671875, (1320.3118, 0.39177686, 893.65686, 0.44124958)
   validation loss 763.8316650390625, (517.7635, 1.1334721, 244.49348, 0.44124958)
decoder loss ratio: 20059.056432, decoder SINDy loss  ratio: 0.527774
THRESHOLDING: 1 active coefficients
REFINEMENT
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991696]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-17.041586]
 [ -0.      ]]
Epoch 0
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1233.7105712890625, (617.5209, 0.3472342, 615.84247, 0.44128576)
   validation loss 806.1746826171875, (557.88403, 0.92038065, 247.37021, 0.44128576)
decoder loss ratio: 21613.395976, decoder SINDy loss  ratio: 0.533983
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99916416]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.997087]
 [  0.      ]]
Epoch 25
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 982.651611328125, (466.16306, 0.41553617, 516.07306, 0.44064352)
   validation loss 572.214111328125, (348.90033, 0.18845813, 223.12535, 0.44064352)
decoder loss ratio: 13517.004486, decoder SINDy loss  ratio: 0.481647
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9991319]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.896341]
 [  0.      ]]
Epoch 50
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 768.851806640625, (292.22238, 0.28843743, 476.34097, 0.43757683)
   validation loss 467.31005859375, (249.42398, 0.12073796, 217.76534, 0.43757683)
decoder loss ratio: 9663.118032, decoder SINDy loss  ratio: 0.470077
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990869]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.765032]
 [ -0.      ]]
Epoch 75
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 912.7564697265625, (418.71747, 0.24990326, 493.7891, 0.4335838)
   validation loss 553.57861328125, (332.84473, 0.08497344, 220.64894, 0.4335838)
decoder loss ratio: 12894.982551, decoder SINDy loss  ratio: 0.476302
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9990282]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-16.554834]
 [  0.      ]]
Epoch 100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 841.38818359375, (386.61462, 0.23621035, 454.53738, 0.42928392)
   validation loss 532.3923950195312, (311.3075, 0.065037325, 221.01987, 0.42928392)
decoder loss ratio: 12060.592814, decoder SINDy loss  ratio: 0.477102
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.998971]
 [0.      ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.408098]
 [  0.      ]]
Epoch 125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 730.2660522460938, (266.61438, 0.24289607, 463.40878, 0.42516825)
   validation loss 432.4636535644531, (219.17174, 0.053500317, 213.23842, 0.42516825)
decoder loss ratio: 8491.093616, decoder SINDy loss  ratio: 0.460305
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9989081]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-16.217033]
 [ -0.      ]]
Epoch 150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.927978515625, (229.0192, 0.22930263, 449.67947, 0.42113128)
   validation loss 396.9234924316406, (185.93198, 0.048155982, 210.94336, 0.42113128)
decoder loss ratio: 7203.327555, decoder SINDy loss  ratio: 0.455351
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9988439]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-16.050404]
 [ -0.      ]]
Epoch 175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 903.7681884765625, (420.041, 0.21391748, 483.51328, 0.4173564)
   validation loss 583.1447143554688, (366.02487, 0.041495, 217.07832, 0.4173564)
decoder loss ratio: 14180.438982, decoder SINDy loss  ratio: 0.468594
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99878204]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-15.915274]
 [ -0.      ]]
Epoch 200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1020.2762451171875, (585.48346, 0.1659122, 434.6269, 0.41393113)
   validation loss 723.150634765625, (498.1882, 0.04385853, 224.91861, 0.41393113)
decoder loss ratio: 19300.675835, decoder SINDy loss  ratio: 0.485518
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9987161]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.788015]
 [  0.      ]]
Epoch 225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 681.2770385742188, (231.2772, 0.18670143, 449.81314, 0.4106554)
   validation loss 398.77447509765625, (189.89037, 0.038623407, 208.84547, 0.4106554)
decoder loss ratio: 7356.682428, decoder SINDy loss  ratio: 0.450822
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9986523]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.636808]
 [  0.      ]]
Epoch 250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 735.9691162109375, (307.09912, 0.17011173, 428.69986, 0.40762988)
   validation loss 452.5067138671875, (242.06085, 0.041440826, 210.40442, 0.40762988)
decoder loss ratio: 9377.857645, decoder SINDy loss  ratio: 0.454188
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9985912]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.518696]
 [  0.      ]]
Epoch 275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 679.6314697265625, (231.3884, 0.17518143, 448.0679, 0.4049428)
   validation loss 395.3800354003906, (187.94516, 0.034980353, 207.3999, 0.4049428)
decoder loss ratio: 7281.321782, decoder SINDy loss  ratio: 0.447702
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9985311]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.409975]
 [  0.      ]]
Epoch 300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 950.4896240234375, (524.1045, 0.14488706, 426.24023, 0.4025298)
   validation loss 656.9596557617188, (438.61002, 0.038089935, 218.31154, 0.4025298)
decoder loss ratio: 16992.513475, decoder SINDy loss  ratio: 0.471256
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99847376]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.312607]
 [  0.      ]]
Epoch 325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 667.1693725585938, (236.04646, 0.17023197, 430.9527, 0.4003489)
   validation loss 387.0747985839844, (180.65103, 0.034362316, 206.3894, 0.4003489)
decoder loss ratio: 6998.734584, decoder SINDy loss  ratio: 0.445521
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99842143]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-15.217365]
 [  0.      ]]
Epoch 350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 957.8064575195312, (531.9345, 0.143928, 425.72803, 0.3983592)
   validation loss 647.3319091796875, (430.04266, 0.03767983, 217.25154, 0.3983592)
decoder loss ratio: 16660.599374, decoder SINDy loss  ratio: 0.468968
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99836946]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-15.153442]
 [  0.      ]]
Epoch 375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 658.1840209960938, (218.85013, 0.18522882, 439.14868, 0.39653888)
   validation loss 378.3858337402344, (173.62373, 0.03343483, 204.72867, 0.39653888)
decoder loss ratio: 6726.484861, decoder SINDy loss  ratio: 0.441936
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9983175]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.058002]
 [ -0.      ]]
Epoch 400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.00927734375, (241.93954, 0.17057079, 427.89917, 0.39484853)
   validation loss 383.440185546875, (179.24025, 0.035449047, 204.16449, 0.39484853)
decoder loss ratio: 6944.078446, decoder SINDy loss  ratio: 0.440718
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99827206]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-15.005821]
 [  0.      ]]
Epoch 425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 645.2699584960938, (209.8897, 0.16982716, 435.21042, 0.3933311)
   validation loss 371.2781066894531, (168.05972, 0.032380126, 203.186, 0.3933311)
decoder loss ratio: 6510.925430, decoder SINDy loss  ratio: 0.438606
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99822813]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.943391]
 [ -0.      ]]
Epoch 450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 922.643310546875, (499.90317, 0.14331871, 422.59686, 0.3919377)
   validation loss 611.7010498046875, (398.34796, 0.034218263, 213.3189, 0.3919377)
decoder loss ratio: 15432.691588, decoder SINDy loss  ratio: 0.460479
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9981822]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.881218]
 [  0.      ]]
Epoch 475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 673.23388671875, (230.94809, 0.17044562, 442.11536, 0.39059052)
   validation loss 400.3565673828125, (196.86119, 0.031085968, 203.4643, 0.39059052)
decoder loss ratio: 7626.744297, decoder SINDy loss  ratio: 0.439206
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99814147]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.829362]
 [  0.      ]]
Epoch 500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 658.0294189453125, (227.99434, 0.17761117, 429.85748, 0.3894312)
   validation loss 374.2038879394531, (171.94353, 0.032911357, 202.22745, 0.3894312)
decoder loss ratio: 6661.390752, decoder SINDy loss  ratio: 0.436536
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99810827]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.767794]
 [ -0.      ]]
Epoch 525
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 700.8067016601562, (256.01935, 0.17112935, 444.6162, 0.38841745)
   validation loss 430.97491455078125, (227.39925, 0.031073464, 203.5446, 0.38841745)
decoder loss ratio: 8809.841581, decoder SINDy loss  ratio: 0.439380
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99807096]
 [0.        ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.702287]
 [ -0.      ]]
Epoch 550
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 780.5857543945312, (362.0801, 0.14117102, 418.36447, 0.38744918)
   validation loss 485.4517517089844, (278.9929, 0.03321294, 206.42566, 0.38744918)
decoder loss ratio: 10808.668888, decoder SINDy loss  ratio: 0.445599
=========================
[[0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.      ]
 [0.998039]
 [0.      ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.689328]
 [ -0.      ]]
Epoch 575
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 736.7533569335938, (278.81186, 0.20187137, 457.73962, 0.3866137)
   validation loss 453.0284423828125, (246.3748, 0.030858783, 206.62279, 0.3866137)
decoder loss ratio: 9544.987541, decoder SINDy loss  ratio: 0.446024
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9980093]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.629504]
 [  0.      ]]
Epoch 600
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 911.9794311523438, (493.9539, 0.13535668, 417.8902, 0.38582468)
   validation loss 593.8941650390625, (383.1461, 0.033173893, 210.71489, 0.38582468)
decoder loss ratio: 14843.744606, decoder SINDy loss  ratio: 0.454858
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9979831]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.586714]
 [  0.      ]]
Epoch 625
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 990.6727905273438, (506.78946, 0.17780568, 483.70554, 0.38508755)
   validation loss 693.6339111328125, (480.12546, 0.02852942, 213.47995, 0.38508755)
decoder loss ratio: 18600.893768, decoder SINDy loss  ratio: 0.460826
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99795544]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.598556]
 [ -0.      ]]
Epoch 650
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 659.3289794921875, (236.00246, 0.1674674, 423.1591, 0.3844487)
   validation loss 372.62451171875, (171.68912, 0.032094534, 200.90332, 0.3844487)
decoder loss ratio: 6651.534475, decoder SINDy loss  ratio: 0.433678
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9979329]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.557852]
 [  0.      ]]
Epoch 675
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 651.4247436523438, (224.5934, 0.16719298, 426.66415, 0.38389856)
   validation loss 370.4906005859375, (169.70393, 0.031495318, 200.75519, 0.38389856)
decoder loss ratio: 6574.625011, decoder SINDy loss  ratio: 0.433358
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9979085]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.532552]
 [  0.      ]]
Epoch 700
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 654.0145874023438, (230.51137, 0.16800009, 423.3352, 0.38331607)
   validation loss 369.55694580078125, (169.15576, 0.031542093, 200.36963, 0.38331607)
decoder loss ratio: 6553.387876, decoder SINDy loss  ratio: 0.432526
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9978899]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.496004]
 [  0.      ]]
Epoch 725
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 716.9281005859375, (268.86313, 0.18455304, 447.88043, 0.38282576)
   validation loss 452.311767578125, (248.30453, 0.029517919, 203.97774, 0.38282576)
decoder loss ratio: 9619.748758, decoder SINDy loss  ratio: 0.440315
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99786747]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.481793]
 [  0.      ]]
Epoch 750
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 670.707275390625, (242.92822, 0.1807303, 427.59836, 0.38236672)
   validation loss 382.2274475097656, (181.9099, 0.030978102, 200.28658, 0.38236672)
decoder loss ratio: 7047.505213, decoder SINDy loss  ratio: 0.432347
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99785084]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.452591]
 [  0.      ]]
Epoch 775
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 658.88134765625, (223.93051, 0.1662005, 434.78467, 0.38196072)
   validation loss 394.9117431640625, (193.9996, 0.028216954, 200.88393, 0.38196072)
decoder loss ratio: 7515.881429, decoder SINDy loss  ratio: 0.433636
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9978355]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.458836]
 [ -0.      ]]
Epoch 800
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 930.7969360351562, (514.7171, 0.13449694, 415.9453, 0.38161033)
   validation loss 604.7061767578125, (395.5936, 0.030180804, 209.08241, 0.38161033)
decoder loss ratio: 15325.982744, decoder SINDy loss  ratio: 0.451334
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9978229]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.413249]
 [ -0.      ]]
Epoch 825
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 856.6923828125, (393.69278, 0.17451502, 462.82507, 0.38124266)
   validation loss 592.7889404296875, (385.22784, 0.02721483, 207.5339, 0.38124266)
decoder loss ratio: 14924.395471, decoder SINDy loss  ratio: 0.447991
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99780893]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.408493]
 [  0.      ]]
Epoch 850
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 758.7060546875, (341.33487, 0.1506223, 417.22052, 0.3809424)
   validation loss 438.7847900390625, (235.43489, 0.030552605, 203.31935, 0.3809424)
decoder loss ratio: 9121.156400, decoder SINDy loss  ratio: 0.438893
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977983]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.410342]
 [ -0.      ]]
Epoch 875
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 678.9851684570312, (240.53934, 0.16244252, 438.2834, 0.38067663)
   validation loss 416.44183349609375, (215.23537, 0.0271611, 201.17929, 0.38067663)
decoder loss ratio: 8338.591776, decoder SINDy loss  ratio: 0.434274
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977833]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.386988]
 [ -0.      ]]
Epoch 900
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 754.928466796875, (335.7173, 0.1574019, 419.05374, 0.38037968)
   validation loss 422.887451171875, (220.70056, 0.030123694, 202.15675, 0.38037968)
decoder loss ratio: 8550.322906, decoder SINDy loss  ratio: 0.436384
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99777126]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.364881]
 [  0.      ]]
Epoch 925
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1211.9256591796875, (710.289, 0.18935542, 501.44733, 0.38010225)
   validation loss 937.7022094726562, (716.79266, 0.026289934, 220.88326, 0.38010225)
decoder loss ratio: 27769.792194, decoder SINDy loss  ratio: 0.476808
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977591]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.328961]
 [ -0.      ]]
Epoch 950
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 788.4000244140625, (334.99097, 0.20260736, 453.20642, 0.37989455)
   validation loss 528.734375, (322.70126, 0.028995223, 206.0041, 0.37989455)
decoder loss ratio: 12502.007179, decoder SINDy loss  ratio: 0.444689
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99775255]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.337687]
 [  0.      ]]
Epoch 975
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 1296.662353515625, (787.147, 0.19089217, 509.3244, 0.3796776)
   validation loss 1019.184814453125, (795.19916, 0.026196111, 223.9595, 0.3796776)
decoder loss ratio: 30807.395896, decoder SINDy loss  ratio: 0.483448
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977452]
 [0.       ]]
[[ -0.     ]
 [  0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [ -0.     ]
 [  0.     ]
 [ -0.     ]
 [  0.     ]
 [-14.37406]
 [ -0.     ]]
Epoch 1000
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 633.5462646484375, (207.16301, 0.15794878, 426.22534, 0.37953803)
   validation loss 375.33941650390625, (176.4421, 0.028553002, 198.86876, 0.37953803)
decoder loss ratio: 6835.672996, decoder SINDy loss  ratio: 0.429286
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977396]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.320459]
 [  0.      ]]
Epoch 1025
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 781.268310546875, (329.67865, 0.16333415, 451.42633, 0.3793963)
   validation loss 525.5728759765625, (321.04465, 0.026372075, 204.50185, 0.3793963)
decoder loss ratio: 12437.826991, decoder SINDy loss  ratio: 0.441446
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977351]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.313921]
 [ -0.      ]]
Epoch 1050
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 664.5438842773438, (251.30424, 0.14966257, 413.08997, 0.37932968)
   validation loss 378.4534606933594, (180.29811, 0.029802702, 198.12555, 0.37932968)
decoder loss ratio: 6985.061830, decoder SINDy loss  ratio: 0.427682
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977264]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.312691]
 [ -0.      ]]
Epoch 1075
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.0283813476562, (256.53363, 0.1817962, 442.31296, 0.3791648)
   validation loss 441.3912353515625, (238.99524, 0.027623864, 202.36836, 0.3791648)
decoder loss ratio: 9259.090483, decoder SINDy loss  ratio: 0.436841
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99772227]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.324915]
 [  0.      ]]
Epoch 1100
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 731.7315063476562, (319.95624, 0.13861907, 411.63666, 0.37906605)
   validation loss 421.43701171875, (220.7174, 0.028914154, 200.6907, 0.37906605)
decoder loss ratio: 8550.975538, decoder SINDy loss  ratio: 0.433219
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977176]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.341949]
 [  0.      ]]
Epoch 1125
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 699.331298828125, (259.81238, 0.15692176, 439.36197, 0.3789533)
   validation loss 439.36370849609375, (237.91814, 0.025853934, 201.41972, 0.3789533)
decoder loss ratio: 9217.361656, decoder SINDy loss  ratio: 0.434793
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977137]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.346375]
 [  0.      ]]
Epoch 1150
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 791.2554931640625, (381.72107, 0.12535347, 409.40903, 0.37888145)
   validation loss 488.7913818359375, (286.05902, 0.027876467, 202.7045, 0.37888145)
decoder loss ratio: 11082.423094, decoder SINDy loss  ratio: 0.437566
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99771047]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.317894]
 [ -0.      ]]
Epoch 1175
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 830.721435546875, (372.2884, 0.16334707, 458.26965, 0.37879977)
   validation loss 566.22802734375, (359.68555, 0.025071265, 206.51741, 0.37879977)
decoder loss ratio: 13934.842528, decoder SINDy loss  ratio: 0.445797
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977044]
 [0.       ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.298238]
 [  0.      ]]
Epoch 1200
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 647.8478393554688, (228.11809, 0.16136315, 419.5684, 0.3787254)
   validation loss 370.3805236816406, (172.52708, 0.02762604, 197.8258, 0.3787254)
decoder loss ratio: 6683.998768, decoder SINDy loss  ratio: 0.427035
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977035]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.306064]
 [ -0.      ]]
Epoch 1225
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 642.502685546875, (217.7158, 0.14235047, 424.64453, 0.37868157)
   validation loss 373.7252197265625, (175.20015, 0.02485106, 198.50023, 0.37868157)
decoder loss ratio: 6787.557954, decoder SINDy loss  ratio: 0.428491
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99770284]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.312134]
 [ -0.      ]]
Epoch 1250
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 926.29443359375, (518.2835, 0.11745453, 407.89352, 0.37865332)
   validation loss 605.9866943359375, (398.74857, 0.027077684, 207.21103, 0.37865332)
decoder loss ratio: 15448.211692, decoder SINDy loss  ratio: 0.447294
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977037]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.305811]
 [  0.      ]]
Epoch 1275
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 904.266845703125, (433.96927, 0.20786887, 470.0897, 0.37869045)
   validation loss 641.6707763671875, (430.61383, 0.026847448, 211.03012, 0.37869045)
decoder loss ratio: 16682.727375, decoder SINDy loss  ratio: 0.455538
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977037]
 [0.       ]]
[[ -0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [  0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [ -0.       ]
 [-14.2919235]
 [  0.       ]]
Epoch 1300
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 785.3138427734375, (330.8048, 0.19136915, 454.31763, 0.3787104)
   validation loss 524.56640625, (318.65158, 0.026948672, 205.88785, 0.3787104)
decoder loss ratio: 12345.115444, decoder SINDy loss  ratio: 0.444438
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9977037]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.322029]
 [ -0.      ]]
Epoch 1325
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 647.1497802734375, (220.02042, 0.17552547, 426.95383, 0.37867606)
   validation loss 391.90338134765625, (193.48198, 0.026817355, 198.39458, 0.37867606)
decoder loss ratio: 7495.827780, decoder SINDy loss  ratio: 0.428263
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99770087]
 [0.        ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [-14.314644]
 [  0.      ]]
Epoch 1350
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 892.7548828125, (427.56702, 0.20073715, 464.98715, 0.37860408)
   validation loss 646.9953002929688, (436.4821, 0.027233832, 210.486, 0.37860408)
decoder loss ratio: 16910.073785, decoder SINDy loss  ratio: 0.454364
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99770033]
 [0.        ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [-14.295234]
 [  0.      ]]
Epoch 1375
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 850.736572265625, (394.2085, 0.16519724, 456.36288, 0.37856063)
   validation loss 603.9247436523438, (397.72357, 0.024894705, 206.17627, 0.37856063)
decoder loss ratio: 15408.501649, decoder SINDy loss  ratio: 0.445060
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9976988]
 [0.       ]]
[[  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.320842]
 [  0.      ]]
Epoch 1400
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 623.446044921875, (206.91844, 0.14702566, 416.38055, 0.37854743)
   validation loss 361.32177734375, (164.42737, 0.026768383, 196.86766, 0.37854743)
decoder loss ratio: 6370.201701, decoder SINDy loss  ratio: 0.424967
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9976944]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [-14.275549]
 [  0.      ]]
Epoch 1425
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 620.1153564453125, (202.34073, 0.15195277, 417.6227, 0.37846836)
   validation loss 361.473388671875, (164.543, 0.02574272, 196.90466, 0.37846836)
decoder loss ratio: 6374.681451, decoder SINDy loss  ratio: 0.425046
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9976915]
 [0.       ]]
[[ -0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.278667]
 [  0.      ]]
Epoch 1450
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 672.0819091796875, (263.20767, 0.14187992, 408.73233, 0.37842256)
   validation loss 381.8551025390625, (184.18263, 0.026345802, 197.64613, 0.37842256)
decoder loss ratio: 7135.554936, decoder SINDy loss  ratio: 0.426647
=========================
[[0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.       ]
 [0.9976914]
 [0.       ]]
[[  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [-14.298826]
 [  0.      ]]
Epoch 1475
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 626.1156005859375, (215.90536, 0.14133269, 410.06888, 0.37840223)
   validation loss 355.805908203125, (159.88248, 0.025702586, 195.89774, 0.37840223)
decoder loss ratio: 6194.124720, decoder SINDy loss  ratio: 0.422873
=========================
[[0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.        ]
 [0.99768865]
 [0.        ]]
[[ -0.      ]
 [  0.      ]
 [ -0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [ -0.      ]
 [  0.      ]
 [  0.      ]
 [-14.302037]
 [  0.      ]]
Epoch 1500
dict_keys(['decoder', 'sindy_z', 'sindy_x', 'sindy_regularization'])
   training loss 652.59375, (227.23029, 0.16353282, 425.19995, 0.3783866)
   validation loss 382.2897644042969, (184.1612, 0.025939597, 198.10263, 0.3783866)
decoder loss ratio: 7134.724368, decoder SINDy loss  ratio: 0.427632
params['save_name']
pendulum_2022_09_16_17_57_46_698157
